[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manuel de formation MOSAIKS",
    "section": "",
    "text": "Welcome\nThis is the first edition of the MOSAIKS Training Manual! The manual serves as a comprehensive reference for understanding MOSAIKS, its capabilities, and guidance on practical implementation. You will learn what MOSAIKS is, what can be done with it, and how to use it effectively in a variety of applications.\nThe skills and knowledge you gain from this manual will enable you to leverage satellite imagery and machine learning to address complex socioeconomic and environmental challenges. This can be a self taught manual or used in conjunction with a training course.\nMany of the concepts and examples are broadly applicable to the world of remote sensing and machine learning, so even if you are not using MOSAIKS, you may find the content useful.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-is-mosaiks",
    "href": "index.html#what-is-mosaiks",
    "title": "Manuel de formation MOSAIKS",
    "section": "What is MOSAIKS?",
    "text": "What is MOSAIKS?\nMOSAIKS stands for Multi-task Observation using SAtellite Imagery & Kitchen Sinks. It is a framework designed to simplify the use of satellite imagery and machine learning for predicting socioeconomic and environmental outcomes across different geographic contexts and time periods. MOSAIKS relis on random convolutions (developed in Rahimi and Recht (2008)) applied to satellite imagery, which extract task-agnostic features and enable researchers and practitioners to easily and flexibly predict a diversity of outcomes from raw imagery.\n\n\n\n\n\n\nFigure 1: MOSAIKS spelled out with imagery from the Landsat Satellite Constellation data catalog. Made with: Your Name in Landsat",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-is-this-for",
    "href": "index.html#who-is-this-for",
    "title": "Manuel de formation MOSAIKS",
    "section": "Who is this for?",
    "text": "Who is this for?\nThis comprehensive two-week program is designed for academics, professionals, and practitioners interested in leveraging MOSAIKS to better understand socioeconomic and environmental challenges. The course is particularly valuable for those working in:\n\nRemote sensing and satellite imagery analysis\nMachine learning applications with geospatial data\nAgricultural and environmental monitoring and assessment\nDevelopment research and policy making",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-will-i-learn",
    "href": "index.html#what-will-i-learn",
    "title": "Manuel de formation MOSAIKS",
    "section": "What will I learn?",
    "text": "What will I learn?\nThroughout this course, you’ll learn practical applications through a combination of:\n\nTheoretical foundations and conceptual understanding\nHands-on exercises with real-world data\nBest practices for implementation\nStrategies for analyzing and interpreting results\n\nThe curriculum covers the complete MOSAIKS workflow, including:\n\nAccessing and processing satellite imagery\nUnderstanding MOSAIKS feature extraction\nWorking with the MOSAIKS API\nImplementing machine learning models\nQuantifying and communicating uncertainty\nApplying models to various contexts\nWorking with survey data\n\nWhether you’re new to MOSAIKS or looking to deepen your expertise, this course provides the tools and knowledge needed to effectively utilize this framework.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "Manuel de formation MOSAIKS",
    "section": "Course structure",
    "text": "Course structure\nThis course is designed as an intensive two-week program that combines lectures, demonstrations, and hands-on sessions. Each day is structured as follows:\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n9:00 - 10:30\nMorning Session 1\n\n\n10:30 - 11:00\nBreak\n\n\n11:00 - 12:30\nMorning Session 2\n\n\n12:30 - 1:30\nLunch\n\n\n1:30 - 3:00\nAfternoon Session 1\n\n\n3:00 - 3:30\nBreak\n\n\n3:30 - 4:30\nAfternoon Session 2\n\n\n4:30 - 5:00\nFeedback and Development\n\n\n\n\n\nTable 1: Daily time divisions showing 2 morning sessions, 2 afternoon sessions, and a final time slot alloted for developing the course further.\n\n\n\nEach day concludes with a Q&A and feedback session from 4:30-5:00, providing opportunities to clarify concepts and share ideas. It is expected that this first course will spur many new ideas and concepts which should be included in the future trainings. Please remember to take notes throughout each day with particular emphasis in areas you think could be explained better or that need additional topics covered. These can be areas that you struggled with or that you would anticipate could be difficult for others.\nWhile the in-person version of this course was designed with the schedule outlined above, other users can easily navigate throughout the course content as desired, noting that the chapter content is designed for sequential learning.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Manuel de formation MOSAIKS",
    "section": "Course schedule",
    "text": "Course schedule\n\nWeek 1\n\nDay 1: MOSAIKS framework, accessing features, basic workflow\nDay 2: Understanding ground truth data, data cleaning, spatial resolution\nDay 3: Agricultural yield prediction, downloading features via API\nDay 4: Types of satellite imagery, processing considerations, quality control\nDay 5: Feature computation, theory behind RCFs, hands-on implementation\n\n\n\nWeek 2\n\nDay 1: Martin Luther King Jr. Day - No Class\nDay 2: Model selection, hyperparameter tuning, cross-validation\nDay 3: Error analysis, confidence intervals, reporting uncertainty\nDay 4: Survey design principles, geolocation methods, sampling strategies\nDay 5: Advanced topics, emerging applications, future development",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#training-expectations",
    "href": "index.html#training-expectations",
    "title": "Manuel de formation MOSAIKS",
    "section": "Training expectations",
    "text": "Training expectations\n\nWhat you will learn\n\nUnderstanding of MOSAIKS framework and capabilities\nPractical skills in satellite imagery processing\n\nExperience with machine learning applications\nHands-on practice with real-world datasets\nKnowledge of survey data integration\nBest practices for model implementation\n\n\n\nPrerequisites\nThere are no explicit prerequisites, though this course does cover some advanced topics in:\n\nThe Python programming language\nMachine learning\nGeospatial data\n\n\n\nParticipant expectations\n\nActive participation in discussions and hands-on sessions\nCompletion of assigned homework (particularly the Week 1 Friday assignment)\n\nEngagement in Q&A sessions\nContribution to feedback sessions for course improvement\n\n\n\nComputing requirements\nThe course includes hands-on computing sessions. You will need:\n\nA computer with access to the internet\nA Google account\nAccess to Google Colaboratory\nAccess to necessary data (details to be provided)\n\n\n\nHomework and presentations\nThere will be a homework assignment at the end of Week 1, which participants will present on Tuesday of Week 2. This assignment is designed to reinforce learning and provide practical experience with MOSAIKS tools.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#book-structure-and-content",
    "href": "index.html#book-structure-and-content",
    "title": "Manuel de formation MOSAIKS",
    "section": "Book structure and content",
    "text": "Book structure and content\nThis manual is organized into six main parts, each focusing on a critical aspect of MOSAIKS. We begin with foundational concepts and gradually progress to more advanced topics in modeling and uncertainty quantification.\n\n\n\n\n\n\n\n\n\n\nPart\nDescription\n\n\n\n\nIntroduction\nComputing setup, MOSAIKS overview, API access, initial demonstration\n\n\nLabel data\nUnderstanding suitable labels, survey integration, data preparation\n\n\nSatellite imagery\nSelecting appropriate imagery, processing considerations\n\n\nFeatures\nRandom convolutional features, API access, feature computation\n\n\nTask modeling\nModel selection, spatial analysis, temporal considerations\n\n\nModel uncertainty\nUncertainty quantification, ethical considerations\n\n\n\n\n\nTable 2: Overview of the MOSAIKS Training Manual contents\n\n\n\nThe content is designed to be both comprehensive and practical, with each part building upon previous concepts while remaining relatively self-contained. This structure allows readers to either progress through the manual sequentially or focus on specific topics of interest. Throughout each section, we provide practical examples, code demonstrations, and best practices drawn from real-world applications.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Manuel de formation MOSAIKS",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMOSAIKS was developed and is supported by a large team of researchers across multiple partner organizations:\nDevelopment Team:\nBenjamin Recht, Cullen Molitor, Darin Christensen, Esther Rolf, Eugenio Noda, Grace Lewin, Graeme Blair, Hannah Druckenmiller, Hikari Murayama, Ian Bolliger, Jean Tseng, Jessica Katz, Jonathan Proctor, Juliet Cohen, Karena Yan, Luke Sherman, Miyabi Ishihara, Shopnavo Biswas, Simon Greenhill, Solomon Hsiang, Steven Cognac, Tamma Carleton, Taryn Fransen, Trinetta Chong, Vaishaal Shankar\nMOSAIKS Training Manual Team: Cullen Molitor, Tamma Carleton, Esther Rolf, Sean Luna McAdams, Heather Lahr\nPartner Organizations:\n\nCenter for Effective Global Action (CEGA; UCB)\nEnvironmental Markets Lab (emLab; UCSB)\nGlobal Policy Lab (GPL; Stanford University)\nProject on Resources and Governance (PRG; UCLA)\nMaster of Environmental Data Science Program (MEDS; UCSB)\n\nFunding Support:\n\nThe Patrick J. McGovern Foundation\nThe Fund for Innovation in Development (FID)\nThe United States Agency for International Development (USAID)\nUnited Nations Development Programme (UNDP)\n\nWe are grateful for the support and contributions of all team members and partner organizations in making MOSAIKS a reality. We hope to continue expanding the framework and its applications to address pressing global challenges.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the first part of this book, we will cover the basics of MOSAIKS, including its framework, capabilities, and practical applications. This section is focused on exploring the original MOSAIKS publication (Rolf et al. 2021) and understanding the core concepts behind the framework.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#quest-ce-que-mosaiks",
    "href": "index.html#quest-ce-que-mosaiks",
    "title": "Manuel de formation MOSAIKS",
    "section": "Qu’est-ce que MOSAIKS?",
    "text": "Qu’est-ce que MOSAIKS?\nMOSAIKS signifie Multi-task Observation using SAtellite Imagery & Kitchen Sinks, soit littéralement en français Observation multitâche à l’aide de l’imagerie satellitaire et des éviers de cuisine. Il s’agit d’un cadre conçu pour simplifier l’utilisation de l’imagerie satellite et de l’apprentissage automatique pour prédire les résultats socio-économiques et environnementaux dans différents contextes géographiques et périodes. MOSAIKS se base sur des filtres de convolutions aléatoires (développées dans Rahimi et RECHT (2008)) appliquées à l’imagerie satellite, qui extrait des features agnostiques des tâches et permettent aux chercheurs et aux praticiens de prédire facilement une diversité de résultats à partir d’images brutes.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#à-qui-sadresse-ce-livre",
    "href": "index.html#à-qui-sadresse-ce-livre",
    "title": "Manuel de formation MOSAIKS",
    "section": "À qui s’adresse ce livre?",
    "text": "À qui s’adresse ce livre?\nCe programme complet de deux semaines est conçu pour les universitaires, les professionnels et les praticiens intéressés à tirer parti des MOSAIKS pour mieux comprendre les défis socio-économiques et environnementaux. Le cours est particulièrement précieux pour ceux qui travaillent:\n\nAnalyse d’images satellitaires et télédétection\nApplications d’apprentissage automatique avec des données géospatiales\nSurveillance et évaluation de l’agriculture et de l’environnement\nRecherche et développement et élaboration des politiques",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#que-vais-je-apprendre",
    "href": "index.html#que-vais-je-apprendre",
    "title": "Manuel de formation MOSAIKS",
    "section": "Que vais-je apprendre?",
    "text": "Que vais-je apprendre?\nTout au long de ce cours, vous apprendrez des applications pratiques grâce à une combinaison de:\n\nFondements théoriques et compréhension conceptuelle\nExercices pratiques avec des données réelles\nMeilleures pratiques de mise en œuvre\nStratégies d’analyse et d’interprétation des résultats\n\nLe programme d’études couvre le flux de travail complet des MOSAIKS, notamment:\n\nAccéder et traiter des images satellites\nComprendre l’extraction des features MOSAIKS\nTravailler avec l’API MOSAIKS\nImplémenter des modèles d’apprentissage automatique\nQuantifier et communiquer l’incertitude\nAppliquer des modèles à divers contextes\nTravailler avec les données d’enquête\n\nQue vous soyez nouveau dans MOSAIKS ou que vous cherchiez à approfondir votre expertise, ce cours fournit les outils et les connaissances nécessaires pour utiliser efficacement ce framework.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#structure-de-cours",
    "href": "index.html#structure-de-cours",
    "title": "Manuel de formation MOSAIKS",
    "section": "Structure de cours",
    "text": "Structure de cours\nCe cours est conçu comme un programme intensif de deux semaines qui combine des conférences, des démonstrations et des séances pratiques.Chaque jour est structuré comme suit:\n\n\n\n\n\n\nHoraire\nActivité\n\n\n\n\n9h00 - 10h30\nSession du matin 1\n\n\n10h30 - 11h00\nPause\n\n\n11h00 - 12h30\nSession du matin 2\n\n\n12h30 - 13h30\nDéjeuner\n\n\n13h30 - 15h00\nSession de l’après-midi 1\n\n\n15h00 - 15h30\nPause\n\n\n15h30 - 16h30\nSession de l’après-midi 2\n\n\n16h30 - 17h00\nFeedback and Development\n\n\n\n\n\nTable 3: Divisions de temps quotidiennes montrant 2 séances du matin, 2 séances de l’après-midi et un dernier créneau horaire attribué pour développer le cours.\n\n\n\nChaque jour se termine par une séance de questions-réponses et une session de rétroaction de 16h30 à 17h00, offrant des opportunités de clarifier les concepts et de partager des idées. Il est prévu que ce premier cours stimulera de nombreuses nouvelles idées et concepts qui devraient être inclus dans les futures formations. N’oubliez pas de prendre des notes tout au long de chaque journée avec un accent particulier dans les domaines qui, selon vous, pourraient être mieux expliqués ou qui ont besoin de sujets supplémentaires couverts. Il peut s’agir de domaines avec lesquels vous avez des difficultés ou que vous anticipez pourraient être difficiles pour les autres.\nBien que la version en personne de ce cours ait été conçue avec le calendrier décrit ci-dessus, les autres utilisateurs peuvent facilement naviguer dans le contenu du cours comme il le souhaite. Notons que le contenu du chapitre est conçu pour l’apprentissage séquentiel.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#horaire-de-cours",
    "href": "index.html#horaire-de-cours",
    "title": "Manuel de formation MOSAIKS",
    "section": "Horaire de cours",
    "text": "Horaire de cours\n\nSemaine 1\n\nJour 1: Framework MOSAIKS, fonctionnalités d’accès, workflow de base\nJour 2: Comprendre les données de vérité au sol, le nettoyage des données, la résolution spatiale\nJour 3: Prédiction de rendement agricole, téléchargement des fonctionnalités via API\nJour 4: Types d’images satellites, considérations de traitement, contrôle de la qualité\nJour 5: Calcul des fonctionnalités, théorie derrière les RCF, implémentation pratique\n\n\n\nSemaine 2\n\nJour 1: Sélection du modèle, réglage de l’hyperparamètre, validation croisée\nJour 2: Analyse des erreurs, intervalles de confiance, rapport incertitude\nJour 3: Principes de conception de l’enquête, méthodes de géolocalisation, stratégies d’échantillonnage\nJour 4: Sujets avancés, applications émergentes, développement futur",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#attentes-de-la-formation",
    "href": "index.html#attentes-de-la-formation",
    "title": "Manuel de formation MOSAIKS",
    "section": "Attentes de la formation",
    "text": "Attentes de la formation\n\nCe que vous apprendrez\n\nCompréhension du framework et des capacités de MOSAIKS\nCompétences pratiques dans le traitement des images satellites\n\nExpérience avec les applications d’apprentissage automatique\nPratique avec des ensembles de données du monde réel\nConnaissance de l’intégration des données d’enquête/sondage\nMeilleures pratiques pour la mise en œuvre du modèle\n\n\n\nPrérequis\nIl n’y a pas de conditions préalables explicites. Toutefois pour les travaux pratiques une connaissance des outils suivants est nécessaire\n\nPython Langage de programmation\nJupyter Notebook Outil permettant d’exécuter le code Python de manière interactive.\n\nLe cours couvre également des sujets avancés tels que l’apprentissage automatique et les données géospatiales dont une connaissance préalable facilite la compréhension du contenu.\n\n\nAttentes des participants\n\nParticiper activement aux discussions et aux sessions pratiques\nFinir les devoirs attribués (en particulier la mission de la semaine 1 vendredi)\n\nS’engager dans les séances de questions-réponses\nContribuer aux séances de rétroaction pour l’amélioration des cours\n\n\n\nExigences informatiques\nLe cours comprend des séances informatiques pratiques.Vous aurez besoin:\n\nUn ordinateur avec accès à Internet\nUn compte Google\nAccès à Google Colab\nAccès aux données nécessaires (détails à fournir)\n\n\n\nDevoirs maison et présentations\nIl y aura un devoir-maison à la fin de la semaine 1, que les participants présenteront le lundi de la semaine 2. Ce travail est conçu pour renforcer l’apprentissage et offrir une expérience pratique avec les outils MOSAIKS.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#structure-et-contenu-du-livre",
    "href": "index.html#structure-et-contenu-du-livre",
    "title": "Manuel de formation MOSAIKS",
    "section": "Structure et contenu du livre",
    "text": "Structure et contenu du livre\nCe manuel est organisé en six parties principales, chacune se concentrant sur un aspect critique des MOSAIKS. Nous commençons par des concepts fondamentaux et progressons progressivement vers des sujets plus avancés dans la modélisation et la quantification de l’incertitude.\n\n\n\n\n\n\n\n\n\n\nPartie\nDescription\n\n\n\n\nIntroduction\nConfiguration de l’informatique, Présentation des MOSAIKS, accès API, démonstration initiale\n\n\nDonnées d’étiquette\nComprendre les étiquettes appropriées, l’intégration d’enquête, la préparation des données\n\n\nImagerie satellite\nSélection de l’imagerie appropriée, des considérations de traitement\n\n\nCaractéristiques\nCaractéristiques convolutionnelles aléatoires, accès API, calcul des fonctionnalités\n\n\nModélisation des tâches\nSélection du modèle, analyse spatiale, considérations temporelles\n\n\nIncertitude du modèle\nQuantification de l’incertitude, considérations éthiques\n\n\n\n\n\nTable 4: Présentation du contenu du manuel de formation des MOSAIKS\n\n\n\nLe contenu est conçu pour être à la fois complet et pratique, chaque partie s’appuyant sur les concepts précédents tout en restant relativement autonome. Cette structure permet aux lecteurs de progresser dans le manuel séquentiellement ou de se concentrer sur des sujets d’intérêt spécifiques. Tout au long de chaque section, nous fournissons des exemples pratiques, des démonstrations de code et des meilleures pratiques tirées des applications du monde réel.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Manuel de formation MOSAIKS",
    "section": "Remerciements",
    "text": "Remerciements\nMOSAIKS a été développé et est soutenu par une grande équipe de chercheurs dans plusieurs organisations partenaires:\nÉquipe de développement:\nBenjamin Recht, Cullen Molitor, Darin Christensen, Esther Rolf, Eugenio Noda, Grace Lewin, Graeme Blair, Hannah Druckenmiller, Hikari Murayama, Ian Bolliger, Jean Tseng, Jessica Katz, Jonathan Proctor, Juliet Cohen, Karena Yan, Luke Sherman, Miyabi Ishihara, Shopnavo Biswas, Simon Greenhill, Salomon Hsiang, Steven Cognac, Tamma Carleton, Taryn Fransen, Trinetta Chong, Vaishaal Shankar\nÉquipe du manuel de formation Mosaiks: Cullen Molitor, Tamma Carleton, Esther Rolf, Sean Luna McAdams, Heather Lahr, Gnouyaro Zissler Sougoyou, Farooq Sanni\nOrganisations partenaires:\n\nCenter for Effective Global Action (CEGA; UCB)\nEnvironmental Markets Lab (Emlab; UCSB)\nGlobal Policy Lab (GPL; Université de Stanford)\nProject on Resources and Governance (PRG; UCLA)\nMaster of Environmental Data Science Program (Meds; UCSB)\n\nFinancement:\n\nLa Fondation Patrick J. McGovern\nLe ​​Fonds pour l’innovation dans le développement (FID)\nThe United States Agency for International Development (USAID)\nProgramme des Nations Unies pour le développement (PNUD)\n\nNous sommes reconnaissants pour le soutien et les contributions de tous les membres de l’équipe et des organisations partenaires pour faire de MOSAIKS une réalité. Nous espérons continuer à étendre le cadre et ses applications pour relever des défis mondiaux pressants.\n\n\n\n\n\n\nDans la première partie de ce livre, nous couvrirons les bases de MOSAIKS, y compris son framework, ses capacités et ses applications pratiques. Cette section se concentre sur l’exploration de la publication originale de MOSAIKS (Rolf et al. 2021) et la compréhension des concepts de base derrière le framework.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "en/part-00-intro/00-intro.html",
    "href": "en/part-00-intro/00-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Overview\nThis section introduces the fundamental concepts of MOSAIKS (Multi-task Observation using Satellite Imagery & Kitchen Sinks) and provides practical guidance for getting started with the system. Whether you’re new to satellite imagery analysis or an experienced practitioner, understanding these foundations is crucial for effectively utilizing MOSAIKS in your work.\nMOSAIKS bridges the gap between the vast potential of satellite imagery and practical applications by providing:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/part-00-intro/00-intro.html#overview",
    "href": "en/part-00-intro/00-intro.html#overview",
    "title": "Introduction",
    "section": "",
    "text": "Accessible machine learning tools for non-experts\nComputationally efficient predictions\nFlexible applications across diverse tasks\nScalable solutions for global challenges",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/part-00-intro/00-intro.html#when-to-use-mosaiks",
    "href": "en/part-00-intro/00-intro.html#when-to-use-mosaiks",
    "title": "Introduction",
    "section": "When to use MOSAIKS",
    "text": "When to use MOSAIKS\nMOSAIKS is particularly valuable when you need to:\n\nGenerate predictions across large geographic areas\nWork with limited computational resources\nAnalyze multiple outcomes using the same imagery\nCreate predictions without deep learning expertise\nScale analysis from local to global applications\n\nHowever, MOSAIKS may not be the best choice when:\n\nYou need predictions at sub-kilometer resolution\nYour outcome requires specific spectral bands\nReal-time predictions are essential\nYour application requires interpretable features\n\n\n\n\n\n\n\nThere may be an existing tool that meets your needs. MOSAIKS is not the best choice for every application.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/part-00-intro/00-intro.html#section-outline",
    "href": "en/part-00-intro/00-intro.html#section-outline",
    "title": "Introduction",
    "section": "Section outline",
    "text": "Section outline\nThe following chapters will guide you through getting started with MOSAIKS:\n\n\n\n\n\n\n\n\nChapter\nKey Topics\n\n\n\n23  Configuration\nGoogle Colab, data management, implementation practices\n\n\n24  C’est quoi MOSAIKS?\nCore concepts, system architecture, capabilities\n\n\n25  Accéder à MOSAIKS\nAPI access, data products, authentication\n\n\n26  Essayer MOSAIKS\nBasic workflow, example analysis, common pitfalls\n\n\n\n\n\nTable 1: Outline of the introduction section\n\n\nThese chapters provide both theoretical understanding and practical skills needed to begin working with MOSAIKS. The focus is on making satellite-based prediction accessible while maintaining scientific rigor and computational efficiency.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll set up our computing environment using Google Colab. This course uses Colab to demonstrate various aspects of MOSAIKS, in a free and accessible environment.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html",
    "href": "en/part-00-intro/01-intro-compute.html",
    "title": "1  Compute setup",
    "section": "",
    "text": "1.1 Overview\nThis course primarily uses Google Colaboratory (Colab) for our computational needs. Colab is a free, cloud-based platform that allows you to write and execute Python code through your browser. It comes with many pre-installed libraries and provides free access to computing resources, including GPUs.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#requirements",
    "href": "en/part-00-intro/01-intro-compute.html#requirements",
    "title": "1  Compute setup",
    "section": "1.2 Requirements",
    "text": "1.2 Requirements\nTo participate in the coding portions of this course, you’ll need:\n\nA laptop or desktop computer\nA reliable internet connection\nA Google account (if you don’t have one, create one at accounts.google.com)\nA web browser (Chromium based browsers recommended)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#getting-started-with-google-colab",
    "href": "en/part-00-intro/01-intro-compute.html#getting-started-with-google-colab",
    "title": "1  Compute setup",
    "section": "1.3 Getting started with Google Colab",
    "text": "1.3 Getting started with Google Colab\n\n1.3.1 Accessing Colab\n\nGo to colab.research.google.com\nSign in with your Google account\nClick “New Notebook” to create your first Colab notebook\n\n\n\n1.3.2 Understanding the interface\nThe Colab interface is similar to Jupyter notebooks, with a few key components:\n\nMenu Bar: Contains options for File, Edit, View, Insert, Runtime, Tools, and Help.\nToolbar: Quick access to common actions like adding code/text cells.\nCell Area: Where you write and execute code or text.\nRuntime Status: Shows the state of your notebook’s connection to Google’s servers.\n\n\n\n1.3.3 Basic operations\n\nCreating Cells:\n\nCode cells: Click + Code. Supports Python or R code depending on the selected runtime\nText cells: Click + Text. Supports Markdown and HTML tags for documentation\n\nRunning Cells:\n\nClick the play button next to the cell or use Shift+Enter\nCan also select Runtime &gt; Run the focused cell (or another Run option) from the menu\n\n\n\n\n1.3.4 Important features\n\nRuntime Type:\n\nClick Runtime &gt; Change runtime type\nSelect Python 3 as the runtime\nFor GPU access: Change the hardware accelerator to one of the offered GPU types when needed\n\nFile Management:\n\nFiles uploaded to Colab are temporary and will be lost when the runtime disconnects\nConnect to Google Drive and save outputs there for persistent storage:\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nPackage Installation:\n\nInstall additional packages using:\n\ncondapip\n\n\n# Warning: using \"!conda install\" is not recommended. \n# As a general rule use the magic command \"%conda install\" instead.\n%conda install &lt;package_name&gt;\n\n\n# Warning: using \"!pip install\" is not recommended. \n# As a general rule use the magic command \"%pip install\" instead.\n%pip install &lt;package_name&gt;\n\n\n\n\n\n1.3.5 Best practices\n\nSave Your Work:\n\nThe links in this book will make a fresh copy of a notebook as they are saved on GitHub.\nTo save any changes you make, click File &gt; Save a copy in Drive\nDownload important notebooks locally as backups\n\nResource Management:\n\nClose unused notebooks to free up resources\nBe aware of idle timeouts (notebooks disconnect after extended inactivity)\n\nMemory Usage:\n\nMonitor memory usage through Runtime &gt; View resources\nThe free tier of Colab provides very limited memory (12GB) and may not be sufficient for large datasets or complex models\n\n\n\n\n1.3.6 Keyboard shortcuts\nHere are some useful keyboard shortcuts for working in Colab:\n\nWindows/LinuxMac\n\n\n\n\n\n\n\n\n\n\n\n\nShortcut\nAction\n\n\n\n\nCtrl+M H\nView keyboard shortcuts\n\n\nCtrl+Enter\nRun current cell\n\n\nShift+Enter\nRun cell and move to next\n\n\nAlt+Enter\nRun cell and insert below\n\n\nCtrl+M A\nInsert code cell above\n\n\nCtrl+M B\nInsert code cell below\n\n\nCtrl+M M\nConvert to text cell\n\n\nCtrl+M Y\nConvert to code cell\n\n\nCtrl+M D\nDelete current cell\n\n\nCtrl+M L\nToggle line numbers\n\n\nCtrl+M O\nToggle output\n\n\nCtrl+M X\nCut cell\n\n\nCtrl+M C\nCopy cell\n\n\nCtrl+M V\nPaste cell below\n\n\nShift+Up/Down\nSelect multiple cells\n\n\nCtrl+F\nFind and replace\n\n\nCtrl+S\nSave notebook\n\n\n\n\n\nTable 1.1: Windows/Linux keyboard shortcuts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShortcut\nAction\n\n\n\n\n⌘+M H\nView keyboard shortcuts\n\n\n⌘+Enter\nRun current cell\n\n\nShift+Enter\nRun cell and move to next\n\n\nOption+Enter\nRun cell and insert below\n\n\n⌘+M A\nInsert code cell above\n\n\n⌘+M B\nInsert code cell below\n\n\n⌘+M M\nConvert to text cell\n\n\n⌘+M Y\nConvert to code cell\n\n\n⌘+M D\nDelete current cell\n\n\n⌘+M L\nToggle line numbers\n\n\n⌘+M O\nToggle output\n\n\n⌘+M X\nCut cell\n\n\n⌘+M C\nCopy cell\n\n\n⌘+M V\nPaste cell below\n\n\nShift+Up/Down\nSelect multiple cells\n\n\n⌘+F\nFind and replace\n\n\n⌘+S\nSave notebook\n\n\n\n\n\nTable 1.2: Mac keyboard shortcuts\n\n\n\n\n\n\n\n\n1.3.7 Common issues and solutions\n\nRuntime Disconnections:\n\nClick “Reconnect” when prompted\nYour variables will be reset, but saved code remains\n\nPackage Installation Issues:\n\nRestart the runtime after installing new packages\nUse Runtime &gt; Restart runtime\n\nMemory Errors:\n\nClear unnecessary variables as you go\nConsider using smaller data samples during development\n\n\n\n\n\n\n\n\nMemory errors are common when working with large datasets or complex models on the free tier of Colab. If you encounter these issues, consider using a paid version of Colab or connecting a Google Cloud Platform virtual machine (VM).\n\n\n\n\n\n1.3.8 Getting help\n\nAccess Colab’s documentation: Help &gt; Frequently Asked Questions\nTry using Google Gemini for AI assistance.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#ai-assistance-in-colab",
    "href": "en/part-00-intro/01-intro-compute.html#ai-assistance-in-colab",
    "title": "1  Compute setup",
    "section": "1.4 AI assistance in Colab",
    "text": "1.4 AI assistance in Colab\nGoogle Gemini is a powerful AI assistant seamlessly integrated with Google Colab. You can use it to generate code, comments, or markdown text to improve your notebooks. Gemini can be accessed in several ways in Colab, all starting by selecting the Gemini icon in different parts of the notebook editor.\n\n\n\n\n\n\nGemini icon\n\n\n\n\nLook for this icon to indicate where you can click to access Gemini in Colab.\n\n\nHere are a few ways you can use Google Gemini effectively in Colab:\n\n1.4.1 Chat support\nClick the Gemini button in the top-right corner to open a chat interface where you can ask questions about your code, debug issues, or get explanations of concepts. This option is especially useful for beginners or for tackling complex problems.\n\n\n1.4.2 Code generation\nUse the “Generate code” option (the sparkle icon) above any empty code cell to generate new code based on your description. You can ask it to do many different things including:\n\nLoading a dataset called my_data.csv\nPlotting a histogram of the data\nBuilding a model to predict y from X\n\n\n\n1.4.3 Code explanation\nUse the “Explain code” option (the sparkle icon) above any complete code cell to open a chat interface that will automatically explain the code in the cell. This is useful for understanding code written by someone else, learning new concepts, or getting a second opinion on your work.\n\n\n1.4.4 Code completion\nColab provides intelligent autocomplete as you type:\n\nPress Tab to accept suggestions\nUse Ctrl+Space (Cmd+Space on Mac) to manually trigger suggestions\nGet real-time documentation and parameter hints\n\n\n\n\n\n\n\nWhile these AI tools are helpful, always review and understand the code they suggest before using it in your work.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#accessing-course-notebooks",
    "href": "en/part-00-intro/01-intro-compute.html#accessing-course-notebooks",
    "title": "1  Compute setup",
    "section": "1.5 Accessing course notebooks",
    "text": "1.5 Accessing course notebooks\nAll course notebooks are hosted on GitHub and can be accessed directly in Google Colab. There are two ways to open them:\n\n1.5.1 Method 1: Direct links\nEach section of this book includes direct “Open in Colab” links for relevant notebooks. Simply click the badge to open the notebook:\nExample \nThis method will open a fresh copy of the notebook as it is saved on GitHub. If you have already clicked the badge once, made changes, and saved your notebook, then you will need to navigate to your drive folder where it is saved to access those changes.\n\n\n\n\n\n\nClicking the badge in this book will always open a fresh copy.\n\n\n\n\n\n1.5.2 Method 2: Clone the notebook\nTo select a notebook from the repository Notebook repository:\n\nOpen Google Colab (colab.research.google.com)\nClick File &gt; Open Notebook\nSelect the GitHub tab\nEnter the repository URL: https://github.com/[username]/[repo] (UPDATE WITH REPO)\nSelect the notebook you want to open\n\n\n\n1.5.3 Saving your work\nWhen you open a notebook from GitHub in Colab, it creates a temporary copy. To save your work:\n\nClick File &gt; Save a copy in Drive\nThis creates your own editable copy in your Google Drive\nAll future changes will be saved to your copy\n\n\n\n1.5.4 Notebook organization\nThe course notebooks are organized into:\n\ndemos/: Complete demonstration notebooks\nexercises/: Interactive notebooks with exercises to complete\nsolutions/: Complete versions of exercise notebooks\n\nEach notebook includes:\n\nClear instructions and explanations in markdown cells\nCode cells with examples or exercises\nTO DO sections for exercises\nValidation cells to check your work",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#data-access-and-management",
    "href": "en/part-00-intro/01-intro-compute.html#data-access-and-management",
    "title": "1  Compute setup",
    "section": "1.6 Data access and management",
    "text": "1.6 Data access and management\nThere are several ways to access data in Colab notebooks. Here are the main approaches:\n\n1.6.1 Direct downloads\nFor data hosted on repositories like Zenodo, you can download directly using wget:\n# Download the data\n!wget https://zenodo.org/records/14040658/files/Data.zip\n\n# Unzip the data\n!unzip Data.zip\n\n\n1.6.2 Google Drive integration\n\n1.6.2.1 Mount Google Drive\nFor data stored in Google Drive:\n\nFirst, mount your Google Drive:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nAccess your data using the mounted path:\ndrive_path = \"/content/drive/MyDrive/&lt;project_folder&gt;\"\n\n\n\n1.6.2.2 Copy data to the VM (optional)\nFor better performance, make local copies of the data on the virtual machine (VM):\nimport os\nimport shutil\n\n# Create local directory\nlocal_dir = \"/content/data/\"\nos.makedirs(local_dir, exist_ok=True)\n\n# Copy data from Drive to VM\ndrive_data = os.path.join(drive_path, \"my_data\") \nshutil.copytree(drive_data, local_dir, dirs_exist_ok=True)\n\n\n\n\n\n\nRemember that the VM’s storage is temporary - files will be deleted when the runtime disconnects. Always keep a backup of your data in Drive or another permanent storage location.\n\n\n\n\n1.6.2.2.1 Why copy data to the VM?\nWhen working with data in Colab, copying files from Google Drive to the virtual machine (VM) can significantly improve performance:\n\nFaster Access: Reading directly from Google Drive requires data to be transferred over the network for each operation. Local VM storage provides much faster read/write speeds.\nReduced Latency: Network latency between Colab and Google Drive can slow down operations that require multiple data accesses. Local data eliminates this latency.\nMore Reliable: Network connectivity issues or Drive access problems won’t interrupt your analysis once data is copied locally.\nBetter for Iterative Processing: If your code needs to read the same data multiple times (like in machine learning training loops), local access is much more efficient.\n\nFor example, reading a 1 GB dataset from Drive might take 30 seconds, while reading from local VM storage could take just a few seconds. The time spent copying data once at the start of your session can save significant time during analysis. This is especially true in a notebook environment where a user may develop code that repeatedly accesses the same data files, but cannot store it all in memory (e.g., many image files).\n\n\n\n1.6.2.3 Save outputs to Google Drive\nTo save outputs or models to Google Drive:\n# Set the output directory\noutput_dir = \"/content/drive/MyDrive/project_folder/output\"\n\n# Save outputs\nshutil.copytree(local_output, output_dir, dirs_exist_ok=True)\nThis ensures that any work done in the notebook is saved to your Google Drive for future reference. If output files are not copied and remain in the VM, they will be lost when the runtime disconnects.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/01-intro-compute.html#local-environment-setup",
    "href": "en/part-00-intro/01-intro-compute.html#local-environment-setup",
    "title": "1  Compute setup",
    "section": "1.7 Local environment setup",
    "text": "1.7 Local environment setup\nWhile this book’s primary approach is to use Google Colab, some learners may prefer or need to run code locally. The book is largely setup to do this, though the user will need to manage their own computing environment. For that purpose, we provide an environment.yml file (located in the environment directory of this book). Below are the steps to get you set up with Miniconda and create a local environment.\n\n\n\n\n\n\nThough local environments can offer more control, we strongly recommend Google Colab for consistency and free cloud-based resources. This local setup is purely optional and might be more suitable for those with particular dependencies or advanced setups.\n\n\n\n\n1.7.1 Downloading and installing Miniconda\nMiniconda is a minimal installer for conda. Choose the installer for your operating system from the links below and follow the prompts.\n\nWindowsmacOSLinux\n\n\n\nGo to the Miniconda Windows Installer.\nDownload the .exe installer for your Windows system (64-bit recommended).\nDouble-click the installer and follow the on-screen instructions.\nWhen prompted, check the option to Add Miniconda to PATH or select “Install for All Users” which typically adds conda to PATH automatically.\n\n\n\n\nGo to the Miniconda macOS Installer.\nDownload the .pkg (or .sh if you prefer) installer for macOS (64-bit).\nDouble-click the installer and follow the on-screen instructions.\nWhen prompted, check the option to Add Miniconda to PATH or add the appropriate path lines to your ~/.zshrc or ~/.bash_profile file manually.\n\n\n\n\nGo to the Miniconda Linux Installer.\nDownload the .sh installer for your Linux distribution (64-bit recommended).\nOpen a terminal and run bash Miniconda3-latest-Linux-x86_64.sh.\nFollow the prompts; consider allowing the installer to initialize Miniconda for your shell (adding conda to your PATH).\n\n\n\n\n\n\n1.7.2 Adding conda to your PATH\nIf you did not add conda to your PATH during installation, you can manually do so by adding a line to your shell configuration file (~/.bashrc, ~/.zshrc, or similar):\n# Example for Linux/macOS users\nexport PATH=\"$HOME/miniconda3/bin:$PATH\"\nFor Windows, ensure that you selected the option to add conda to PATH during installation, or run the Anaconda Prompt (which automatically has conda available) to manage your environment.\n\n\n1.7.3 Creating a local environment from environment.yml\nIn the environment directory of the course repository, you will find a file named environment.yml. This file lists all the packages needed for the local setup.\n\nClone or download the book repository to your local machine.\nOpen a terminal (or Anaconda Prompt on Windows).\nNavigate to the folder containing environment.yml.\ncd path/to/MOSAIKS-Training-Manual/environment\nCreate the environment:\nconda env create -f environment.yml\nActivate the environment:\nconda activate &lt;environment_name&gt;\nWhere &lt;environment_name&gt; is the name specified in environment.yml (check the name: field in the file). In this case the name is mosaiks.\n\n\n\n1.7.4 Using the new environment in VS Code\nVisual Studio Code (VS Code) can detect and use your new conda environment for Python development.\n\nOpen VS Code.\nInstall the Python extension (if not already installed).\nPress Ctrl+Shift+P (or Cmd+Shift+P on macOS) and type “Python: Select Interpreter”.\nSelect the interpreter associated with your newly created environment (it should be listed by name or path).\nOpen or create a new Python file or notebook, and verify that VS Code is using the correct environment (you can see the chosen environment in the bottom-right corner of VS Code).\n\n\n\n1.7.5 Other environment managers\nWhile conda is a common tool for managing Python environments, there are other popular options such as:\n\nPoetry\n\npipenv\n\nvirtualenv\n\nEach has its own configuration files and setup instructions. If you prefer these tools or already use them, you can typically replicate the packages listed in environment.yml. Check the respective tool’s documentation for specific instructions on how to translate the dependencies.\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we will take a closer look at the MOSAIKS framework, its core concepts, and how it can be applied to solve real-world problems.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Compute setup</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html",
    "href": "en/part-00-intro/02-intro-mosaiks.html",
    "title": "2  What is MOSAIKS?",
    "section": "",
    "text": "2.1 The challenge\nRight now, numerous public satellite systems collect huge amounts of data about the world every day. But there is so much imagery (terabytes per day) that it’s overwhelming to sort through by hand; and it’s too complex and unstructured to be usable in its raw form for most applications.\nThat is why linking satellite imaging to machine learning (sometimes referred to as SIML or SatML) is incredibly powerful. It enables vast amounts of unstructured image data to be transformed into structured information that can be used for planning, research, and decision-making.\nOur hope is that people all over the world can access and use SIML technologies, but we recognize that many who would benefit from these tools don’t have the time or resources to manage enormous satellite imagery data sets and learn how to apply machine learning to them.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#the-challenge",
    "href": "en/part-00-intro/02-intro-mosaiks.html#the-challenge",
    "title": "2  What is MOSAIKS?",
    "section": "",
    "text": "Figure 2.1: Visual representation of satellites orbiting earth.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#the-solution",
    "href": "en/part-00-intro/02-intro-mosaiks.html#the-solution",
    "title": "2  What is MOSAIKS?",
    "section": "2.2 The solution",
    "text": "2.2 The solution\nThat’s why we developed MOSAIKS. MOSAIKS aims to lower the barriers to entry into SIML, diversifying the users of this powerful technology and the problems we solve with it.\nMOSAIKS is designed to work “out of the box” for a wide array of SIML applications, for people with no SIML expertise who work on normal desktop or laptop computers. For many applications, MOSAIKS users never have to touch satellite imagery themselves and only need to have basic statistical training.\n\nIf you can run a regression, you can use MOSAIKS!\n\nMOSAIKS empowers users to create their own new datasets from satellite imagery. We don’t control what variables users look at, and we never need to know. MOSAIKS is a system that allows users to quickly transform vast amounts of imagery into maps of new variables, using their own training data.\nIf you’ve ever been curious about trying machine learning with satellite imagery, but don’t know anything about machine learning or satellite imagery, MOSAIKS is for you.\nAnd if you know a lot about machine learning and satellite imagery, MOSAIKS might still be for you, since it performs competitively with deep learning methods but is much simpler and cheaper to use.\n\n\n\n\n\n\n\n\nFigure 2.2: Traditional framework of deep learning models (i.e., machine learning with artificial neural networks) applied to imagery. In this example, the model is attempting to classify what vehicle the image contains.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#how-mosaiks-works",
    "href": "en/part-00-intro/02-intro-mosaiks.html#how-mosaiks-works",
    "title": "2  What is MOSAIKS?",
    "section": "2.3 How MOSAIKS works",
    "text": "2.3 How MOSAIKS works\n\n\n\n\n\n\nRecommended reading\n\n\n\nA generalizable and accessible approach to machine learning with global satellite imagery (Rolf et al. 2021)\n\n\n\n2.3.1 Separating users from imagery\nThe basic idea of MOSAIKS is to separate users from the costly and difficult process of transforming imagery into inputs (called “features”) to a downstream machine learning algorithm (images → X). The MOSAIKS team has computed these features globally, so in many use cases users never have to download or manage imagery themselves. Instead, users download a table of MOSAIKS features (X), link them to their own geocoded data on the outcome (Y) they are interested in predicting from satellite imagery (we call these data “labels”), and then run a linear regression (or something fancier if desired!) to predict their labels using MOSAIKS features (Y = Xβ). Importantly, this prediction can be performed in locations, time periods, and at spatial resolutions for which labels are not available.\n\n\n\n  \n\n\nFigure 2.3: This false-color image shows snow-capped peaks and ridges of the eastern Himalayas between major rivers in southwest China. The Himalayas are made up of three parallel mountain ranges that together stretch for more than 1800 miles (2,900 kilometers). This particular image was taken by NASA’s Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), flying aboard the Terra satellite, on February 27, 2002. The picture is a composite made by combining near-infrared, red and green wavelengths. (Source: NASA)\n\n\n\n\n\n2.3.2 Generalizability of MOSAIKS\nBecause MOSAIKS features synthesize information contained in raw imagery that is not tailored for any specific outcome (e.g., biodiversity, household income, land use), many users can use the same MOSAIKS features and simply match them to their own labels based on location. Users can run their analysis on any statistical software they are comfortable with. For most applications, the computing demands will not require users to work with specialized machines, since desktops and laptops work.\n\n\n\n\n\n\nFigure 2.4: MOSAIKS is designed to solve an unlimited number of tasks at planet-scale quickly. After a one-time unsupervised image featurization using random convolutional features, MOSAIKS centrally stores and distributes task-agnostic features to users, each of whom generates predictions in a new context. A Satellite imagery is shared across multiple potential tasks. B Schematic of the MOSAIKS process. N images are transformed using random convolutional features into a compressed and highly descriptive K-dimensional feature vector before labels are known. Once features are computed, they can be stored in tabular form (matrix X) and used for unlimited tasks without recomputation. Users interested in a new task (s) merge their own labels (ys) to features for training. Here, user 1 has forest cover labels for locations p + 1 to N and user 2 has population density labels for locations 1 to q. Each user then solves a single linear regression for βs. Linear prediction using βs and the full sample of MOSAIKS features X then generates SIML estimates for label values at all locations. Generalizability allows different users to solve different tasks using an identical procedure and the same table of features—differing only in the user-supplied label data for training. Each task can be solved by a user on a desktop computer in minutes without users ever manipulating the imagery. C Illustration of the one-time unsupervised computation of random convolutional features. K patches are randomly sampled from across the N images. Each patch is convolved over each image, generating a nonlinear activation map for each patch. Activation maps are averaged over pixels to generate a single K-dimensional feature vector for each image. (Source: Rolf et al. 2021 Figure 1)\n\n\n\n\n\n2.3.3 Why it works\nMOSAIKS works because MOSAIKS features capture a huge amount of information about the colors, patterns and textures that show up in satellite imagery. We don’t know what patterns/colors/textures will be important for the application that users have (since we don’t know what applications users will try), so we just try to capture all of them. The purpose of the regression step is to teach the model which patterns/colors/textures predict the labels, and then to use that understanding to make predictions in locations where users don’t have labels. In addition, MOSAIKS encodes image information in a way that allows for nonlinear relationships between labels and imagery data, even though the regression that users generally implement is a linear regression.\n\n\n\n\n\n\nFigure 2.5: Example of 4 (of 4,000) MOSAIKS feature maps (right) computed from satellite imagery (left). These features were chosen at random from what is available on the MOSAIKS API.\n\n\n\nFor learn more about these features, see Chapter 34 where we attempt to provide intuition for what a feature is and how it is made.\n\n\n2.3.4 Five steps to using MOSAIKS\n\n\n\n\n\n\nThis section is a very broad overview of the steps to use MOSAIKS. Later chapters will provide more detailed guidance on each step.\n\n\n\nIn many cases, users aiming to predict an outcome from satellite imagery can do so using pre-computed imagery features (X) in a simple linear regression framework. Later in this training course, we will detail more customized workflows that remain tractable but allow for more flexibility. In the standard case, however, the procedure for using MOSAIKS has five steps (corresponding figure from Rolf et al. is below):\n\nDownload pre-computed MOSAIKS features (X) corresponding to the locations where you have labels (Chapter 25).\nMerge the features with your labels (Y) based on location (so features at position P are linked to labels at position P) (Chapter 29).\nRun a cross-validated ridge regression of your labels on the MOSAIKS features (Y = Xβ + e; or any other model you choose! See Chapter 38).\nEvaluate performance.\nUse the results of the regression model (β) to make predictions (Xβ) in a new region of interest where you do not have labels, using only the MOSAIKS features (X) that correspond with those new locations.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#what-can-mosaiks-predict",
    "href": "en/part-00-intro/02-intro-mosaiks.html#what-can-mosaiks-predict",
    "title": "2  What is MOSAIKS?",
    "section": "2.4 What can MOSAIKS predict?",
    "text": "2.4 What can MOSAIKS predict?\n\n\n\n\n\n\nThis question is answered in greater detail in Chapter 27\n\n\n\nMOSAIKS has been successfully used to predict a wide range of outcomes including:\n\nEnvironmental conditions (forest cover, elevation)\nPopulation patterns (density, nighttime lights)\nEconomic indicators (income, house prices)\nInfrastructure (road networks)\n\nThe figure below is from the original MOSAIKS publication (Rolf et al. 2021). The left maps show the input labels. The right map shows the modeled predictions. The scatter plot shows the modeled predictions against the true labels and reports the coefficient of determination (R²) as a measure of performance.\n\n\n\n\n\n\nFigure 2.6: (100,000 daytime images were each converted to 8,192 features and stored. Seven tasks were then selected based on coverage and diversity. Predictions were generated for each task using the same procedure. Left maps: 80,000 observations used for training and validation, aggregated up to 20 km × 20 km cells for display. Right maps: concatenated validation set estimates from 5-fold cross-validation for the same 80,000 grid cells (observations are never used to generate their own prediction), identically aggregated for display. Scatters: Validation set estimates (vertical axis) vs. ground truth (horizontal axis); each point is a ~1 km × 1 km grid cell. Black line is at 45∘. Test-set and validation set performance are essentially identical; validation set values are shown for display purposes only, as there are more observations. The tasks in the top three rows are uniformly sampled across space, the tasks in the bottom four rows are sampled using population weights; grey areas were not sampled in the experiment. Source: Rolf et al. 2021 Figure 2)\n\n\n\nImportantly, all these predictions use the same set of satellite features - there’s no need to reprocess the imagery for different tasks. MOSAIKS achieves accuracy comparable to more complex deep learning methods, but at a fraction of the computational cost. This is the power of MOSAIKS, it removes the need for reprocessing the imagery after the initial encoding.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#is-mosaiks-always-the-best-choice",
    "href": "en/part-00-intro/02-intro-mosaiks.html#is-mosaiks-always-the-best-choice",
    "title": "2  What is MOSAIKS?",
    "section": "2.5 Is MOSAIKS always the best choice?",
    "text": "2.5 Is MOSAIKS always the best choice?\nNo! MOSAIKS is a powerful tool, but it is not always the best choice for every application. In fact, it is usually not the “best” choice for any application. We aim to be competitive with leading models, so the true benefit of MOSAIKS is in its simplicity, accessibility, and scalability for the average user.\nWe recommend that you start by searching for existing methods developed for your application, before investing time and resources into MOSAIKS. An excellent place to begin this search is at satellite-image-deep-learning where you can find a list of deep learning methods that have been developed for satellite imagery, as well as existing datasets, tools, and tutorials.\nThe world of SIML is vast and rapidly evolving. This means there is a good choice you do not have to make global scale predictions yourself. Instead, you might be able to use or build off the hard work of many others in the field.\nIf you have a specific context where you want tailored information or a variable/outcome no one else has predicted before, then you want MOSAIKS. Not only will MOSAIKS allow you to make predictions in a new context, but it will also allow you to do so quickly and with minimal computational resources.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#lecture-materials",
    "href": "en/part-00-intro/02-intro-mosaiks.html#lecture-materials",
    "title": "2  What is MOSAIKS?",
    "section": "2.6 Lecture materials",
    "text": "2.6 Lecture materials\nTODO: Add recorded lecture here.\nLecture slides.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/02-intro-mosaiks.html#summary",
    "href": "en/part-00-intro/02-intro-mosaiks.html#summary",
    "title": "2  What is MOSAIKS?",
    "section": "2.7 Summary",
    "text": "2.7 Summary\nMOSAIKS is a powerful tool that allows users to predict a wide range of outcomes from satellite imagery using pre-computed features. The system is designed to be accessible to users with no prior experience in machine learning or satellite imagery. The MOSAIKS framework involves five simple steps\n\nDownload features\nMerge with labels\nrun a regression\nEvaluate performance\nMake predictions\n\nIn this book we will explore all the ways in which this is an oversimplification. You will learn to adapt this framework to your own needs, and to understand the limitations and assumptions of the MOSAIKS system. Many skills presented in this training manual will be applicable to other satellite imagery and machine learning workflows.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, you will be introduced to the MOSAIKS API which is a free and open resource for accessing pre-computed MOSAIKS features.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/03-intro-api.html",
    "href": "en/part-00-intro/03-intro-api.html",
    "title": "3  Access MOSAIKS",
    "section": "",
    "text": "3.1 Introduction\nAt its core, MOSAIKS requires two main inputs: satellite features and ground truth data. Our aim is to make these features as accessible as possible so that the majority of users do not have to worry about the technical details of satellite imagery processing.\nTo this end, we have worked to develop multiple ways to access MOSAIKS features:\nThe MOSAIKS API should be considered the primary way to access features. It is a user-friendly interface that allows you to download features for any location on Earth. The API is designed to be accessible to users with a range of technical backgrounds, from beginners to experts. For more details on what features are available on the API, see Chapter 35.\nHowever, there are many settings where users will want or need to compute their own customized features. Chapter 36 guides readers through this process.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Access MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/03-intro-api.html#introduction",
    "href": "en/part-00-intro/03-intro-api.html#introduction",
    "title": "3  Access MOSAIKS",
    "section": "",
    "text": "Option\nImagery Source\nSpatial Coverage\nSpatial Resolution\nTemporal Resolution\nWeighting\n\n\n\nMOSAIKS API\nPlanet Labs Visual Basemap\nGlobal land areas\n0.01°\n2019 Q3\nUnweighted\n\n\nMOSAIKS API\nPlanet Labs Visual Basemap\nGlobal land areas\n0.1°, 1°\n2019 Q3\nArea & population\n\n\nMOSAIKS API\nPlanet Labs Visual Basemap\nGlobal land areas\nADM0, ADM1, ADM2\n2019 Q3\nArea & population\n\n\nRolf et al 2021\nGoogle Static Maps\nContinental United States (~100k locations)\n0.01°\n2019\nunweighted\n\n\nChapter 36\nAny - see Chapter 31\n\nUser-defined\nUser-defined\nUser-defined\nUser-defined\n\n\n\n\n\nTable 3.1: Summary of MOSAIKS feature sources. The weighting column indicates that the features were generated at 0.01 degree resolution and are weighted when they are aggregated up to lower resolutions. The available weighting schemes are based on area of the aggregation polygon, or by the population of the the aggregation polygon.\n\n\n\n\n\n\n\n\n\nChapters 23 through 8 focus on publicly available features\nChapters 31 through 37 cover computing custom features from imagery",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Access MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/03-intro-api.html#mosaiks-api",
    "href": "en/part-00-intro/03-intro-api.html#mosaiks-api",
    "title": "3  Access MOSAIKS",
    "section": "\n3.2 MOSAIKS API",
    "text": "3.2 MOSAIKS API\n\n\n\n\n\n\nMOSAIKS API Link\n\n\n\napi.mosaiks.org\n\n\nThe MOSAIKS API is a user-friendly interface that allows you to download features for any land location on Earth. The API is designed to be accessible to users with a range of technical backgrounds, from beginners to experts. To take advantage of the API, you will need to register for an account.\n\n3.2.1 Register for an account\nVisit api.mosaiks.org.\n\n\n\n\n\nFigure 3.1: Login page for the MOSAIKS API.\n\n\nSelect Register to create an account. You will need to provide a username, an email, and a password.\n\n\n\n\n\nFigure 3.2: Registration page for the MOSAIKS API.\n\n\nOnce registered, you can log in to begin downloading MOSAIKS features.\n\n\n\n\n\nFigure 3.3: MOSAIKS API landing page.\n\n\n\n3.2.2 API resources\nFrom the landing page, you can read additional information about MOSAIKS and access resources to help you get started.\n\n\n\n\n\n\nThis book is developed to provide you with all the information you need to use MOSAIKS.\n\n\n\nThe API contains the following pages:\n\n\n\n\n\n\n\n\nPage\nDescription\n\n\n\nHome\nLanding page for the API. Contains general information about using MOSAIKS and the API\n\n\nPrecomputed Files\nPrecomputed features at administrative boundary scales\n\n\nHDI\nGlobal Human Development Index (HDI) estimates at the municipality and grid levels\n\n\nGlobal Grids\nPrecomputed and area or population features at 0.1° and 1° resolution\n\n\nMap Query\nPrecomputed features at 0.01 degree resolution, user defines bounding box over area of interest\n\n\nFile Query\nPrecomputed features at 0.01 degree resolution, user uploads file with latitude and longitude coordinates\n\n\nMy Files\nFiles you have queried from the API, available to download\n\n\nResources\nExample Python and R notebooks for using the MOSAIKS framework\n\n\n\n\n\nTable 3.2: MOSAIKS API pages and descriptions.\n\n\n\n3.2.3 API features\nCurrently the MOSAIKS API has a single set of global features (with several aggregation levels). The features are freely available to the public for download; this is the fastest and easiest way to begin using MOSAIKS.\nThe API features use input imagery from Planet Labs, Inc. Visual Basemap Global Quarterly 2019 (quarter 3) product. Image quality, and therefore feature quality, may be affected by local conditions. For example, an area undergoing a rainy season in the third quarter (July to September), is likely to contain image artifacts from cloud cover. This will in turn effect the feature calculations. For more details on the input imagery Chapter 31.\nGiven the static nature of the API, the easiest way to get started with MOSAIKS is to have label data for a recent time period (ideally from 2019 for fast changing labels, or a close year for more steady labels).\n\n\n\n\n\nFigure 3.4: Planet Labs basemap imagery (left) and 4 of 4,000 MOSAIKS features downloaded from the API (right).\n\n\n\n\n\n\n\n\nUsing MOSAIKS for time series data is possible and can work well, however this currently requires computing your own custom features. See Chapter 36 and Chapter 40 for more information.\n\n\n\nThe MOSAIKS features are created using a 0.01 x 0.01 degree latitude-longitude global land grid. These are the native features available for download from the API, but it also offers pre-aggregated features at 0.1 and 1 degree resolution, as well as administrative boundaries (ADM0, ADM1, and ADM2).\n\n\n3.2.4 High resolution features\nThe file query and map query are the two methods to obtain the high resolution (0.01 degree) features through the API. For simplicity, we store these features in a tabular format with latitude and longitude coordinates. These coordinates are the center of each grid cell.\nWhen you download the high resolution features (0.01 degree), you will receive them in a tabular .csv format where:\n\nEach row (N) represents a unique grid cell\nThe first two columns contain latitude and longitude coordinates (grid centroids)\nThe remaining columns represent K features (currently K = 4000 features)\n\n\nNote: There is a limit of N = 100,000 records per query\n\n\n3.2.4.1 Map query\n\nCreate rectangular boxes by specifying latitude and longitude coordinates\nMultiple boxes can be created\nThe system displays an estimated number of records for each box\nNote that estimates are based on box area and may not reflect actual record numbers, especially for areas containing seas and oceans\n\n\n\n\n\n\nFigure 3.5: MOSAIKS API Map Query page.\n\n\n\n\n\n\n\n\nUse geojson.io to find the bounding box coordinates for your area of interest.\n\n\n\n\n3.2.4.2 File query\n\nSubmit a file with custom latitude and longitude coordinates\nThe API returns features for grid cells closest to your input coordinates\nPoints are allocated to the nearest grid point if they don’t exactly match\nThe output file may have a different number of rows than your input\nPoint ordering may change in the output\n\n\n\n\n\n\nFigure 3.6: API File Query\n\n\n\n3.2.5 Aggregated features\nMany users may find it easier to work with features aggregated to some level. The MOSAIKS API offers pre-aggregated features to accommodate these needs. The API offers several levels, including larger grid cells (0.1 and 1 degree) or summarized to administrative boundaries (ADM0, ADM1, and ADM2). These files are available for download as either single or chunked files depending on the resolution.\n\n\n\n\n\nFigure 3.7: Example showing of 3 representative random convolutional features (rows). Features are downloaded from the MOSAIKS API at 0.01° resolution (the native resolution) and aggregated to 3 levels, including (A) larger grid cells (0.1°), (B) counties, and (C) states.\n\n\n\n3.2.5.1 Weighting schemes\nAt each level of aggregation, we offer area weighted features and population weighted features. Population weights are from the Gridded Population of the World (GPWv4) population density dataset. The area weighting scheme is based on the area of the high resolution grid cells.\n\n3.2.5.2 When to use aggregated features\nThe aggregated features are particularly useful in a few scenarios:\n\nYou have data at a scale larger than the 0.01 degree grid cells. Many datasets come at the country, state, or county level.\nYour data has a lot of noise that can be smoothed out by aggregating to a larger scale. A common example of this might be household survey data that is noisy at the individual level but smooths out when aggregated to the village or district level.\nYou want to do global analysis and don’t have the computational resources to work with the full 0.01 degree grid cells.\n\nIn all cases using the pre-aggregated features can save you time and computational resources.\n\nScenario: You are working with a Living Standards Measurement Study - Integrated Surveys on Agriculture (LSMS-ISA). This dataset has survey data with geographic coordinates at the household level. To protect, the privacy of the respondents, the data is jittered within a 5 km radius but it always remains within local administrative boundaries. You can therefore summarize your labels to the administrative units and build a model with the aggregated features.\n\n\n\n\n\n\n\nIf you want to make high resolution predictions, with low resolution label data, you can build your model with aggregated features and use the high resolution features to make predictions. This will be covered in Chapter 39.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Access MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/03-intro-api.html#using-mosaiks-features-for-prediction",
    "href": "en/part-00-intro/03-intro-api.html#using-mosaiks-features-for-prediction",
    "title": "3  Access MOSAIKS",
    "section": "\n3.3 Using MOSAIKS features for prediction",
    "text": "3.3 Using MOSAIKS features for prediction\n\n\n\n\n\n\nThis is a brief overview. Detailed instructions appear later in the manual (Chapter 38).\n\n\n\nBasic workflow:\n\nObtain ground truth measurements (“labels”; see Chapter 27)\nDownload matching features (see Chapter 35 for more details).\nSpatially merge labels and features (see Chapter 29)\nUse regression to model relationship between imagery and outcome (see Chapter 38)\nUse regression results to predict outcome in new locations (see Chapter 38)\n\nYou can experiment with various machine learning approaches in the regression step. For beginners, we recommend starting with our example Jupyter notebook (Chapter 26) that demonstrates a simple ridge regression approach (suitable for both R and Python users).\n\n\n\n\n\nFigure 3.8: Using MOSAIKS, a simplified workflow design.\n\n\nThis topic will be covered in greater depth in later chapters (see Chapter 38). In the next chapter, you will see a simple MOSAIKS workflow which replicates the results of Rolf et al. 2021.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Access MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/03-intro-api.html#citation-requirements",
    "href": "en/part-00-intro/03-intro-api.html#citation-requirements",
    "title": "3  Access MOSAIKS",
    "section": "\n3.4 Citation requirements",
    "text": "3.4 Citation requirements\nWhen referring to the MOSAIKS methodology or when generating MOSAIKS features, please reference: Rolf et al. “A generalizable and accessible approach to machine learning with global satellite imagery.” Nature Communications (2021).\nYou can use the following Bibtex:\n@article{article,\n    author = {Rolf, Esther and Proctor, Jonathan and Carleton, Tamma and Bolliger, Ian and Shankar, Vaishaal and Ishihara, Miyabi and Recht, Benjamin and Hsiang, Solomon},\n    year = {2021},\n    month = {07},\n    pages = {},\n    title = {A generalizable and accessible approach to machine learning with global satellite imagery},\n    volume = {12},\n    journal = {Nature Communications},\n    doi = {10.1038/s41467-021-24638-z}\n}\nIf using features downloaded from the API, please reference, in addition to the publication above, the MOSAIKS API.\nYou can cite the API using the following Bibtex:\n @misc{MOSAIKS API,\n    author = {{Carleton, Tamma and Chong, Trinetta and Druckenmiller, Hannah and Noda, Eugenio and Proctor, Jonathan and Rolf, Esther and Hsiang, Solomon}},\n    title = {{Multi-Task Observation Using Satellite Imagery and Kitchen Sinks (MOSAIKS) API}},\n    howpublished = \"\\url{ https://api.mosaiks.org }\",\n    version = {1.0},\n    year = {2022},\n}\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter you will have a chance to try MOSAIKS on Google Colab with the data from Rolf et al 2021.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Access MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html",
    "href": "en/part-00-intro/04-intro-demo.html",
    "title": "4  Try MOSAIKS",
    "section": "",
    "text": "4.1 Overview\nThis demo replicates key results from the original MOSAIKS publication (Rolf et al. 2021). While MOSAIKS has great potential to improve access to satellite-based prediction in data-sparse environments, the original paper focused on demonstrating performance in the United States where high-quality training data was readily available.\nThe US served as an ideal testing ground for several reasons:\nThis validation in a data-rich environment was crucial for establishing MOSAIKS as a reliable tool before deploying it in contexts where ground truth data is scarce or unreliable.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html#overview",
    "href": "en/part-00-intro/04-intro-demo.html#overview",
    "title": "4  Try MOSAIKS",
    "section": "",
    "text": "Extensive ground truth data available across multiple variables\nReliable spatial referencing of data\nDiverse landscapes and built environments\nAbility to benchmark against existing methods\nSystematic validation of predictions",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html#demonstration-code",
    "href": "en/part-00-intro/04-intro-demo.html#demonstration-code",
    "title": "4  Try MOSAIKS",
    "section": "\n4.2 Demonstration code",
    "text": "4.2 Demonstration code\n\n4.2.1 Workflow\nBelow is a link to a Jupyter notebook intended to demonstrate practical use of MOSAIKS with real data. In fact, this notebook uses the original input data and features from Rolf et al. 2021. The code demonstrates:\n\nLoading pre-computed MOSAIKS features and labels\nMerging the features and labels\nTraining a ridge regression model\nEvaluating predictions\nVisualizing results\n\n4.2.2 Label data\nThe demo showcases MOSAIKS predicting several variables, and with a subset of the data used in, the original paper. The variables include:\n\n\nForest Cover\nElevation\nPopulation Density\nNighttime Lights\nIncome\nRoad Length\n\n\n\n\n\n\n\n\nFigure 4.1: Forest cover input data (left) from Global Land Analysis & Discover (GLAD) Global 2010 Tree Cover (30 m)\n\n\n\n\n\n\n\n\n\nFigure 4.2: Elevation input data (left) provided by Mapzen, and accessed via the Amazon Web Services (AWS) Terrain Tile service. Download code can be found here.\n\n\n\n\n\n\n\n\n\nFigure 4.3: Population density input data (left) from the Gridded Population of the World (GPW) dataset. These data can be accessed here.\n\n\n\n\n\n\n\n\n\nFigure 4.4: Nighttime lights luminosity input data (left) generated from nighttime satellite imagery, which is provided by the Earth Observations Group at the National Oceanic and Atmospheric Administration (NOAA) and the National Geophysical Data Center (NGDC). These data can be accessed here.\n\n\n\n\n\n\n\n\n\nFigure 4.5: Income input data (left) from the American Community Survey (ACS) 5-year estimates of median annual household income in 2015. These data are accessible using the acs package in R (48), table number B19013\n\n\n\n\n\n\n\n\n\nFigure 4.6: Road length input data (left) from the United States Geological Survey (USGS) National Transportation Dataset, which is based on TIGER/Line data provided by US Census Bureau in 2016. These data can be accessed here.\n\n\n\n\n\nA user simply needs to select which variable they would like to predict, and no other changes need to be made to the code. All data has been preprocessed and the code will download the necessary files from Zenodo.\n\n4.2.3 Constraints\nTo stay within the Colab free tier limits of memory usage, we subset the data. We take a 50% random sample of both features (K=4,000 instead of 8,192) and observations (N=50,000 instead of 100,000) compared to the original paper. Despite using this reduced dataset, the demo still achieves strong predictive performance, highlighting MOSAIKS’s efficiency.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html#run-the-code",
    "href": "en/part-00-intro/04-intro-demo.html#run-the-code",
    "title": "4  Try MOSAIKS",
    "section": "\n4.3 Run the code!",
    "text": "4.3 Run the code!\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\nFor instructions and tips on using Google Colab, please refer to Chapter 23.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html#dont-want-to-run-code",
    "href": "en/part-00-intro/04-intro-demo.html#dont-want-to-run-code",
    "title": "4  Try MOSAIKS",
    "section": "\n4.4 Don’t want to run code?",
    "text": "4.4 Don’t want to run code?\nConsider watching this demonstration instead!\n\n\n\n\n\nFigure 4.7: An overview of MOSAIKS and a live demonstration of generating novel predictions using the system. Video recorded by CIGAR Generalized Planetary Remote Sensing - 2020 Convention session. Presented by Esther Rolf and Tamma Carleton.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-00-intro/04-intro-demo.html#whats-next",
    "href": "en/part-00-intro/04-intro-demo.html#whats-next",
    "title": "4  Try MOSAIKS",
    "section": "\n4.5 What’s next?",
    "text": "4.5 What’s next?\nAfter establishing MOSAIKS’s capabilities in the US context, the MOSAIKS development team have successfully demonstrated the system in many additional settings. This includes on the global scale, or in settings with few or low quality data. In the coming chapters, we will explore some of these applications, showing how MOSAIKS can help address data gaps in regions where traditional data collection is challenging or costly.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next section we will take a closer look at the label data that can be used with MOSAIKS.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Try MOSAIKS</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/00-labels.html",
    "href": "en/part-01-labels/00-labels.html",
    "title": "Label data",
    "section": "",
    "text": "Overview\nThis section explores the ground truth data (labels) that can be used to train a predictive model with MOSAIKS. While the system is designed to be flexible with respect to the types of outcomes it can predict, understanding what makes good label data and how to prepare it properly is crucial for success.\nLabel data represents the “truth” that MOSAIKS attempts to predict - whether that’s crop yields, population density, economic indicators, or any other variable that might be visible (directly or indirectly) in satellite imagery. The quality and characteristics of this label data significantly influence model performance.",
    "crumbs": [
      "Label data"
    ]
  },
  {
    "objectID": "en/part-01-labels/00-labels.html#what-makes-good-label-data",
    "href": "en/part-01-labels/00-labels.html#what-makes-good-label-data",
    "title": "Label data",
    "section": "What makes good label data?",
    "text": "What makes good label data?\nFor optimal performance with MOSAIKS, label data should have several key characteristics:\n\nAccurate geographic location information\nAppropriate spatial resolution (typically ≥1km²)\nReasonable temporal alignment with imagery features\nSufficient sample size (generally ≥300 observations)\nObservable connection to surface features",
    "crumbs": [
      "Label data"
    ]
  },
  {
    "objectID": "en/part-01-labels/00-labels.html#section-outline",
    "href": "en/part-01-labels/00-labels.html#section-outline",
    "title": "Label data",
    "section": "Section outline",
    "text": "Section outline\nThe following chapters will guide you through key considerations for working with label data in MOSAIKS:\n\n\n\n\n\n\n\n\nChapter\nKey Topics\n\n\n\n27  Quelles étiquettes fonctionnent ?\nExample applications, performance analysis, validation\n\n\n28  Données d’enquête\nSurvey integration, sampling design, geographic referencing\n\n\n29  Préparation des étiquettes\nData cleaning, spatial joining, quality control\n\n\n8  Label data demo\nHands-on example, practical workflow, troubleshooting\n\n\n\n\n\nTable 1: Outline of the label data section\n\n\nThese chapters provide both practical guidance for preparing your own label data and deeper understanding of what types of outcomes MOSAIKS can effectively predict.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll explore over 100 different outcomes that have been tested with MOSAIKS, examining what works well and what doesn’t.",
    "crumbs": [
      "Label data"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html",
    "href": "en/part-01-labels/01-labels-100-maps.html",
    "title": "5  What labels work?",
    "section": "",
    "text": "5.1 Overview\nMOSAIKS is a designed to be useful for predicting anything that may be visible in satellite imagery. Some things are easier to predict than others, but the system is designed to be flexible. For instance, some variables can be seen directly in the imagery itself, such as forest cover, which clearly emits a visible green signal. Other outcomes can only be predicted through indirect relationships between imagery data and labels. For example, income and housing price are not themselves directly visible in raw imagery, but their values can be reliably estimated from objects (e.g., cars), textures (e.g., roofing material), and colors (e.g., grey road infrastructure) contained within the imagery.\nIn this chapter we will discuss a new working paper (Proctor et al., in prep.) that explores the question of what can and cannot be reliably predicted from satellite imagery using MOSAIKS. This paper investigates over 100 different outcomes, reporting predictive performance for each using MOSAIKS. We will discuss the results of a selection of these outcomes in detail, and provide a brief overview of the rest. Of course, this list of outcomes is not exhaustive and reported performance can differ substantially across contexts and in particular with varying quality of ground truth data. We show these results as an initial investigation of what might be possible with SIML using MOSAIKS, but encourage users to conduct their own experiments as resulst are likely to differ in new settings. The pre-print of Proctor et al. will be posted here when publicly available.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html#overview",
    "href": "en/part-01-labels/01-labels-100-maps.html#overview",
    "title": "5  What labels work?",
    "section": "",
    "text": "Figure 5.1: MOSAIKS versatility makes it the perfect tool for a wide range of applications.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html#one-hundred-maps",
    "href": "en/part-01-labels/01-labels-100-maps.html#one-hundred-maps",
    "title": "5  What labels work?",
    "section": "\n5.2 One hundred maps",
    "text": "5.2 One hundred maps\n\n5.2.1 Original publication\nIn Rolf et al. 2021, the authors tested MOSAIKS on 7 outcomes: forest cover, income, housing price, population density, nighttime luminosity, and elevation. The study area is focused in the continental United States. This is an excellent starting point for understanding the capabilities of MOSAIKS as the data quality is high for a diverse set of outcomes. While the results showed significant promise and demonstrated the potential of MOSAIKS, the true test is in the application to new outcomes and new geographies.\n\n5.2.2 Going global\nTo test the global applicability of MOSAIKS, across a diverse set of outcomes, there were 2 primary things that needed to happen:\n1. The creation of a global set of features\n\n\n\n\n\nFigure 5.2: Planet Labs visual basemap imagery from quarter 3 of 2019 (left) and 4 of 4,000 MOSAIKS features downloaded from the API (right).\n\n\n2. Collecting and curating a large set of outcomes with diversity in spatial structures and categories\n\n\n\n\n\n\n\n\n\nCategory\nNumber of Labels\nExample Label\n\n\n\nAgricultural Assets\n5\nAgricultural land ownership\n\n\nAgriculture\n16\nMaize yield\n\n\nBuilt Infrastructure\n9\nBuildings\n\n\nDemographics\n5\nMedian age\n\n\nEducation\n10\nExpected years of schooling\n\n\nHealth\n15\nMalaria in children\n\n\nHousehold Assets\n21\nMobile phones\n\n\nIncome\n9\nHuman development index\n\n\nNatural Systems\n8\nTree cover\n\n\nOccupation\n17\nUnemployment\n\n\n\n\n\nTable 5.1: The authors selected 115 variables across 10 categories and set to work testing each in the MOSAIKS system.\n\n\nWith this data in hand, they were able to devise a few simple questions to test:\n\nWhich variables can be effectively measured?\nWhat are the most compelling applications?\nWhat are the modes of failure?",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html#results",
    "href": "en/part-01-labels/01-labels-100-maps.html#results",
    "title": "5  What labels work?",
    "section": "\n5.3 Results",
    "text": "5.3 Results\n\n5.3.1 Overall performance\nThe results of the 100 maps experiment are shown in the scatter plot below (Figure 27.3). Each point in each scatter sub-plot represents a location in the study for a given label. The x-axis is the observed value of the label, and the y-axis is the MOSAIKS-predicted value. The diagonal 45° line in each sub-plot represents perfect prediction. The coefficient of determination (R²) is used here as the primary measure of accuracy.\nA few broad insights stand out:\n\nSubstantial variation: Even within the same category, we see varying degrees of predictive power. For instance, in the “Agriculture” category, some labels (such as high-level yield averages) are predicted quite accurately, while others (like certain niche crops or management practices) remain more elusive.\nCategory differences: Some categories have consistently higher R² scores. For instance, “Natural Systems” (e.g., tree cover) often score better because the patterns are more directly visible from above—think of large, contiguous forest areas contrasted with open fields or urban centers. On the other hand, “Occupation” or “Demographics” include variables (like unemployment rates) that are largely socio-economic in nature, requiring more indirect and subtle cues.\nFailure cases: A few outcomes show near-random performance, suggesting that the satellite imagery features alone are insufficient to capture their spatial patterns, or that the signals are drowned out by noise (see Failures below).\n\n\n\n\n\n\nFigure 5.3: The results of the 100 maps experiment with the x-axis shows the observed values of the outcome, while the y-axis shows the predicted values. Each point in each scatter is a location from the study. The diagonal line (45°) represents perfect prediction. Performance is measured with the coefficient of determination (R²).\n\n\nIn the box plot (Figure 27.4) we see the distribution of R² values for each category across all 115 labels. This confirms the wide range of performance. Categories such as “Agriculture,” “Income,” and “Natural Systems” tend to have higher median R² values; categories such as “Health” and “Occupation” show more varied or lower overall performance.\n\n\n\n\n\nFigure 5.4: The results of the 100 maps experiment.\n\n\nThis heterogeneity underscores an important takeaway: MOSAIKS is not a one-size-fits-all solution. Some phenomena lend themselves to easier detection via satellite data than others. Still, the ability to simultaneously handle over 100 different outcomes from a single feature set is itself a testament to MOSAIKS’ flexibility and global applicability.\n\n5.3.2 Successes\n\n5.3.2.1 Maize yield\n\n5.3.2.1.1 Maize data\nThe maize yield data comes from crop yield data collected at the second administrative level (e.g., counties in the US) from the United States, China, Brazil and the European Union. Yields are calculated as harvested grain divided by the planted area, though in some cases harvested area is used instead of planted area. The data covers years from 1983-2009, with the most recent available year used for each location.\n\n5.3.2.1.2 Maize yield results\nA standout example of a high-performing label is Maize yield (Figure 27.5). This outcome is naturally suited to detection by satellite imagery:\n\n\nDirect visual signal: Agricultural fields have characteristic features, including crop texture, canopy cover, and phenological (growth stage) patterns, all of which can be captured in the spectral and spatial signals from satellite images.\n\n\n\nSpatial contiguity: Large, contiguous fields of maize reduce noise and enable easier extraction of relevant features.\n\nIn the left-hand scatter plot of Figure 27.5, the predicted yield values match well with the observed values, often clustering along the 45° line. On the right, we see that visually identifiable patterns in maize-growing regions are clearly reflected in the predicted maps. This strong alignment highlights how MOSAIKS can quickly yield robust predictions for outcomes that are clearly manifested in the satellite imagery.\n\n\n\n\n\nFigure 5.5: Performance of MOSAIKS on Maize yield, showing the observed values plotted against the model predictions (left). Observed label data is shown in the upper right, while the corresponding predictions are shown bottom right.\n\n\n\n5.3.2.1.3 Why it works\nCrop yields are a classic use case for remote sensing because farmland is often large, geographically dispersed, and subject to rapid changes from weather and management practices—conditions that satellite imagery can routinely monitor at scale. By measuring vegetation indices (e.g., NDVI, EVI), researchers gain insight into plant health, canopy density, and photosynthetic activity, all of which correlate strongly with agricultural productivity. This non-invasive, timely, and spatially comprehensive approach makes it invaluable for crop forecasting, detecting stress, and guiding resource allocation. Consequently, remote sensing has become a cornerstone in modern yield estimation methods for staple crops around the world. MOSAIKS is a natural extension of this trend, leveraging the latest in machine learning to extract actionable insights from satellite imagery.\n\n\n\n\n\nFigure 5.6: Agricultural fields in the United States Midwest region. This examples shows the clear delineation of fields with varying color intensities, making for easily detectable features in the satellite imagery. Source: NASA\n\n\n\n5.3.2.2 International wealth index (IWI)\n\n5.3.2.2.1 IWI data\nThe International Wealth Index data comes from the Demographic and Health Surveys (DHS) program. The index is expressed as a value between 0 and 100, with higher values indicating greater wealth. It is computed from household data on ownership of consumer durables, housing characteristics, and access to basic services like water and electricity. The data is processed and provided by the Global Data Lab with permission from DHS, with values averaged across households within each survey cluster. Survey clusters are displaced by up to 2km for urban areas and up to 5km for rural areas to protect privacy, while remaining within the same administrative boundaries.\n\n5.3.2.2.2 IWI results\nAnother notable success is the International Wealth Index (IWI; Figure 27.7). This composite measure of household wealth is derived from a variety of indicators, such as housing quality, access to services, and ownership of durable goods. While wealth itself is not directly visible from space, the underlying factors that contribute to it often are. For example, wealthier areas tend to have more developed infrastructure, larger homes, and more vehicles—all of which leave distinct signatures in satellite imagery.\n\n\n\n\n\nFigure 5.7: Performance of MOSAIKS on the International Wealth Index (IWI), showing the observed values plotted against the model predictions (left). Observed label data is shown in the upper right, while the corresponding predictions are shown bottom right.\n\n\n\n5.3.2.2.3 Why it works\nDespite being a composite measure of socioeconomic status, the IWI’s underlying indicators—housing conditions, access to utilities, and asset ownership—often manifest in the built environment as features that satellites capture well. For instance, wealthier neighborhoods typically exhibit a higher density of substantial buildings, paved roads, formal layouts, and visible amenities (e.g., swimming pools, parked vehicles). These cues translate into distinctive patterns in the spectral and spatial data extracted by MOSAIKS’ features. Furthermore, infrastructure development and housing materials (like metal roofs versus thatch) can produce detectable differences in reflectance, making it easier for the algorithm to discern socioeconomic gradients.\n\n\n\n\n\n\nThis highlights one of MOSAIKS’ core advantages: even when the target variable isn’t directly “visible,” the system can tease out its proxies from wide-ranging visual cues, leading to robust predictions of wealth indices around the globe.\n\n\n\n\n5.3.3 Failures\n\n5.3.3.1 Pipeline infrastructure\n\n5.3.3.1.1 Pipeline data\nThe pipeline data comes from the Energy Information Association (EIA) and includes interstate trunk lines and selected intrastate lines across three types: crude oil pipelines, hydrocarbon gas liquids (HGL) pipelines, and petroleum product pipelines. The data represents pipeline infrastructure as of January 2020 and covers the lower 48 United States. The variable measures the length in kilometers of each pipeline type within each grid cell.\n\n5.3.3.1.2 Pipeline results\nCertain labels show extremely low R² values, effectively indicating no predictive power under this approach. One notable example is the presence of underground pipelines Figure 27.8.\n\n\n\n\n\nFigure 5.8: Where it fails\n\n\n\n5.3.3.1.3 Why it fails\nUnlike forests or agricultural fields, pipeline infrastructure is typically hidden from direct visual inspection—often located entirely underground or obscured in ways that do not provide surface indicators distinguishable in imagery (Figure 27.9).\n\nLack of visible features: There is no spectral or structural cue (e.g., coloration, texture, shape) that reliably indicates the presence of a pipeline.\nIndirect clues Are unreliable: One might speculate that pipelines could follow roads or distinct corridors, but these correlations vary widely by region and do not consistently appear in the imagery.\nSignal-to-noise ratio: In many areas, the pipeline corridor may appear visually indistinguishable from farmland or other vegetation, leaving little to no unique satellite signature.\n\nAs a result, MOSAIKS has little chance to identify and learn features predictive of such hidden infrastructure. This stands in stark contrast to more visually prominent targets like maize fields or tree cover.\n\n\n\n\n\nFigure 5.9: Why it fails - buried\n\n\n\n5.3.3.2 Bee diversity\n\n5.3.3.2.1 Bee data\nThe bee diversity data comes from the US Geological Survey Eastern Ecological Science Center Native Bee Laboratory, which provides species occurrence records for native and non-native bees, wasps, and other insects collected through various trapping methods. Each record includes taxonomic identification and geographic coordinates. Using point data from 2009-2019, bee diversity is computed as a count of unique species documented within each 0.01° × 0.01° grid cell in North America (including U.S. territories and Minor Outlying islands). For cells with multiple sampling events, species are counted only once. Importantly, the database only includes records of species presence - absences are not recorded - which can lead to sampling bias in the diversity measures.\n\n5.3.3.2.2 Bee results\nAnother notable failure case is bee diversity. While bees play a crucial role in ecosystems and agriculture, their presence and diversity cannot be directly observed from satellite imagery. Several factors contribute to this limitation:\n\n\nScale mismatch: Bees operate at a much finer spatial scale than the resolution of typical satellite imagery\n\nIndirect relationships: While bees rely on vegetation, the link between plant cover visible from space and bee populations is complex and varies by context\n\nTemporal dynamics: Bee populations fluctuate seasonally and can change rapidly, while imagery captures only static snapshots\n\nHidden factors: Critical habitat features like nesting sites are often concealed under canopy or in small spaces invisible from above\n\nThis case illustrates an important principle: MOSAIKS works best when predicting outcomes that have consistent, visible relationships with surface features captured in satellite imagery. When those relationships become too indirect or complex, performance typically suffers.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html#types-of-variables",
    "href": "en/part-01-labels/01-labels-100-maps.html#types-of-variables",
    "title": "5  What labels work?",
    "section": "\n5.4 Types of variables",
    "text": "5.4 Types of variables\nMOSAIKS can work with both continuous and categorical outcome variables, though the approach and evaluation metrics differ between these types.\n\n\n\n\n\n\nThis section provides a brief overview of the two types of variables and some of the metrics used to evaluate them. This will be covered in greater detail in Chapter 38.\n\n\n\n\n5.4.1 Continuous variables\nContinuous variables take numeric values along a spectrum, such as:\n\nCrop yields (e.g., tons per hectare)\nPopulation density (people per square kilometer)\nForest cover percentage (0-100%)\nIncome levels (dollars)\nBuilding height (meters)\n\nFor continuous variables, MOSAIKS typically uses regression approaches and evaluates performance using metrics like R² (coefficient of determination) or RMSE (root mean square error). The R² values reported throughout this chapter indicate the proportion of variance in the outcome that is explained by the MOSAIKS predictions.\n\n\n\n\n\nFigure 5.10: Continuous variable example showing the breeding bird species diversity over the continental United States\n\n\n\n5.4.2 Categorical variables\nCategorical variables group observations into distinct classes or categories, such as:\n\nLand use types (urban/agriculture/forest)\nBuilding types (residential/commercial/industrial)\nCrop types (maize/wheat/rice)\nPresence/absence of features (roads, buildings)\nDevelopment categories (low/medium/high)\n\nFor categorical variables, MOSAIKS can be used in two ways:\n\nBinary classification: For variables with two categories (e.g., presence/absence), MOSAIKS can output probability predictions between 0 and 1. Performance is typically evaluated using metrics like accuracy, precision, recall, or area under the receiver operating characteristic curve (AUC-ROC).\n\nMulti-class classification: For variables with multiple categories, MOSAIKS can either:\n\nUse a one-vs-all approach, treating each category as a separate binary classification problem\nOutput probabilities for each possible category that sum to 1\nConvert categories to numeric values if they have a natural ordering\n\n\n\n\n\n\n\n\nFigure 5.11: Classifier example showing Ecoregions of the world.\n\n\n\n5.4.3 Choosing appropriate metrics\nThe choice of evaluation metric should match the type of variable:\n\n\nVariable Type\nCommon Metrics\nInterpretation\n\n\n\nContinuous\nR², RMSE, MAE\nR² ranges 0-1, higher is better\n\n\nBinary\nAccuracy, AUC-ROC\nRange 0-1, higher is better\n\n\nMulti-class\nAccuracy, F1-score\nRange 0-1, higher is better",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/01-labels-100-maps.html#summary",
    "href": "en/part-01-labels/01-labels-100-maps.html#summary",
    "title": "5  What labels work?",
    "section": "\n5.5 Summary",
    "text": "5.5 Summary\nThis exploration of over 100 different outcomes reveals several key insights about MOSAIKS:\n\nPerformance varies significantly: Predictive power ranges from very strong (R² &gt; 0.8) to essentially random guessing, depending on the outcome\nDirect visibility matters: Outcomes that are directly observable in imagery (like forest cover) or have strong visible proxies (like wealth indices) tend to perform better\nCategory patterns: Some categories like Natural Systems and Agriculture show consistently stronger performance than others like Health or Demographics\n\nPractical implications: Understanding these patterns helps users:\n\nSet realistic expectations for new applications\nIdentify which types of outcomes are most suitable\nRecognize when alternative approaches might be needed\n\n\n\nThese results demonstrate both the power and limitations of MOSAIKS. While it excels at predicting many important outcomes globally, it is not a universal solution. Success depends largely on whether the outcome of interest has a meaningful relationship with features visible in satellite imagery.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll explore survey label data in more detail.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What labels work?</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html",
    "href": "en/part-01-labels/02-labels-survey.html",
    "title": "6  Survey data",
    "section": "",
    "text": "6.1 Why does survey data needs its own chapter?\nNotes:\nSurvey data presents unique challenges and opportunities when working with MOSAIKS. Unlike many other data sources that may be consistently gathered through automated systems or administrative records, survey data:",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html#why-does-survey-data-needs-its-own-chapter",
    "href": "en/part-01-labels/02-labels-survey.html#why-does-survey-data-needs-its-own-chapter",
    "title": "6  Survey data",
    "section": "",
    "text": "Captures detailed household and individual-level information that’s otherwise unobservable\nOften follows complex sampling designs that need special handling\nMay have inconsistent geographic referencing across different surveys\nRequires careful consideration of privacy and ethical concerns\nCan be expensive and time-consuming to collect, making validation of MOSAIKS predictions particularly valuable",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html#types-of-survey-data",
    "href": "en/part-01-labels/02-labels-survey.html#types-of-survey-data",
    "title": "6  Survey data",
    "section": "\n6.2 Types of survey data",
    "text": "6.2 Types of survey data\nSeveral major categories of surveys are commonly used with MOSAIKS:\n\n6.2.1 Household surveys\n\nLiving Standards Measurement Study (LSMS)\nDemographic and Health Surveys (DHS)\nMultiple Indicator Cluster Surveys (MICS)\nLabor force surveys\nNational census data\n\n6.2.2 Agricultural surveys\n\nAgricultural censuses\nCrop cutting surveys\nFarm management surveys\nAgricultural household surveys\n\n6.2.3 Economic surveys\n\nEnterprise surveys\nMarket price surveys\nConsumer expenditure surveys",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html#accessing-survey-data",
    "href": "en/part-01-labels/02-labels-survey.html#accessing-survey-data",
    "title": "6  Survey data",
    "section": "\n6.3 Accessing survey data",
    "text": "6.3 Accessing survey data\nSurvey data access varies by source and type:\n\n6.3.1 Public repositories\n\nWorld Bank Microdata Library\nIPUMS International\nDHS Program website\nFAO statistical databases\n\n6.3.2 National statistical offices\n\nCensus bureaus\nAgricultural ministries\nEconomic agencies\n\n6.3.3 Research institutions\n\nUniversities\nThink tanks\nResearch organizations",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html#working-with-survey-data",
    "href": "en/part-01-labels/02-labels-survey.html#working-with-survey-data",
    "title": "6  Survey data",
    "section": "\n6.4 Working with survey data",
    "text": "6.4 Working with survey data\n\n6.4.1 LSMS data\nThe Living Standards Measurement Study (LSMS) requires specific considerations:\n\nComplex multi-topic household surveys\nDetailed geographic information\nPanel structure in some countries\nIntegration with agricultural data\nVarying spatial referencing methods\n\n6.4.2 DHS data\nThe Demographic and Health Surveys (DHS) present unique characteristics:\n\nStandardized across countries\nCluster-based sampling\nDisplaced GPS coordinates\nRich health and demographic indicators\nRegular update cycle",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/02-labels-survey.html#remote-sensing-informed-survey-design",
    "href": "en/part-01-labels/02-labels-survey.html#remote-sensing-informed-survey-design",
    "title": "6  Survey data",
    "section": "\n6.5 Remote sensing informed survey design",
    "text": "6.5 Remote sensing informed survey design\nMOSAIKS can enhance survey design in several ways:\n\n6.5.1 Pre-survey planning\n\nOptimize sampling frame using satellite-derived information\nIdentify areas of interest based on physical characteristics\nStratify sampling based on predicted characteristics\n\n6.5.2 During survey implementation\n\nValidate location information\nGuide field teams with up-to-date imagery\nMonitor survey progress\n\n6.5.3 Post-survey analysis\n\nValidate survey responses against satellite indicators\nFill data gaps in hard-to-reach areas\nCreate high-resolution predictions from survey samples\n\nExample of using MOSAIKS features for survey planning:\nThis integration of MOSAIKS with survey data represents a powerful approach for both enhancing traditional survey methods and extending their reach through satellite-based prediction.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll look at practical guidance for preparing label data for use with MOSAIKS, including data cleaning, aggregation, and joining to satellite features.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survey data</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html",
    "href": "en/part-01-labels/03-labels-data-prep.html",
    "title": "7  Preparing labels",
    "section": "",
    "text": "7.1 Overview\nIn this chapter, we discuss the process of preparing labels for use with MOSAIKS features. Labels are the observed values we aim to predict with our model—such as crop yields, forest cover, or any variable of interest. They can come in many spatial formats (e.g., points, polygons, or gridded rasters), but they must include a spatial component. We use this spatial information to join the labels with MOSAIKS features, which are also spatially explicit.\nAlthough MOSAIKS offers many optional steps, two components are essential:\nBoth datasets must align in spatial resolution and contain appropriate geographic data for merging.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#overview",
    "href": "en/part-01-labels/03-labels-data-prep.html#overview",
    "title": "7  Preparing labels",
    "section": "",
    "text": "Ground observations (labels)\n\nSatellite features",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#mosaiks-grid",
    "href": "en/part-01-labels/03-labels-data-prep.html#mosaiks-grid",
    "title": "7  Preparing labels",
    "section": "\n7.2 MOSAIKS Grid",
    "text": "7.2 MOSAIKS Grid\nBefore we talk about labels, we must first understand the resolution that the MOSAIKS features are offered in. The resolution you choose will serve as the target resolution for your summarizing your labels.\n\n7.2.1 Resolution\nThe standard resolution of MOSAIKS is a global grid at 0.01° resolution. Each grid cell is approximately 1 km² at the equator. The grid is often represented as a point grid, where each point is the center of a grid cell. This means that standard MOSAIKS features come with a latitude and longitude coordinate, which is the center of the grid cell.\n\n\n\n\n\n\nMOSAIKS grid cell centroids are rounded to 0.005 degrees and are spaced by 0.01 degree (e.g., 10.005, 10.015, 10.025,…).\n\n\n\n\n\n\n\n\nFigure 7.1: Visual representation of a standardized grids at varying resolutions (δ) with the highest resolution on the left, and lower resolutions moving right. Source: Rolf et al. 2021 Figure 3 c.\n\n\n\n7.2.2 Advantages of the MOSAIKS grid\nThe MOSAIKS grid has several advantages. The primary advantage is that it helps avoid overlapping labels. Often label data come with coordinates which are unevenly spaced. If you are forced to align your labels to a grid and summarize within cells, you can avoid bleed over from one label to another. This is especially important when you are working with data that has a high degree of spatial autocorrelation.\n\n\n\n\n\n\nThe MOSAIKS API is designed to predict outcomes at scales of 1 km² or larger. Custom solutions are possible for higher-resolution applications (see Chapter 36).\n\n\n\n\n7.2.3 Disadvantages of the MOSAIKS grid\nThe MOSAIKS grid is defined in degrees, therefore the area of a given cell varies with latitude. Near the equator, each cell is approximately 1 km², while at higher latitudes the area decreases as the distance between meridians (longitude lines) converges.\n\n\n\n\n\nFigure 7.2: The area of a grid cell at different latitudes.\n\n\n\n7.2.4 Choosing your resolution\nWe know from Chapter 25 that the MOSAIKS API offers features at 0.01°, 0.1°, 1°, ADM2, ADM1, and ADM0 resolutions. In all cases, features are computed at 0.01° resolution and then aggregated to the desired resolution. If you plan on using the API to download features, you need to make sure your labels are at the same resolution as the features you plan to download.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#ground-observations",
    "href": "en/part-01-labels/03-labels-data-prep.html#ground-observations",
    "title": "7  Preparing labels",
    "section": "\n7.3 Ground Observations",
    "text": "7.3 Ground Observations\n\n7.3.1 Resolution\nPreparing label data for MOSAIKS depends on location, extent, time, and resolution. When observations have a resolution finer than 1 km², you must select or aggregate them to match the features you plan to use. MOSAIKS can incorporate labels from raster, point, polygon, or vector data. In Chapter 8, we will demonstrate how to prepare labels for each input type.\n\n\n\n\n\nFigure 7.3: Examples of label data formats that can be easily integrated into the MOSAIKS pipeline. Label data of any spatial format that can be aggregated to at least the scale of 1km² (or larger) can be used directly in combination with MOSAIKS imagery features for downstream prediction tasks. Examples shown here are from Rolf et al. (2021) and include: forest cover, elevation, population, and nighttime lights datasets (all raster format); income data (polygon format); road length (vector format); and housing price data (point format). Source: Rolf et al. 2021 Supplementary Figure 4.\n\n\n\n7.3.2 Administrative level data\nIn some cases, you will find labels for administrative regions (states, districts, etc.). In this case, it might not come with any geographic information other than a place name. You can usually find the relevant geographic information online. A good resource for this is the Global Administrative Areas (GADM) database, which provides the boundaries for administrative division at various levels for completely free.\n\n\n\n\n\nFigure 7.4: Global Human Development Index (HDI) data at the first sub-national level of administrative division (ADM1). Source: Smits & Permanyer 2019.\n\n\n\n7.3.3 Challenges of administrative data\nData can be messy. There are two main challenges with administrative data.\n\nName matching: The names in your dataset might not match perfectly with the names in the GADM database or in the MOSAIKS API. Finding a way to comprehensively match these can be time consuming and difficult.\nBoundary changes: Administrative boundaries are not always static. Some regions undergo frequent changes and you need to ensure your data matches the boundaries of the features you use.\n\n7.3.4 Sample Size\nIncreasing sample size (N) often yields higher model performance. MOSAIKS has demonstrated effectiveness across a wide range of sample N. The sample size depends on the spatial (and potentially temporal) resolution of your label data. For instance, if each record is aggregated at the county level, then N equals the number of counties. Incorporating multiple time periods can increase N but also requires more imagery to be featurized (see Chapter 36).\n\n\n\n\n\n\nAs a general rule, a minimum of 300 observations for model training is recommended, though every application is unique and may require more or fewer observations.\n\n\n\nThe original MOSAIKS publication (Rolf et al., 2021) evaluated models with sample sizes from 60,000 to 100,000. In most cases there were only modest performance declines with a few hundred observations (Figure 29.5). In recent crop yield experiments, high performance (R² = 0.80) was achieved with around 400 observations, provided the data were cleaned and aggregated to a district level. It is important to note that the original crop yield dataset included interview records from thousands of farmers across the study country. While this data has a large sample size, it is messy. In this case, a clean dataset with a low number of observations was preferred to a large but noisy dataset.\n\n\n\n\n\nFigure 7.5: Model performance for all seven tasks while varying the number of random convolutional features K and holding N = 64,000 (left) and while varying N and holding K = 8,192 (right). Shaded bands indicate the range of predictive skill across five folds. Lines indicate average accuracy across validation folds. Source: Rolf et al. 2021 Figure 3 b.\n\n\n\n7.3.5 Data Types\nMOSAIKS can accommodate both continuous labels (e.g., fraction of area forested) and discrete labels (e.g., presence/absence of mine). Data type informs model development, performance evaluation, and choice of metric (see Chapter 38). Continuous variables often use coefficient of determination (R²), while discrete variables often use Receiver Operating Characteristic Area Under the Curve (ROC AUC).\n\n\n\n\n\nFigure 7.6: A The coefficient of determination (R²) is a measure of how well the model fits the data. It ranges from 0 to 1, where 1 indicates a perfect fit. The closer each point is to the 45 degree line, the higher the better the model fit and the higher the score will be. B The Receiver Operating Characteristic (ROC) curve is a graphical representation of the true positive rate (sensitivity) against the false positive rate (1-specificity). The area under the curve (AUC) ranges from 0 to 1, where 1 indicates a perfect model. Diagonal line is equivalent to random guessing.\n\n\nThe data type may also effect how the data is cleaned and prepared. For example you may have a dataset of mining locations across a country. If you are interested in predicting the presence of mining, you may want to convert this to a binary variable where a 0 indicates no mining and a 1 indicates mining. Alternatively, you may be interested in predicting the area of mining in each location, in which case you might need to calculate the area of the mining polygons to make the variable continuous.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#joining-data",
    "href": "en/part-01-labels/03-labels-data-prep.html#joining-data",
    "title": "7  Preparing labels",
    "section": "\n7.4 Joining Data",
    "text": "7.4 Joining Data\n\n7.4.1 Merging Labels with MOSAIKS Features\nTo merge labels with features, you must align the geographic location of both datasets. The native resolution MOSAIKS feature files have rows for each location and columns with longitude, latitude, and features. Your label dataset must also have columns for longitude, latitude, and label values (at minimum). Alternatively, aggregated features will come with the name of the administrative region (e.g., district) and the features. You can join this with your label data by matching the district names.\n\n7.4.2 Example Data Structure\nA simple example: district-level crop yield labels might look like:\n\n\n\n\nObservation\nDistrict\nYear\nCrop Yield\n\n\n\n1\nChibombo\n2019\n1.520\n\n\n2\nKabwe\n2019\n1.878\n\n\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n2.383\n\n\n\n\n\nTable 7.1: Fictional crop yield data for districts in Zambia.\n\n\nMOSAIKS features at this same resolution might look like:\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nDistrict\nYear\nFeature 1\nFeature 2\n…\nFeature K\n\n\n\n\n1\nChibombo\n2019\n4.2\n11.6\n…\n12.7\n\n\n2\nKabwe\n2019\n2.9\n5.3\n…\n11.2\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n10.6\n1.1\n…\n2.2\n\n\n\n\n\nTable 7.2: Fictional MOSAIKS feature data for the same districts.\n\n\nAfter a spatial join, you end up with a merged dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nDistrict\nYear\nCrop Yield\nFeature 1\nFeature 2\n…\nFeature K\n\n\n\n\n1\nChibombo\n2019\n1.520\n4.2\n11.6\n…\n12.7\n\n\n2\nKabwe\n2019\n1.878\n2.9\n5.3\n…\n11.2\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n2.383\n10.6\n1.1\n…\n2.2\n\n\n\n\n\nTable 7.3: Example of joined data with both labels and features.\n\n\nIn the above example, our geographic location is the district and our label is the crop yield (mt/ha). We then have K columns containing the features and N observations.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#data-cleaning-considerations",
    "href": "en/part-01-labels/03-labels-data-prep.html#data-cleaning-considerations",
    "title": "7  Preparing labels",
    "section": "\n7.5 Data Cleaning Considerations",
    "text": "7.5 Data Cleaning Considerations\n\n7.5.1 Coordinate Reference Systems (CRS)\nThe default coordinate reference system used by MOSAIKS is World Geodetic System 84 (WGS 84). The standardized code that defines WGS 84 is “EPSG:4326”. EPSG stands for the European Petroleum Survey Group, which maintains a database of coordinate systems and projections. The WGS 84 coordinate system is the most commonly used coordinate system for GPS data.\n\n\n\n\n\nFigure 7.7: Nine small-scale map projections.\n\n\nIf your data is not in WGS 84, you will need to reproject it to this coordinate system before joining it with MOSAIKS features.\n\n7.5.2 Label Quality\nConfirm that label values are within expected ranges, deal with any outliers or missing data, and ensure units are consistent and numeric fields are properly formatted. This book does not go into a great deal of detail on cleaning messy data. This topic is covered in exhaustive detail in the book R for Data Science.\n\n7.5.3 Temporal Alignment\nIf you have time series labels, you will need to compute custom features for each time period. See Chapter 36 for more information on how to do this and ?sec-model-temporal for guidance on modeling time series data with MOSAIKS features.\n\n7.5.4 Data Formats\nMOSAIKS can work with several common spatial data formats:\n\n\n\n\n\n\n\n\n\n\n\nData Type\nCommon File Formats\nDescription\nExample\nGeographic information\n\n\n\nPoint Data\nCSV, GeoJSON, Shapefile\nCoordinate pairs\nPlaces of interest\ngeometry\n\n\nLine Data\nGeoJSON, Shapefile\nGeographic lines\nRoads, rivers\ngeometry\n\n\nPolygon\nGeoJSON, Shapefile\nGeographic areas\nBuildings, fields\ngeometry\n\n\nRaster\nGeoTIFF, NetCDF\nGridded data\nForest cover, elevation\ngrid\n\n\nAdministrative\nCSV\nAdministrative boundaries\nDistricts, states\nplace names\n\n\n\n\n\nTable 7.4: Common spatial data formats with file types, descriptions, examples, and indication of how the spatial information is stored.\n\n\n\n\n\n\n\n\nWhen working with large datasets, converting to efficient data formats such as Parquet, Feather, GeoTIFF, or Zarr can reduce memory usage and improve processing speed.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/03-labels-data-prep.html#summary",
    "href": "en/part-01-labels/03-labels-data-prep.html#summary",
    "title": "7  Preparing labels",
    "section": "\n7.6 Summary",
    "text": "7.6 Summary\nThe most important considerations when preparing labels for MOSAIKS are spatial resolution, sample size, data type, and data quality. Once you have prepared your labels, you can join them with MOSAIKS features to create a dataset ready for modeling.\nA demonstration of how to process data for the data types in Table 29.4 is provided in the next chapter. This notebook will cover the process of creating a MOSAIKS grid, downloading data, and creating a label dataset at the grid level (0.01 degree) and at the second level of administrative division (ADM2).\n\n7.6.1 Labels data checklist\nFor optimal use with MOSAIKS, label data should be:\n\nConsistently geolocated as point, polygon, vector, or raster data\nAggregable to ≥ 1km² resolution\nObservable in daytime satellite imagery (directly or indirectly)\nRecent or slow-changing if using current API features\nSample size N≥300 (larger samples generally perform better)\nCleaned and formatted for modeling\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll look at practical guidance for preparing label data for use with MOSAIKS including data cleaning and aggregation.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Preparing labels</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/04-labels-demo.html",
    "href": "en/part-01-labels/04-labels-demo.html",
    "title": "8  Label data demo",
    "section": "",
    "text": "8.1 Overview\nThis demonstration will show you a few key concepts about label data in MOSAIKS.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Label data demo</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/04-labels-demo.html#demonstration-code",
    "href": "en/part-01-labels/04-labels-demo.html#demonstration-code",
    "title": "8  Label data demo",
    "section": "\n8.2 Demonstration code",
    "text": "8.2 Demonstration code\nBelow is a link to a Jupyter notebook intended to demonstrate practical preparation of label data for use in MOSAIKS. The notebook will guide you through the process of preparing a dataset for use in MOSAIKS, including:\n\nBuilding and use a MOSAIKS standardized grid\nPreparing geographic point labels (latitude and longitude coordinates)\nPreparing geographic line labels (e.g. shapefiles)\nPreparing geographic polygon labels (e.g. shapefiles)\nPreparing raster labels (e.g. GeoTIFFs)\n\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\nFor instructions and tips on using Google Colab, please refer to Chapter 23.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Label data demo</span>"
    ]
  },
  {
    "objectID": "en/part-01-labels/04-labels-demo.html#whats-next",
    "href": "en/part-01-labels/04-labels-demo.html#whats-next",
    "title": "8  Label data demo",
    "section": "\n8.3 What’s next?",
    "text": "8.3 What’s next?\nNow that we have covered the basics of label data, we will move on to the next section, where we will discuss considerations for choosing and processing satellite imagery. This section is not necessary for users who are either a) okay with using the MOSAIKS API to access features, or b) already have experience working with satellite imagery.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next part, we will take a look at considerations for choosing and processing satellite imagery.",
    "crumbs": [
      "Label data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Label data demo</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/00-satellite.html",
    "href": "en/part-02-satellite/00-satellite.html",
    "title": "Satellite imagery",
    "section": "",
    "text": "Overview\nThis section of the book aims to help navigate the complex world of satellite imagery, with a focus on applying these data within the MOSAIKS framework. While MOSAIKS API features are sufficient for many applications, some use cases require working directly with satellite imagery. Understanding how to select and process appropriate imagery becomes crucial in these situations.",
    "crumbs": [
      "Satellite imagery"
    ]
  },
  {
    "objectID": "en/part-02-satellite/00-satellite.html#overview",
    "href": "en/part-02-satellite/00-satellite.html#overview",
    "title": "Satellite imagery",
    "section": "",
    "text": "The skills covered in these chapters are primarily relevant for users who need to generate custom MOSAIKS features. If you plan to use the MOSAIKS API features, you can skip this section.",
    "crumbs": [
      "Satellite imagery"
    ]
  },
  {
    "objectID": "en/part-02-satellite/00-satellite.html#when-to-look-beyond-the-mosaiks-api",
    "href": "en/part-02-satellite/00-satellite.html#when-to-look-beyond-the-mosaiks-api",
    "title": "Satellite imagery",
    "section": "When to look beyond the MOSAIKS API",
    "text": "When to look beyond the MOSAIKS API\nThe MOSAIKS API provides pre-computed features from 2019 Planet Labs imagery. While these features enable a wide range of applications, you may need to work directly with satellite imagery when:\n\nYour analysis requires data from a different time period\nYou need higher spatial or temporal resolution\nYour application requires specific spectral bands\nYou want to validate or compare MOSAIKS features\nYou’re developing new methodologies",
    "crumbs": [
      "Satellite imagery"
    ]
  },
  {
    "objectID": "en/part-02-satellite/00-satellite.html#earth-observation-satellites-past-present-and-future",
    "href": "en/part-02-satellite/00-satellite.html#earth-observation-satellites-past-present-and-future",
    "title": "Satellite imagery",
    "section": "Earth observation satellites: Past, present and future",
    "text": "Earth observation satellites: Past, present and future\nSatellite-based Earth observation has revolutionized our understanding of the planet since the launch of the first Landsat satellite in 1972. Today, hundreds of Earth observation satellites collect terabytes of imagery daily, supporting applications from weather forecasting to precision agriculture.\nThe variety of available satellite data has grown dramatically, with options including:\n\nFree public satellites (Landsat, Sentinel)\nCommercial providers (Planet Labs, Maxar)\nSpecialized sensors (radar, hyperspectral)\nSatellite constellations providing frequent coverage\nVery high resolution imagery (&lt;1m pixels)\n\nThis wealth of options creates both opportunities and challenges in selecting appropriate imagery for your specific needs.",
    "crumbs": [
      "Satellite imagery"
    ]
  },
  {
    "objectID": "en/part-02-satellite/00-satellite.html#section-outline",
    "href": "en/part-02-satellite/00-satellite.html#section-outline",
    "title": "Satellite imagery",
    "section": "Section outline",
    "text": "Section outline\nThe following chapters will guide you through key considerations when working with satellite imagery:\n\n\n\n\n\n\n\n\nChapter\nKey Topics\n\n\n\n31  Choisir l’imagerie satellitaire\nResolution types, data sources, selection criteria\n\n\n32  Traitement de l’imagerie satellitaire\nPre-processing steps, quality control, computing needs\n\n\n\n\n\nTable 1: Outline of the satellite imagery section\n\n\nThese chapters provide practical guidance for incorporating satellite imagery into your MOSAIKS workflow while highlighting important technical and logistical considerations.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we will take a look at how to choose the right satellite imagery for your application.",
    "crumbs": [
      "Satellite imagery"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html",
    "href": "en/part-02-satellite/01-satellite-imagery.html",
    "title": "9  Choosing imagery",
    "section": "",
    "text": "9.1 Background\nThe number of Earth observation satellites has grown exponentially in recent years, driven by advancements in technology, reduced launch costs, and an increasing demand for environmental, economic, and societal insights.\nAlongside this growth, the quality of satellite imagery has improved significantly, with higher spatial, temporal, and spectral resolutions becoming the norm. The proliferation of satellites, coupled with enhanced imaging capabilities, has resulted in an unprecedented volume of data, offering researchers and practitioners a wealth of opportunities—but also presenting challenges in navigating the diversity of data products and selecting those most suited to specific applications.\nMOSAIKS leverages satellite imagery to generate high-quality training data for machine learning models. In this chapter, we explore the key factors to consider when choosing satellite imagery for use with MOSAIKS, including spatial and spectral resolution, temporal frequency, cloud cover, and processing levels.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#background",
    "href": "en/part-02-satellite/01-satellite-imagery.html#background",
    "title": "9  Choosing imagery",
    "section": "",
    "text": "Figure 9.1: Growth in number of satellites over recent years. Source: Union of Concerned Scientists\n\n\n\n\n\n\n\n\nFigure 9.2: Growth in satellite iamge resolution over time. Source: FlyPix AI\n\n\n\n\n\n\n\n\n\nAccess the UCS Satellite Database for a comprehensive list of Earth observation satellites, including key specifications and operational details.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#overview",
    "href": "en/part-02-satellite/01-satellite-imagery.html#overview",
    "title": "9  Choosing imagery",
    "section": "\n9.2 Overview",
    "text": "9.2 Overview\nWhen selecting satellite imagery for use with MOSAIKS, several key factors need to be considered. The choice of imagery should be guided by your specific research needs, label characteristics, and practical constraints like cost and processing requirements. Different use cases, such as monitoring vegetation, mapping urban areas, or tracking climatic variables, may require specific imaging capabilities, making it essential to align satellite features with your intended application. Additionally, trade-offs between resolution, temporal frequency, and accessibility can significantly influence the feasibility of your analysis.\nFor example, high-resolution data from commercial satellites might offer detailed insights but could be prohibitively expensive for large-scale applications. On the other hand, publicly available datasets like Sentinel-2 provide cost-effective options, albeit with potentially coarser resolutions or limited spectral coverage. Understanding these trade-offs is essential to ensure the optimal use of resources.\n\n\n\n\n\n\n\n\nConsideration\nDescription\n\n\n\nAvailability\nThe availability and cost of imagery from public and private sources.\n\n\nTime range\nThe time period for which satellite images are available.\n\n\nTemporal resolution\nThe frequency at which satellite images are captured (e.g., daily, weekly).\n\n\nSpatial resolution\nThe spatial resolution of the satellite sensor (e.g., 10m, 30m, 250m).\n\n\nSpectral resolution\nThe specific wavelengths captured by the sensor (e.g., RGB, NIR, SWIR).\n\n\nSensor type\nThe type of sensor used (e.g., optical, radar, thermal).\n\n\nCloud cover\nCloud cover or other atmospheric interference.\n\n\nProcessing level\nThe preprocessing applied (e.g., orthorectification, normalization).\n\n\n\n\n\nTable 9.1: Based on your labels, a user needs to decide on these key factors. Each consideration will be covered in detail in the following sections.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#availability",
    "href": "en/part-02-satellite/01-satellite-imagery.html#availability",
    "title": "9  Choosing imagery",
    "section": "\n9.3 Availability",
    "text": "9.3 Availability\n\n9.3.1 Public Satellites\nPublic satellite programs offer free or low-cost imagery with global coverage. These programs, funded by government agencies, provide extensive data for scientific research and environmental monitoring. They are particularly valuable for long-term studies, thanks to consistent data archives spanning decades, and for projects with limited budgets. Publicly funded satellites often balance moderate resolutions with frequent revisit times, ensuring data accessibility and temporal consistency.\n\n\n\n\n\n\n\n\n\n\n\nSatellite\nSensor Type\nResolution\nRevisit Time\nSpecial Features\n\n\n\nSentinel-2\nOptical\n10-60m\n5 days\n13 spectral bands\n\n\nLandsat 8/9\nOptical\n15-100m\n16 days\n11 spectral bands\n\n\nMODIS\nOptical\n250m-1km\nDaily\n36 spectral bands\n\n\nSentinel-1\nRadar (C-band)\n5-40m\n6-12 days\nSynthetic Aperture Radar (SAR)\n\n\nNISAR\nRadar (L- and S-band)\nTBD\nLaunching 2024\nDual-band SAR\n\n\nVIIRS\nOther\n375m-750m\nDaily\nDaily global coverage\n\n\nASTER\nOther\n15-90m\n16 days\n14 spectral bands\n\n\nNICFI\nOptical\n4.77 m\nmonthly composite\nTropical forest monitoring\n\n\n\n\n\nTable 9.2: A selection of public satellite programs and their key specifications.\n\n\n\n9.3.2 Private Satellites\nPrivate satellite programs often provide higher resolution imagery, greater specialization, and more frequent revisits than public programs, but typically at a higher cost. These satellites are particularly useful for applications requiring fine detail, such as urban mapping, infrastructure monitoring, or precision agriculture. Private providers often offer custom data products, tailored delivery timelines, and advanced analytics, which can be invaluable for time-sensitive or commercially driven projects. However, the higher costs associated with private imagery may limit their use for large-scale or long-term studies without significant funding.\n\n\n\n\n\n\n\n\n\n\n\nSatellite\nSensor Type\nResolution\nRevisit Time\nSpecial Features\n\n\n\nMaxar WorldView\nOptical\n31cm (panchromatic), 1.24m (multispectral)\nVaries\nVery high resolution\n\n\nPlanet SkySat\nOptical\n50cm (panchromatic), 1m (multispectral)\nVaries\nCompact, agile satellites\n\n\nAirbus Pleiades\nOptical\n50cm (panchromatic), 2m (multispectral)\nVaries\nVery high resolution\n\n\nPlanet PlanetScope\nOptical\n3-5m\nDaily\nLarge constellation\n\n\nPlanet RapidEye\nOptical\n5m\n5.5 days\nDesigned for agriculture\n\n\nSPOT\nOptical\n1.5-6m\n26 days\nLong-standing program\n\n\nICEYE\nRadar (X-band)\n&lt;1m\nFrequent\nHigh revisit SAR\n\n\nCapella Space\nRadar (X-band)\n50cm\nFrequent\nHigh resolution SAR\n\n\nGHGSat\nSpecialized\nTBD\nVaries\nGreenhouse gas monitoring\n\n\n\n\n\nTable 9.3: A selection of private satellite programs and their key specifications.\n\n\n\n9.3.3 Cost considerations\n\n\n\n\n\n\nRemember that the most expensive or highest resolution imagery isn’t always the best choice. Balancing your needs with practical constraints—like budget, storage capacity, and processing expertise—can often yield better long-term outcomes than simply opting for the highest-specification option.\n\n\n\nSelecting satellite imagery involves not only the direct expense of acquiring data but also a range of indirect or “hidden” costs. When factoring these into your overall budget, consider how frequently you need updates, the extent of pre- or post-processing required, and whether your team has the technical skills to work with complex datasets. Some satellites and data portals also bundle analytics and cloud storage into subscription services, which can alleviate infrastructure demands at an additional cost.\nBelow is an example of how imagery costs might break down, offering a quick reference for typical price points and considerations across different data sources:\n\n\n\n\n\n\n\n\n\n\nCost Tier\nApproximate Range\nExample Missions/Programs\nKey Considerations\n\n\n\nFree Public Data\n$0\nLandsat (30m), Sentinel (10m), MODIS (250m–1km), VIIRS (375m–750m)\nGovernment-funded; widely used for large-scale or long-term projects; moderate resolution.\n\n\nMedium-Resolution\n$1–5 per km²\nSPOT (1.5–6m)\nRelatively affordable for moderate detail; suitable for regional analyses.\n\n\nHigh-Resolution\n$5–15 per km²\nPlanet (3–5m), RapidEye (5m)\nUseful for more detailed studies; frequent revisit can drive up cost if coverage is large.\n\n\nVery High Resolution\n$15–25 per km²\nWorldView (sub-meter), SkySat (0.5–1m)\nOffers fine-grained detail but at a premium; cost can escalate quickly for large areas.\n\n\nSubscription Services\nVariable\nSome commercial data providers bundle storage & analytics\nOften convenient “one-stop shop,” but pricing may be unpredictable or scale poorly.\n\n\n\n\n\nTable 9.4: Cost tiers for satellite imagery and key considerations.\n\n\nIn addition to these basic acquisition costs, you should also consider:\n\n\nData Storage and Computing: Large volumes of high-resolution imagery require greater storage space and more computational power for processing.\n\n\nExpertise and Training: Interpreting complex datasets (such as radar or hyperspectral imagery) often demands specialized skills.\n\n\nSoftware Licenses: Proprietary GIS or image processing software can add to your operational budget.\n\n\nCloud Infrastructure: Commercial cloud solutions can handle large-scale processing but may entail ongoing subscription fees.\n\nCarefully weighing these direct and indirect expenses will help you choose imagery that optimizes both scientific value and cost-effectiveness.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#time-range",
    "href": "en/part-02-satellite/01-satellite-imagery.html#time-range",
    "title": "9  Choosing imagery",
    "section": "\n9.4 Time range",
    "text": "9.4 Time range\nThe operational lifespan and launch history of a satellite mission are essential considerations when selecting imagery for your project. Older programs such as Landsat offer data archives spanning several decades, making them valuable for long-term change detection or historical analyses. In contrast, newer satellites like Sentinel, launched in 2014, provide data with more advanced sensor technologies but cover a shorter temporal window.\nWhen deciding on a time range, it is important to assess the historical depth your study demands, as well as the consistency of sensor technology over that period. Projects that require comparisons across many years benefit from missions with well-documented calibration procedures and stable sensor performance over time. You may also need to factor in whether future data continuity is guaranteed by planned satellite launches or extended operational budgets. For instance, Landsat’s multi-generational program ensures a relatively consistent data record, while newer constellations might offer superior capabilities but face funding uncertainties that could impact long-term availability.\n\n\n\n\n\nFigure 9.3: The Landsat satellite constellation service timeline. Source: NASA",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#temporal-resolution",
    "href": "en/part-02-satellite/01-satellite-imagery.html#temporal-resolution",
    "title": "9  Choosing imagery",
    "section": "\n9.5 Temporal resolution",
    "text": "9.5 Temporal resolution\nTemporal resolution, or revisit frequency, dictates how often a satellite images the same location. Higher revisit rates allow you to monitor rapidly changing phenomena, such as vegetation growth cycles or flood dynamics, and respond more quickly to evolving events. However, satellites that pass over more frequently often trade off spatial or spectral detail.\nWhen selecting temporal resolution, consider the pace at which your target variables change. Monitoring daily fluctuations in crop conditions requires denser time series than an annual assessment of deforestation. Cloud conditions in your study area can also influence the effective revisit rate: if clouds frequently obscure the land surface, you may need a satellite constellation with multiple imaging opportunities or a sensor that can “see” through clouds, like radar (SAR). Budget and data processing capacities further shape your decision, since frequent imaging can lead to increased data storage needs and processing overhead.\n\n\n\n\n\nFigure 9.4: Comparison of temporal resolution from different satellite systems. Source: Radiant Earth",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#spatial-resolution",
    "href": "en/part-02-satellite/01-satellite-imagery.html#spatial-resolution",
    "title": "9  Choosing imagery",
    "section": "\n9.6 Spatial resolution",
    "text": "9.6 Spatial resolution\nSpatial resolution of the satellite sensor determines the level of detail captured in satellite imagery. At higher resolutions, features such as individual trees, vehicles, or small buildings are discernible. Lower resolutions provide broader overviews of landscapes—suitable for regional-scale studies like climate analysis or large-area land cover mapping—but may miss fine-grained changes in smaller features.\nAlthough very high resolution imagery (below one meter) can yield rich information, it often carries higher costs and storage requirements. Meanwhile, moderate resolutions (10–30 m) balance meaningful detail with affordability and manageable data volumes. Your choice should account for the physical size of the features relevant to your labels, the scale of your study area, and the computational resources at your disposal. In many cases, public missions like Sentinel-2 or Landsat offer practical resolutions (10–30 m) that suffice for broad-scale analyses without incurring the expense associated with commercial high-resolution imagery.\n\n\n\n\n\nFigure 9.5: The spatial resolution of satellite imagery from 3 public satellites (top row) and 3 commercial satellites (bottom row). Source: Radiant Earth",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#spectral-resolution",
    "href": "en/part-02-satellite/01-satellite-imagery.html#spectral-resolution",
    "title": "9  Choosing imagery",
    "section": "\n9.7 Spectral resolution",
    "text": "9.7 Spectral resolution\nSpectral resolution refers to the sensor’s ability to measure discrete wavelengths across the electromagnetic spectrum. Different materials—such as vegetation, water, and urban infrastructure—exhibit distinct spectral signatures, so capturing multiple bands can enhance classification accuracy and thematic mapping. For instance, near-infrared (NIR) bands are extremely valuable for quantifying vegetation health, while shortwave infrared (SWIR) can help distinguish between minerals and moisture content.\nChoosing an appropriate spectral resolution involves balancing the number and width of bands with the specific thematic information you need. Sensors that capture only visible light (RGB) may suffice for broad land cover discrimination, whereas applications such as agricultural health monitoring often benefit from additional NIR or SWIR coverage. Thermal or microwave bands can also be critical in specialized domains—like thermal anomaly detection or soil moisture estimation—and thus influence the utility of certain satellite platforms for specific scientific or operational goals.\n\n\nSpectral resolution and its applications. Source: Radiant Earth",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#sensor-type",
    "href": "en/part-02-satellite/01-satellite-imagery.html#sensor-type",
    "title": "9  Choosing imagery",
    "section": "\n9.8 Sensor type",
    "text": "9.8 Sensor type\nSatellite sensors can generally be characterized as passive or active instruments. Both categories have distinct advantages and limitations that influence their suitability for particular applications.\nPassive sensors measure natural radiation, typically reflected sunlight (optical) or emitted heat (thermal). Because they rely on external energy sources, data collection can be constrained by sunlight availability and atmospheric conditions. However, optical imagery from passive sensors often offers intuitive color representations, making it easier to interpret. Thermal bands can reveal heat signatures useful in land surface temperature studies.\nActive sensors emit their own energy and record the backscatter signal. Radar systems (e.g., SAR) and LiDAR instruments fall under this category. They can penetrate clouds, operate at night, and measure surface characteristics such as roughness or elevation. On the downside, the data are often more complex to process and interpret, requiring specialized expertise and software.\n\n\n\n\n\nFigure 9.6: Graphic depicting the difference between active and passive sensors. Source: Radiant Earth\n\n\nBelow is a simple comparison of these sensor types:\n\n\n\n\n\n\n\n\n\n\n\nSensor Type\nExamples\nOperating Principle\nPros\nCons\n\n\n\nPassive\nOptical, Thermal\nMeasures naturally available reflected energy (sunlight or emitted heat)\nEasier to interpret; often intuitive (e.g., RGB images)\nLimited by cloud cover and sensitive to atmospheric conditions\n\n\nActive\nRadar (SAR), LiDAR\nEmits energy and measures return signals\nCan penetrate clouds, capture data day or night\nData may require more complex processing\n\n\n\n\n\nTable 9.5: Sensor types and their key characteristics.\n\n\nUnderstanding which sensor type best aligns with your research needs is crucial. For instance, if your study area is frequently cloudy, a radar-based approach can offer more reliable coverage. Alternatively, optical sensors might be sufficient for regions with seasonal cloud-free windows or for general land-cover classification when consistent sunlight is available.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#cloud-cover",
    "href": "en/part-02-satellite/01-satellite-imagery.html#cloud-cover",
    "title": "9  Choosing imagery",
    "section": "\n9.9 Cloud cover",
    "text": "9.9 Cloud cover\nCloud cover is one of the most persistent challenges in working with optical satellite imagery, as clouds and shadows can degrade the quality of the collected data. In regions with frequent cloudiness, images may require additional processing or longer acquisition windows to achieve acceptable coverage. Strategies to address this issue include applying cloud masking algorithms, merging multiple images to create a cloud-free composite, or using radar-based satellites that penetrate clouds.\nOptical sensors, such as those on Sentinel-2 or Landsat, often include quality assurance layers that flag pixels contaminated by clouds. Filtering out these pixels improves data reliability but reduces the amount of usable imagery, potentially limiting temporal coverage in cloudy regions. On the other hand, radar missions like Sentinel-1 or ICEYE remain largely unaffected by cloud conditions, offering consistent coverage at the cost of different data characteristics and additional expertise required for radar data interpretation. Weighing these trade-offs helps in choosing imagery that meets both your accuracy requirements and your practical constraints.\n\n\n\n\n\nFigure 9.7: Cloud cover obscuring the view over over North America. Source: NASA Earth Observatory",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#processing-levels",
    "href": "en/part-02-satellite/01-satellite-imagery.html#processing-levels",
    "title": "9  Choosing imagery",
    "section": "\n9.10 Processing levels",
    "text": "9.10 Processing levels\nSatellite data are distributed at various processing levels, ranging from unprocessed instrument measurements to derived products that are nearly ready for analysis. Selecting a processing level that aligns with your project’s technical requirements can streamline workflows and ensure consistent results.\nBelow is a general outline of commonly encountered processing levels:\n\n\n\n\n\n\n\n\n\nLevel\nDescription\nTypical Use Case\n\n\n\nLevel 0\nRaw instrument data with minimal or no preprocessing. Often not orthorectified or radiometrically calibrated.\nRarely used for general analysis due to complexity.\n\n\nLevel 1\nRadiometric calibration and basic geometric corrections. Sometimes subdivided (e.g., 1A, 1B, 1C).\nSuitable if you need control over final atmospheric corrections or custom workflows.\n\n\nLevel 2\nSurface reflectance products with atmospheric corrections applied, often including cloud/shadow masks.\nMost common for analyses requiring accurate reflectance values and multi-temporal comparisons.\n\n\nLevel 3\nDerived or composite products (e.g., mosaics, NDVI layers, gap-filled data).\nIdeal for thematic applications that benefit from aggregated or pre-processed data.\n\n\n\n\n\nTable 9.6: Common processing levels for satellite imagery and their typical use cases.\n\n\nAdditional processes often applied during or after these levels include:\n\n\nOrthorectification: Removal of geometric distortions caused by sensor tilt, terrain relief, and Earth curvature. Ensures accurate spatial representation for mapping and analysis.\n\nAtmospheric correction: Adjustment for atmospheric effects (aerosols, water vapor) to standardize reflectance values across different times or sensors.\n\nRadiometric calibration: Conversion of raw sensor counts to physical units like reflectance or brightness temperature, enabling consistent comparisons among images from different sensors and acquisition dates.\n\n\n\n\n\n\nFigure 9.8: NICFI satellite imagery raw pixel values showing each band (R, G, B, NIR) for each statistic (min, max, mean, median). These data come with atmospheric correction, cloud correction, and normalized pixel values. After Products created after April 2022 also apply a sharpening filter to the images.\n\n\nKnowing which processing steps your data provider already performs helps you avoid redundant work and ensures you acquire data that meet your accuracy requirements. For instance, if you need consistent multi-temporal comparisons, opt for Level 2 or higher to minimize atmospheric variations. Conversely, if you prefer to perform your own corrections and calibrations, Level 1 might offer greater flexibility at the cost of added complexity.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#choosing-the-right-combination",
    "href": "en/part-02-satellite/01-satellite-imagery.html#choosing-the-right-combination",
    "title": "9  Choosing imagery",
    "section": "\n9.11 Choosing the right combination",
    "text": "9.11 Choosing the right combination\nSelecting the right combination of spatial, spectral, temporal, and sensor characteristics can feel overwhelming, given the numerous satellites and data products available. This choice often comes down to the trade-offs you are willing to make between cost, resolution, revisit frequency, spectral coverage, and data availability.\n\n\n\n\n\n\n\n\n\n\n\nApplication\nSpatial resolution\nTemporal frequency\nKey bands\nExample sensors\n\n\n\nAgricultural\n5–30m\nWeekly–monthly\nNIR, Red, SWIR\nPlanet, Sentinel-2, Landsat 8/9\n\n\nUrban\n0.5–10m\nMonthly–annual\nRGB, NIR\nWorldView, Planet, Sentinel-2\n\n\nForest Monitoring\n10–30m\nMonthly–annual\nNIR, SWIR, Red\nLandsat, Sentinel-2\n\n\nWater Resources\n10–30m\nWeekly–monthly\nNIR, SWIR, Blue\nSentinel-2, Landsat 8/9\n\n\n\n\n\nTable 9.7: Sample satellite characteristics for different applications.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/01-satellite-imagery.html#making-the-final-decision",
    "href": "en/part-02-satellite/01-satellite-imagery.html#making-the-final-decision",
    "title": "9  Choosing imagery",
    "section": "\n9.12 Making the final decision",
    "text": "9.12 Making the final decision\nConsider these questions when making your final imagery selection:\n\nWhat is the minimum spatial resolution needed?\nHow frequent do observations need to be?\nWhat spectral bands are required?\nWhat is the time period of interest?\nWhat is your budget?\nWhat processing level is needed?\nHow will you handle clouds and data gaps?\nWhat are your storage and computing resources?\n\nThe answers to these questions will guide you toward the most appropriate imagery source for your specific application.\n\n\n\n\n\nFigure 9.9: DALL-E generated image of finding the perfect satellite.\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we will explore how to access and process satellite imagery for use with MOSAIKS.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Choosing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html",
    "href": "en/part-02-satellite/02-satellite-processing.html",
    "title": "10  Processing imagery",
    "section": "",
    "text": "10.1 Overview\nAfter selecting appropriate satellite imagery (as discussed in Chapter 31), the next step is accessing and processing that imagery for use with MOSAIKS. This chapter covers key considerations and practical approaches for working with satellite data.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#overview",
    "href": "en/part-02-satellite/02-satellite-processing.html#overview",
    "title": "10  Processing imagery",
    "section": "",
    "text": "Source: Microsoft Planetary Computer",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#accessing-satellite-imagery",
    "href": "en/part-02-satellite/02-satellite-processing.html#accessing-satellite-imagery",
    "title": "10  Processing imagery",
    "section": "\n10.2 Accessing satellite imagery",
    "text": "10.2 Accessing satellite imagery\n\n10.2.1 Cloud vs local\nThere are several cloud-based platforms that provide access to a wide range of satellite imagery and geospatial datasets. These platforms offer scalable computing resources, pre-configured environments, and often include common datasets. Some popular cloud platforms for satellite imagery processing include:\nThese platforms offer several advantages, including:\n\nNo need to download raw imagery\nScalable computing resources\nPre-configured environments\nOften include common datasets\nCan download to local or cloud storage\n\nNASA Earthdata Cloud Cookbook\n\n10.2.1.1 Google Earth Engine\nGoogle Earth Engine provides a vast catalog of satellite imagery and geospatial datasets that can be accessed through a Python API. The GEE API is based on the Earth Engine Python API, which allows you to interact with the Earth Engine servers and run geospatial analyses in the cloud.\n\n10.2.1.2 Microsoft Planetary Computer\nMicrosoft Planetary Computer provides a multi-petabyte catalog of global environmental data that can easily be accessed through APIs. The MPC API is based on the STAC (SpatioTemporal Asset Catalog) specification, which is an emerging open standard for geospatial data that aims to increase the interoperability of geospatial data, particularly satellite imagery.\nFor more information on using the Microsoft Planetary Computer API, see Reading Data from the STAC API.\n\n\n\n\n\n\nFor practical guidance on accessing the Microsoft Planetary Computer Data Catalog through their API,see the Master of Environmental Data Science (MEDS) course EDS 220 section on the STAC specification\n\n\n\n\n10.2.2 Planet API\n\nNICFI is free\n\nSign up at NICFI\n\nAccess to Visual (RGB) and Analytic (RGB+NIR) basemaps\n\n\nPlanet is paid\n\nSign up at Planet\n\nAPI access to PlanetScope, RapidEye, SkySat, Dove, and basemap imagery\nInstitutional licensing available\n\n\n\n\n10.2.2.1 Sentinel Hub\nSentinel Hub is a cloud-based platform that provides access to a wide range of satellite imagery, including data from the Sentinel-1, Sentinel-2, and Landsat missions. The Sentinel Hub API allows you to access and process satellite imagery using a simple Python interface.\n\n10.2.3 Sentinelsat python API\nThe sentinelsat Python API allows you to search and download satellite imagery from the Copernicus Open Access Hub. The API provides a simple interface for searching and downloading Sentinel-1 and Sentinel-2 imagery, as well as other Copernicus data products.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#understanding-the-data",
    "href": "en/part-02-satellite/02-satellite-processing.html#understanding-the-data",
    "title": "10  Processing imagery",
    "section": "\n10.3 Understanding the data",
    "text": "10.3 Understanding the data\nOnce you have decided how to acquire satellite imagery, the next step is to make sure that you understand the data so you can make sure to process it correctly. Often the best resource is to consult the data provider’s documentation. Aside from that, the best way to understand the data is to open it up and explore it.\n\n\n\n\n\n\nFor hands on experience with satellite imagery, skip to the next chapter where you can access NICFI imagery in a Google Colab notebook (Chapter 33).\n\n\n\n\n10.3.1 Storage formats\nSatellite imagery can be stored in various formats, including:\n\nGeoTIFF\nNetCDF\nHDF5\nZarr\n\nThere are several python libraries that can be used to read and write these formats, such as rasterio, xarray, rioxarray, and h5py.\n\n10.3.2 Metadata\n\nData types (INT8, UINT16, FLOAT32)\nCoordinate reference system (CRS)\nSpectral bands (Red, Green, Blue, Near-Infrared, etc.)\nSpatial resolution (scene size, pixel size)\nAcquisition date (single or multiple dates)\nCloud cover\nData quality\n\n10.3.3 Visualization\nThere are many considerations for visualizing satellite imagery. We will cover some of the most common ones here.\n\n10.3.3.1 Normalization\n\n10.3.3.2 True color\n\n10.3.3.3 False color\n\n10.3.3.4 Sharpening\n\n10.3.4 Calculate Indices\nDepending on your application, a good place to start is calculating vegetation or other indices. There are many to choose from and it takes some domain knowledge to know if one would be useful for your application. In agriculture, there are several indices that are commonly used to monitor crop health, such as the Normalized Difference Vegetation Index (NDVI), the Enhanced Vegetation Index (EVI), and the Soil Adjusted Vegetation Index (SAVI).\nNormalized Difference Vegetation Index (NDVI) is a simple and common vegetation index that uses the difference between near-infrared (NIR) and red bands to quantify vegetation health.\n\n\n\n\n\nFigure 10.1: NDVI values animated over Africa. Made with Google Earth Engine Python API.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#processing-satellite-imagery",
    "href": "en/part-02-satellite/02-satellite-processing.html#processing-satellite-imagery",
    "title": "10  Processing imagery",
    "section": "\n10.4 Processing satellite imagery",
    "text": "10.4 Processing satellite imagery\nThere are two main approaches to accessing and processing satellite imagery:\n\n10.4.1 Cloud-based platforms\nModern cloud platforms offer several advantages for satellite image processing:\n\nNo need to download raw imagery\nScalable computing resources\nPre-configured environments\nOften include common datasets\nPay only for what you use\n\nPopular platforms include:\n\nGoogle Earth Engine\nMicrosoft Planetary Computer\nAmazon Web Services\nPlanet Platform\nEuro Data Cube\n\n10.4.2 Local processing\nTraditional local processing may be preferred when:\n\nInternet connectivity is limited\nData privacy is paramount\nWorking with proprietary algorithms\nComputing needs are modest\nFrequent reuse of same imagery\n\nConsider these factors when choosing:\n\nData volume\nProcessing complexity\nBudget constraints\nTime requirements\nSecurity needs",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#processing-steps",
    "href": "en/part-02-satellite/02-satellite-processing.html#processing-steps",
    "title": "10  Processing imagery",
    "section": "\n10.5 Processing steps",
    "text": "10.5 Processing steps\n\n10.5.1 Quality assessment\n\nCloud detection\nShadow masking\nBad pixel identification\nSensor artifacts removal\n\n10.5.2 Atmospheric correction\n\nConvert to surface reflectance\nAccount for atmospheric effects\nStandardize across images\n\n10.5.3 Geometric correction\n\nOrthorectification\nCo-registration\nProjection alignment\n\n10.5.4 Mosaicking\n\nImage stitching\nFeathering/blending\nGap filling\nColor balancing\n\n10.5.5 Temporal compositing\n\nBest-pixel selection\nWeighted averaging\nGap filling\nSmoothing",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#best-practices",
    "href": "en/part-02-satellite/02-satellite-processing.html#best-practices",
    "title": "10  Processing imagery",
    "section": "\n10.6 Best practices",
    "text": "10.6 Best practices\n\n\nDocument everything\n\nProcessing steps\nParameter choices\nQuality control decisions\nSoftware versions\n\n\n\nValidate outputs\n\nVisual inspection\nStatistical checks\nGround truth comparison\nCross-platform verification\n\n\n\nOptimize resources\n\nBatch processing\nParallel computing\nMemory management\nStorage efficiency\n\n\n\nVersion control\n\nTrack code changes\nArchive key datasets\nDocument dependencies\nMaintain reproducibility",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#common-challenges",
    "href": "en/part-02-satellite/02-satellite-processing.html#common-challenges",
    "title": "10  Processing imagery",
    "section": "\n10.7 Common challenges",
    "text": "10.7 Common challenges\n\n10.7.1 Storage requirements\n\nRaw imagery can be massive\nMultiple processing steps multiply storage needs\nIntermediate products management\nBackup considerations\n\n10.7.2 Computing resources\n\nProcessing can be CPU/GPU intensive\nMemory limitations\nI/O bottlenecks\nNetwork bandwidth\n\n10.7.3 Quality issues\n\nCloud contamination\nAtmospheric effects\nSensor artifacts\nGeometric distortions\n\n10.7.4 Time management\n\nProcessing can be slow\nDownload times\nQuality checking\nIteration cycles",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/02-satellite-processing.html#future-considerations",
    "href": "en/part-02-satellite/02-satellite-processing.html#future-considerations",
    "title": "10  Processing imagery",
    "section": "\n10.8 Future considerations",
    "text": "10.8 Future considerations\nAs you develop your processing pipeline, consider:\n\nScalability needs\nAutomation opportunities\nQuality control requirements\nResource constraints\nTime limitations\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next section, we will load, visualize, and explore NICFI satellite imagery in Google Colab.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Processing imagery</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/03-satellite-demo.html",
    "href": "en/part-02-satellite/03-satellite-demo.html",
    "title": "11  Imagery demo",
    "section": "",
    "text": "11.1 Overview\nThis demonstration will show you a few key concepts about satellite data and how it can be prepared for featurization (featurization covered in Chapter 36).",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Imagery demo</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/03-satellite-demo.html#demonstration-data",
    "href": "en/part-02-satellite/03-satellite-demo.html#demonstration-data",
    "title": "11  Imagery demo",
    "section": "\n11.2 Demonstration data",
    "text": "11.2 Demonstration data\nFor this demonstration, we will use satellite imagery from the NICFI Basemaps. The NICFI Basemaps are a collection of high-resolution satellite images that are freely available for research purposes. These data come with atmospheric correction, cloud correction, and normalized pixel values. After Products created after April 2022 also apply a sharpening filter to the images.\nMore details about NICFI Basemap processing can be found here.\nTo learn how to access NICFI Basemaps, follow the sign up instructions here.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Imagery demo</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/03-satellite-demo.html#demonstration-code",
    "href": "en/part-02-satellite/03-satellite-demo.html#demonstration-code",
    "title": "11  Imagery demo",
    "section": "\n11.3 Demonstration code",
    "text": "11.3 Demonstration code\nBelow is a link to a Jupyter notebook intended to demonstrate practical preparation of satellite data for use in MOSAIKS. The notebook will guide you through the process of preparing imagery, including:\n\nLoading satellite imagery\nInspecting image properties\nImage normalization\nImage visualization\n\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\nFor instructions and tips on using Google Colab, please refer to Chapter 23.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Imagery demo</span>"
    ]
  },
  {
    "objectID": "en/part-02-satellite/03-satellite-demo.html#whats-next",
    "href": "en/part-02-satellite/03-satellite-demo.html#whats-next",
    "title": "11  Imagery demo",
    "section": "\n11.4 What’s next?",
    "text": "11.4 What’s next?\nNow that we have covered the basics of working with satellite data, we will move on to the next section, where we will discuss image featurization.\n\n\n\n\n\n\nLooking forward\n\n\n\nThis is the end of the satellite data section. Next, we will move on to the featurization of satellite data.",
    "crumbs": [
      "Satellite imagery",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Imagery demo</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/00-features.html",
    "href": "en/part-03-features/00-features.html",
    "title": "Satellite features",
    "section": "",
    "text": "Overview\nlang: en\nThis section explores MOSAIKS features - the compressed representations of satellite imagery that enable efficient prediction across diverse tasks. While many users can rely on pre-computed API features, understanding how these features work and how to generate them provides valuable context and enables customization when needed.",
    "crumbs": [
      "Satellite features"
    ]
  },
  {
    "objectID": "en/part-03-features/00-features.html#overview",
    "href": "en/part-03-features/00-features.html#overview",
    "title": "Satellite features",
    "section": "",
    "text": "The technical details covered in these chapters are primarily relevant for users who need to understand or generate custom MOSAIKS features. If you plan to use the MOSAIKS API features, you can focus on 35  features API.",
    "crumbs": [
      "Satellite features"
    ]
  },
  {
    "objectID": "en/part-03-features/00-features.html#when-to-look-beyond-the-api-features",
    "href": "en/part-03-features/00-features.html#when-to-look-beyond-the-api-features",
    "title": "Satellite features",
    "section": "When to look beyond the API features",
    "text": "When to look beyond the API features\nThe MOSAIKS API provides pre-computed features derived from 2019 Planet Labs imagery. While these features enable many applications, you may need to work directly with feature generation when:\n\nYour analysis requires data from a different time period\nYou need features at a different spatial resolution\nYou want to experiment with different feature parameters\nYou’re developing new methodological approaches\nYou need to validate or compare feature types",
    "crumbs": [
      "Satellite features"
    ]
  },
  {
    "objectID": "en/part-03-features/00-features.html#feature-types-and-computation",
    "href": "en/part-03-features/00-features.html#feature-types-and-computation",
    "title": "Satellite features",
    "section": "Feature types and computation",
    "text": "Feature types and computation\nMOSAIKS features transform raw satellite imagery into a concise tabular format that captures essential patterns while dramatically reducing data volume. The system currently supports:\n\nRandom convolutional features (RCFs)\nGaussian random features\nEmpirical patch features\nHybrid approaches\n\nThese different feature types offer various tradeoffs in terms of computation time, storage requirements, and predictive performance across tasks.",
    "crumbs": [
      "Satellite features"
    ]
  },
  {
    "objectID": "en/part-03-features/00-features.html#section-outline",
    "href": "en/part-03-features/00-features.html#section-outline",
    "title": "Satellite features",
    "section": "Section outline",
    "text": "Section outline\nThe following chapters will guide you through key aspects of MOSAIKS features:\n\n\n\n\n\n\n\n\nChapter\nKey Topics\n\n\n\n34  Comprendre les features\nRandom convolutional features, implementation details\n\n\n35  features API\nPre-computed features, specifications, usage\n\n\n36  Calcul des features\nProcessing requirements, workflows, storage\n\n\n\n\n\nTable 1: Outline of the features section\n\n\nThese chapters provide both practical guidance for working with MOSAIKS features and deeper technical understanding of how the feature extraction process works.\n\n\n\n\n\n\nLooking forward\n\n\n\nThe next chapter will attempt to provide some context and intuition for the random convolutional features (RCFs) that are at the core of MOSAIKS.",
    "crumbs": [
      "Satellite features"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html",
    "href": "en/part-03-features/01-features-rcf.html",
    "title": "12  Understanding features",
    "section": "",
    "text": "12.1 Kitchen sinks?\nMOSAIKS stands for Multi-task Observation using SAtellite Imagery & Kitchen Sinks. Whenever we present MOSAIKS, we get the question, “Where does ‘kitchen sinks’ come from?” The answer stems from the phrase “everything but the kitchen sink,” which means “almost everything imaginable.” In the context of MOSAIKS, everything but the kitchen sink emphasizes that we take a huge amount of information out of the raw imagery—though, of course, we’re not capturing every last pixel or every possible relationship. It’s as if we’re taking the most useful “ingredients” (i.e., features) from the imagery and leaving the rest behind.\nThis idea of leaving behind the raw imagery is key to MOSAIKS’s power. It means that most users never have to handle the massive amounts of satellite imagery directly. Instead, the MOSAIKS team takes on that burden—extracting a large set of random convolutional features—and then discards the imagery. End users do not need to see the raw imagery or interpret what each individual feature means; they can just use the numerical representation. As a result, users can simply download these features and apply them to their own predictive tasks.\nIn this section, however, we lift the hood to see what’s going on. We focus on how we extract the features from satellite imagery and attempt to provide some intuition for what these features represent.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html#kitchen-sinks",
    "href": "en/part-03-features/01-features-rcf.html#kitchen-sinks",
    "title": "12  Understanding features",
    "section": "",
    "text": "Figure 12.1: Maddy (Madagascar; center) takes raw satellite images (left) and uses the kitchen sink method to produce random convolutional features (right). Art by Grace Lewin.\n\n\n\n\n\n\n\n\n\n\nIn this book, the terms random convolutional features, RCFs, features, satellite features, and MOSAIKS features are used interchangeably.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html#turning-images-into-features",
    "href": "en/part-03-features/01-features-rcf.html#turning-images-into-features",
    "title": "12  Understanding features",
    "section": "\n12.2 Turning images into features",
    "text": "12.2 Turning images into features\n\n\n\n\n\n\nFigure 12.2: A collection of satellite images. Source: Microsoft Planetary Computer\n\n\n\n\n12.2.1 Overview\nThe MOSAIKS featurization process produces a fixed-length feature representation for each patch of satellite imagery. Practically, this means we end up with a numerical vector for each image. Because MOSAIKS uses satellite image, you can substitute the word image for location which means we end up with a numerical representation for each location.\n\n\n\n\n\nFigure 12.3: A closer look at the RCF processing. Illustration of the one-time unsupervised computation of random convolutional features. K patches are randomly sampled from across the N images. Each patch is convolved over each image, generating a nonlinear activation map for each patch. Activation maps are averaged over pixels to generate a single K-dimensional feature vector for each image. Source: Rolf et al. 2021 Figure 1 C\n\n\nThe featurization process has three main steps: convolution, activation, and average pooling.\nIn the coming sub-sections, we will illustrate these steps. In our example, our input imagery will have the dimensions \\(3 x 256 x 256\\), where \\(3\\) is the number of color channels (red, green, and blue) and \\(256 x 256\\) is the image size (width x height) in pixels.\n\n12.2.2 Understanding convolutions\nIn simple terms, applying a convolution to an image can highlight certain patterns, like edges, textures, or colors. Convolutional filters “scan” across the image, computing element-wise products with small patches of the image. Many computer vision models stack multiple convolutional and other layers into a convolutional neural network (CNN). Deep neural networks can have many layers, which is why the approach is often called deep learning.\n\n\n\n\n\nFigure 12.4: A gif showing a convolutional layer with no padding and no strides. Source: A guide to convolution arithmetic for deep learning.\n\n\nMOSAIKS, on the other hand, uses a single convolutional layer. These layer weights are randomly initialized and remain fixed; they aren’t updated during training. This is why the features we get are essentially “random samples” of the spatial and spectral information in the images.\n\n\n\n\n\n\nThere are many great resources for visualizing convolutions, including Convolutional Neural Networks (CNNs) explained.\n\n\n\n\n12.2.2.1 Initializing filters\nFor the convolution step, we need to initialize a set of filters. Each filter is a 3-dimensional tensor with the same number of color channels as the images and a width and height size specified by a kernel size parameter. We can initialize these filters in two ways:\n\nGaussian initialization: We draw the filter weights from a normal distribution.\nEmpirical patches: We randomly sample patches from the image dataset and use these as filters.\n\nEither way, each filter has the same number of color channels as the original images and a specified kernel size (e.g., 3×3). So if our kernel size is 3, each filter might have shape (3, 3, 3). The number of filters is a hyperparameter that you can set when you define your model.\nTo perform the convolution, we compute the dot product of each filter with every portion of the image as the filter slides across it. The result is a new image (a convolution output map) that highlights regions similar to that filter’s pattern.\n\n\n\n\n\n\nWe use pytorch’s torch.nn.functional.conv2d function to perform this operation.\n\n\n\n\n12.2.2.2 Whitening filters\nIf you decide to use empirical patches in the convolution step, it is best practice to whiten the patches. We use a process called Zero-phase Component Analysis (ZCA) whitening, which preserves the spatial structure of the data while removing correlations among pixels.\nThe key steps are:\n\nSubtract the mean of each feature from the data.\nCompute the covariance matrix \\(\\Sigma\\) and perform its eigendecomposition.\nUse the eigenvectors \\(U\\) and eigenvalues \\(D\\), along with a small constant \\(\\varepsilon\\), to form the ZCA transform \\(W\\).\nMultiply the original data by \\(W\\) to obtain the whitened data \\(\\widetilde{X}\\).\n\nMathematically, assuming \\(X\\) is your zero-mean data matrix of shape \\((N \\times d)\\):\n\\[\n\\Sigma = \\frac{1}{N} X^\\top X\n\\quad\\quad\\text{and}\\quad\\quad\n\\Sigma = U \\, D \\, U^\\top,\n\\]\n\\[\nW = U \\Bigl(D + \\varepsilon I\\Bigr)^{-\\tfrac{1}{2}} U^\\top,\n\\]\n\\[\n\\widetilde{X} = X \\, W.\n\\]\n\n\n\n\n\n\nSee the ZCA whitening implementation in torchgeo for more details.\n\n\n\n\n12.2.3 Activation\nNext, we apply a non-linear activation function—ReLU (Rectified Linear Unit)—to the convolution output map. ReLU outputs max(0, x), meaning it zeroes out negative values. This step helps capture non-linearities in the data.\nThe 2-for-1 activation special\nWhen we define our model, one of the parameters that needs to be specified is the number of features. This number needs to be a positive value because we generate 2 features for each filter.\nWe do this by applying the activation function twice:\n\n\nFeature A – ReLU activation on the convolution output.\n\n\nFeature B – ReLU activation on the inverted convolution output (i.e., multiplication by –1, or “negative” of the same filter output).\n\nSo if you specify 200 features, you are actually drawing 100 weights and getting 200 features back. This improves computational efficiency and ensures that each filter has the potential to capture both positive and negative cues.\n\n12.2.4 Average pooling\nWe then apply an adaptive average pooling layer to each activation map, collapsing the 2D spatial grid into a single number per filter. Essentially, this “global average” is a single summary value for how strongly that filter responded to the image.\n\n\n\n\n\n\nWe use pytorch’s torch.nn.functional.adaptive_avg_pool2d function to perform this operation.\n\n\n\n\n12.2.5 Putting it all together\nWe repeat the 3 steps (convolution, activation, and pooling) for all filters. If we have K filters, we end up with a K-dimensional feature vector.\n\n\n\n\n\nFigure 12.5: Input image, selected patches, whitened patches, convolution output, and activation maps",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html#intuition-for-rcfs",
    "href": "en/part-03-features/01-features-rcf.html#intuition-for-rcfs",
    "title": "12  Understanding features",
    "section": "\n12.3 Intuition for RCFs",
    "text": "12.3 Intuition for RCFs\nBelow is a cartoon that illustrates what a random convolutional feature vector might be looking for. Suppose we randomly draw three 3×3 patches from different parts of an image: a forest patch, a road patch, and a river patch.\n\n\n\n\n\nFigure 12.6: A single image with 3 random convolutional patches, highlighting 3 different feature activations of the imagery.\n\n\nWhen we convolve the forest patch across the entire image, the resulting map “lights up” places that look like forest. Likewise, the road patch lights up roads, and the river patch lights up the river. After the ReLU and average-pooling steps, we get a set of summary values—one for each filter.\n\n\n\n\n\nFigure 12.7: Two cartoon images with the same patches used in the convolution step. We see that we have several labels for each image and that we can model each outcome with the same set of features.\n\n\nIf Image 1 has more trees than Image 2, the “forest” feature’s value is higher in Image 1. If Image 2 has more roads, its “road” feature will be higher. Because these features each capture a different (random) spatial pattern, we can then combine them for many downstream prediction tasks—whether it’s predicting tree cover, paved roads, or even something else that correlates with these visual patterns.\n\n\n\n\n\nFigure 12.8: A cartoon image projected into random feature space. If we look at just 2 dimensions, how grey on the x-axis and how green on the y-axis, we can find the vector through this feature space which represents our outcome.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html#why-use-rcfs",
    "href": "en/part-03-features/01-features-rcf.html#why-use-rcfs",
    "title": "12  Understanding features",
    "section": "\n12.4 Why use RCFs?",
    "text": "12.4 Why use RCFs?\n\n12.4.1 Traditional convolutional neural networks (CNNs)\nTo appreciate RCFs, let’s contrast them with traditional CNNs. In a standard CNN, filters are learned via backpropagation. The network sees many examples, calculates errors, and updates the filter weights so that over time they become good at extracting task-specific features. This makes CNNs powerful, but only for what they have been trained to do.\n\n\n\n\n\nFigure 12.9: A simplified diagram showing a typical convolutional neural network model architecture.\n\n\n\n12.4.2 Replacing minimization with randomization in learning\nMOSAIKS takes a radically simpler approach: random filters are used to sample the imagery’s information. Because they are random, they are not “tailored” to any one task. This sounds counterintuitive at first—surely you’d want to learn your filters! But the virtue of randomization is speed and broad applicability. Since no training is required to set these filters, we can produce features at planet-scale very quickly. These features can then be shared with many users, each of whom can apply them to their own predictive tasks (e.g., estimating forest cover, housing density, crop yields, etc.).\n\n\n\n\n\nFigure 12.10: Rolf et al. 2021 Figure 1: MOSAIKS is designed to solve an unlimited number of tasks at planet-scale quickly. After a one-time unsupervised image featurization using random convolutional features, MOSAIKS centrally stores and distributes task-agnostic features to users, each of whom generates predictions in a new context.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/01-features-rcf.html#summary",
    "href": "en/part-03-features/01-features-rcf.html#summary",
    "title": "12  Understanding features",
    "section": "\n12.5 Summary",
    "text": "12.5 Summary\nRandom Convolutional Features (RCFs) form the backbone of MOSAIKS’s ability to handle massive amounts of satellite imagery at scale. Instead of learning tailored filters via backpropagation (like a traditional convolutional neural network), MOSAIKS uses randomly initialized filters that remain fixed. This single-layer approach may seem counterintuitive, but it has several advantages:\n\n\nLightweight and Task-Agnostic\n\nBecause the filters are not tied to any particular outcome, the same feature set can be applied to countless downstream tasks. This drastically reduces the need to reprocess raw imagery for every new prediction goal.\n\n\n\nPlanet-Scale Featurization\n\nMassive amounts of imagery can be processed quickly because no iterative training is needed to refine filters. After a one-time generation of RCFs, they can be stored, shared, and reused—removing the bottleneck of handling petabytes of raw data.\n\n\n\nBroad Feature Capture\n\nRandom filters effectively “sample” a wide variety of spatial and spectral patterns, capturing edges, textures, colors, and more. The “2-for-1” feature approach ensures that each filter captures both positive and negative cues, doubling the dimensionality (and potential information) without doubling compute time.\n\n\n\nEasily Distributed\n\nThe resulting feature vectors (rather than raw images) are small enough to download and manipulate on standard hardware. Researchers and practitioners can thus apply these features to varied applications, from ecological monitoring to socioeconomic modeling.\n\n\n\nBy converting raw imagery into a rich but compact numerical representation, RCFs offer a robust, flexible, and scalable gateway to satellite-based insights—without the headache of storing or manually interpreting vast image archives.\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next section, we’ll look at what is publicly available in the MOSAIKS API and how you can access these features without featurizing data yourself.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Understanding features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html",
    "href": "en/part-03-features/02-features-api.html",
    "title": "13  API features",
    "section": "",
    "text": "13.1 Overview\nIn this chapter, we focus on the publicly available MOSAIKS features that can be accessed via the MOSAIKS API. These features offer a quick and straightforward way to incorporate satellite-based predictors into your analyses without having to manually process satellite imagery.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#overview",
    "href": "en/part-03-features/02-features-api.html#overview",
    "title": "13  API features",
    "section": "",
    "text": "Accessing features on the API is covered in Chapter 25. This chapter provides additional details on the features and how they were generated. To generate your own features, see Chapter 36.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#input-imagery",
    "href": "en/part-03-features/02-features-api.html#input-imagery",
    "title": "13  API features",
    "section": "\n13.2 Input imagery",
    "text": "13.2 Input imagery\n\n\nSourcePlanet Labs Visual Basemap (Global Quarterly 2019, Q3).\n\nTemporal Coverage\nPredominantly images captured between July and September 2019 (Q3), though exact capture dates vary by region.\n\nSpatial Coverage\nGlobal land areas, excluding most large water bodies.\n\nPotential Artifacts\nCloud cover, haze, or shadows may affect the quality of imagery in regions with significant cloud coverage during Q3 2019.\n\n\n\n\n\n\nFigure 13.1: Planet Labs Basemap imagery thumbnail image.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#deeper-look-how-the-api-features-were-generated",
    "href": "en/part-03-features/02-features-api.html#deeper-look-how-the-api-features-were-generated",
    "title": "13  API features",
    "section": "\n13.3 Deeper Look: How the API Features Were Generated",
    "text": "13.3 Deeper Look: How the API Features Were Generated\nThe MOSAIKS team performed a single featurization pass over the Planet Labs 2019 Q3 Visual Basemap images. The process is similar to the Random Convolutional Features (RCFs) method described earlier, but here are the specific parameters:\n\n\nPatch Collection\n\nRandom patches (filters) were drawn from real satellite images (Planet Labs 2019 Q3).\n\nEach patch was whitened: the raw pixel values were mean-centered and decorrelated so that each filter highlights distinct visual patterns.\n\n\n\nKernel Sizes\n\n\n2,000 features from a 4×4 patch shape\n\n\n2,000 features from a 6×6 patch shape\n\nAll patches maintain 3 color channels (R, G, B).\n\n\n\nBias & Activation\n\nA bias of –1 is added to each filter’s convolution output, allowing more nuanced activation levels.\n\nA ReLU activation (max(0, x)) is then applied to keep the model non-linear and remove negative values.\n\n\n\nPooling\n\nAfter convolution + ReLU, the response is average-pooled over each 0.01° patch (i.e., the local 256×256 pixel area, if we approximate each degree of latitude or longitude as ~100 km—though the exact pixel count can vary by latitude).\n\nThis results in a single numeric value per filter.\n\n\n\nFinal Feature Vector\n\nCombining all filters yields a 4,000-dimensional vector at each 0.01° grid cell.\n\nThis entire process was run once, creating a global 0.01° “feature layer.”\n\n\n\n\n\n\n\n\nFigure 13.2: Three randomly generated feature activation maps plotted from the Planet Labs Basemap thumbnail image.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#derived-aggregations",
    "href": "en/part-03-features/02-features-api.html#derived-aggregations",
    "title": "13  API features",
    "section": "\n13.4 Derived aggregations",
    "text": "13.4 Derived aggregations\nAlthough the API stores and provides these features at 0.01° resolution, it also offers pre-aggregated versions:\n\n\n\n\nResolution\nDescription\nWeighting\nDownload\nAccess\n\n\n\n0.01°\nNative resolution (~1km²)\nUnweighted\nMap or File Query\nAPI Portal\n\n\n0.1°\nAggregated grid (~10km²)\nArea or population\nChunked files\nGlobal Grids\n\n\n1°\nAggregated grid (~100km²)\nArea or population\nSingle file\nGlobal Grids\n\n\nADM2\nCounty or district level\nArea or population\nSingle file\nPrecomputed Files\n\n\nADM1\nState or province level\nArea or population\nSingle file\nPrecomputed Files\n\n\nADM0\nCountry level\nArea or population\nSingle file\nPrecomputed Files\n\n\n\n\n\nTable 13.1: The MOSAIKS API offers features derived from Planet Labs imagery (2019 Q3) at various resolutions for the entire globe. All features share the same 4,000 feature columns, with the only difference being the resolution/aggregation level. At each aggregation level above the native resolution, we offer both area-weighted and population-weighted versions. Population weights come from the Gridded Population of the World (GPWv4) population density dataset.\n\n\nIt is nice to have options, but sometimes it is hard to visualize what these aggregations mean. Figure 35.3 shows how these features might look when aggregated to different levels.\n\n\n\n\n\nFigure 13.3: Example showing of 3 representative random convolutional features (rows). Features are downloaded from the MOSAIKS API at 0.01° resolution (the native resolution) and aggregated to 3 levels, including (A) larger grid cells (0.1°), (B) counties, and (C) states.\n\n\n\n13.4.1 Area vs. Population Weighting\nEach aggregated level comes in two weighting flavors: - Area Weighting: Larger grid cells or polygons with more land area receive more weight in the aggregation.\n- Population Weighting: Uses population density (GPWv4) to weight cells more heavily where more people live.\nnote maybe a population map here",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#when-to-use-these-features",
    "href": "en/part-03-features/02-features-api.html#when-to-use-these-features",
    "title": "13  API features",
    "section": "\n13.5 When to use these features",
    "text": "13.5 When to use these features\n\nReadily Available: If your labels are from ~2019 or a period that hasn’t changed drastically since 2019, start with these API features—they’re the fastest and easiest to incorporate into your analyses.\nCoarse-Resolution or Aggregated Labels: If your data is aggregated (e.g., a country-level statistic), consider downloading the aggregated features to match your label resolution.\nResource Constraints: If you’re storage- or compute-limited, using the API’s pre-aggregated files can save time and processing overhead.\nHigh-Resolution or Household Data: For fine-grained tasks (e.g., household surveys), you may still benefit from the 0.01° resolution features—especially if you want to capture local variation. Or you can aggregate to match your label geometry and then use high-resolution features for prediction later (see Chapter 39).\n\n\n\n\n\n\nFigure 13.4: Global Human Development Index (HDI) data at the first sub-national level of administrative division (ADM1). Source: Smits & Permanyer 2019.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#key-takeaways",
    "href": "en/part-03-features/02-features-api.html#key-takeaways",
    "title": "13  API features",
    "section": "\n13.6 Key takeaways",
    "text": "13.6 Key takeaways\n\n\nSingle Source Imagery\n\n\nPlanet Labs Visual Basemap (2019 Q3)\n\nGlobal coverage of land areas at approximately 0.01° (~1 km) resolution\n\nThree color channels (Red, Green, Blue)\n\n\n\nSingle Featurization Pass\n\nAll features are computed once at the native 0.01° resolution.\n\nAny aggregated features (e.g., 0.1°, 1°, administrative boundaries) are derivative and use exactly the same underlying 0.01° features.\n\n\n\nRandom Convolutional Features (RCFs)\n\n\n4,000 total features\n\n\nKernel sizes: 2,000 features from a 4×4 kernel, and 2,000 features from a 6×6 kernel\n\n\nEmpirical patch whitening: random patches are drawn from the image set and then whitened (mean-centered, decorrelated)\n\n\nBias: –1 (applied to each filter output before activation)\n\n\nActivation: ReLU (Rectified Linear Unit)\n\n\n3 color channels from the original RGB imagery\n\n\n\nFlexible Resolutions\n\n\nHigh resolution (0.01°): Download via File Query or Map Query\n\n\nAggregations: 0.1°, 1°, and ADM0/ADM1/ADM2 boundaries, available as precomputed downloads\n\n\n\nUse Cases\n\nIdeal for tasks with label data from the same (or close) time period (2019 or neighboring years)\n\nQuick, straightforward integration into machine learning models\n\nGlobal scale analysis or smaller local/regional analysis",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/02-features-api.html#future-directions",
    "href": "en/part-03-features/02-features-api.html#future-directions",
    "title": "13  API features",
    "section": "\n13.7 Future directions",
    "text": "13.7 Future directions\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next section, we will",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>API features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html",
    "href": "en/part-03-features/03-features-computing.html",
    "title": "14  Computing features",
    "section": "",
    "text": "14.1 Overview\nWhile the MOSAIKS API provides pre-computed features for many applications, some use cases require computing custom features. This chapter covers the technical details of generating MOSAIKS features from satellite imagery.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#requirements",
    "href": "en/part-03-features/03-features-computing.html#requirements",
    "title": "14  Computing features",
    "section": "\n14.2 Requirements",
    "text": "14.2 Requirements\nTo compute MOSAIKS features, you’ll need:\n\nSatellite imagery (see Chapter 32)\nGPU-enabled computing environment (recommended)\nPython with deep learning libraries (pytorch recommended)\nSufficient storage for features",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#implementation",
    "href": "en/part-03-features/03-features-computing.html#implementation",
    "title": "14  Computing features",
    "section": "\n14.3 Implementation",
    "text": "14.3 Implementation\nThere are several ways to implement MOSAIKS feature extraction:\n\n14.3.1 torchgeo implementation\nThe torchgeo library provides a PyTorch implementation of random convolutional features:\nimport torch\nfrom torchgeo.models import RCF\n\n# Define model parameters\npatch_size = 3  # Size of random patches\nin_channels = 4  # Number of input image channels\nnum_filters = 4000  # Number of features to generate\n\n# When empirical, supply a custom pytorch dataset class that returns \n# a dictionary with 'image' key. This samples the dataset for model \n# weights. If gaussian do not supply a dataset class.\n\n# Initialize RCF model\nmodel = RCF(\n    in_channels=in_channels, \n    features=num_filters, \n    kernel_size=3, \n    bias=-1.0, \n    seed=42, \n    mode='empirical',\n    dataset=CustomDataset,\n)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#feature-parameters",
    "href": "en/part-03-features/03-features-computing.html#feature-parameters",
    "title": "14  Computing features",
    "section": "\n14.4 Feature parameters",
    "text": "14.4 Feature parameters\nSeveral key parameters influence feature extraction:\n\n14.4.1 Number of features (K)\n\nControls feature vector dimensionality\nMore features capture more information\nIncreases computation and storage needs\nTypical range: 1,000-8,192\nDiminishing returns above ~4,000\n\n14.4.2 Patch size\n\nDetermines spatial context captured\nLarger patches see more context\nBut increase computation\nTypical size: 3x3 or 5x5 pixels\nMatch to imagery resolution\n\n14.4.3 Input channels\n\nDepends on available spectral bands\nRGB = 3 channels\nCan use additional bands\nMore bands = richer spectral info\nBut increases computation",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#practical-considerations",
    "href": "en/part-03-features/03-features-computing.html#practical-considerations",
    "title": "14  Computing features",
    "section": "\n14.5 Practical considerations",
    "text": "14.5 Practical considerations\n\n14.5.1 Memory management\nWhen processing large imagery datasets:\n\n14.5.2 Storage formats\nEfficient formats for large feature matrices:\n\n14.5.3 Parallel processing\nFor large-scale feature extraction:",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#quality-control",
    "href": "en/part-03-features/03-features-computing.html#quality-control",
    "title": "14  Computing features",
    "section": "\n14.6 Quality control",
    "text": "14.6 Quality control\nImportant checks during feature extraction:\n\n\nInput validation\n\nImage dimensions\nValue ranges\nMissing data\nBand ordering\n\n\n\nFeature statistics\n\nDistribution checks\nZero/missing values\nCorrelation analysis\nFeature importance\n\n\n\nPerformance monitoring\n\nMemory usage\nProcessing speed\nGPU utilization\nStorage efficiency",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/03-features-computing.html#best-practices",
    "href": "en/part-03-features/03-features-computing.html#best-practices",
    "title": "14  Computing features",
    "section": "\n14.7 Best practices",
    "text": "14.7 Best practices\n\n\nDocumentation\n\nRecord all parameters\nTrack data sources\nDocument processing steps\nNote any issues\n\n\n\nTesting\n\nUnit tests for functions\nIntegration tests\nPerformance benchmarks\nValidation checks\n\n\n\nVersion control\n\nCode versioning\nFeature versioning\nParameter tracking\nResult logging\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll work through a complete example of computing custom MOSAIKS features.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Computing features</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/04-features-demo.html",
    "href": "en/part-03-features/04-features-demo.html",
    "title": "15  Featurization demo",
    "section": "",
    "text": "15.1 Overview\nThis demonstration will show you a few key concepts",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Featurization demo</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/04-features-demo.html#demonstration-code",
    "href": "en/part-03-features/04-features-demo.html#demonstration-code",
    "title": "15  Featurization demo",
    "section": "\n15.2 Demonstration code",
    "text": "15.2 Demonstration code\nBelow is a link to a Jupyter notebook intended to demonstrate practical featurization of satellite data for use in MOSAIKS. The notebook will guide you through the process of preparing imagery, including:\n\nBuilding a pytorch model from scratch\nUsing an out of the box solution with torchgeo\nBuilding a torch dataset and dataloader\nFeaturizing satellite imagery\nSaving features to disk\nVisualizing features\n\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\nFor instructions and tips on using Google Colab, please refer to Chapter 23.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Featurization demo</span>"
    ]
  },
  {
    "objectID": "en/part-03-features/04-features-demo.html#whats-next",
    "href": "en/part-03-features/04-features-demo.html#whats-next",
    "title": "15  Featurization demo",
    "section": "\n15.3 What’s next?",
    "text": "15.3 What’s next?\nNow that we have covered the basics of featurizing satellite data, we will move on to the next section, where we will discuss modeling.\n\n\n\n\n\n\nLooking forward\n\n\n\nThis is the end of the feature section. Next, we will move on to the modeling labels with satellite features.",
    "crumbs": [
      "Satellite features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Featurization demo</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/00-model.html",
    "href": "en/part-04-models/00-model.html",
    "title": "Task modeling",
    "section": "",
    "text": "Section outline\nThe following chapters will guide you through key aspects of modeling tasks within the MOSAIKS framework:\nThese chapters provide",
    "crumbs": [
      "Task modeling"
    ]
  },
  {
    "objectID": "en/part-04-models/00-model.html#section-outline",
    "href": "en/part-04-models/00-model.html#section-outline",
    "title": "Task modeling",
    "section": "",
    "text": "Outline of the modeling section\n\n\n\n\n\nChapter\nKey Topics\n\n\n\n38  Construire, évaluer, déployer\nAlgorithm selection, hyperparameter tuning\n\n\n39  Parcourir l’espace\nSpatial cross-validation, geographic generalization\n\n\n40  Aller au fil du temps\nTime series analysis, temporal alignment\n\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nThe next chapter will",
    "crumbs": [
      "Task modeling"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html",
    "href": "en/part-04-models/01-model-choice.html",
    "title": "16  Build, evaluate, deploy",
    "section": "",
    "text": "16.1 Overview\nWhen using MOSAIKS (Multi-task Observation using SAtellite Imagery & Kitchen Sinks), model selection largely depends on your label data type. While more complex methods are certainly possible, experience shows that linear models often perform remarkably well. This is because the random convolutional features in MOSAIKS already capture and encode non-linear information from the underlying satellite imagery. This chapter will outline modeling approaches for different types of label data, and offer guidance on best practices for model evaluation.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#trainvalidation-and-test-splits",
    "href": "en/part-04-models/01-model-choice.html#trainvalidation-and-test-splits",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.2 Train/validation and test splits",
    "text": "16.2 Train/validation and test splits\nBefore jumping into the details, it is important to emphasize that all modeling tasks benefit from a systematic approach to training, validation, and testing:\n\n\nTrain/validation split (80% of the data)\n\n\nTest split (20% of the data)\n\nThis ensures that you have separate, unbiased datasets for both model tuning and final performance evaluation.\n\n\n\n\n\nFigure 16.1: Train/validation and test splits shown for a standard 5-fold cross validation procedure.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#continuous-labels",
    "href": "en/part-04-models/01-model-choice.html#continuous-labels",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.3 Continuous labels",
    "text": "16.3 Continuous labels\nMany MOSAIKS applications involve predicting continuous outcomes such as forest cover percentage, population density, average income, crop yields, or building height. In these cases, penalized linear regression approaches (especially ridge regression) work well. These methods offer simplicity, computational efficiency, and interpretability, while mitigating overfitting through the use of regularization.\n\n16.3.1 Ridge regression\nRidge regression (L2 regularization) is often the default choice in MOSAIKS applications because it effectively handles the large number of potentially correlated features produced by the random convolution process. It achieves this via an L2 penalty on the regression coefficients, which shrinks coefficients towards zero and reduces variance, thereby improving generalization.\nThe ridge regression objective function:\n\\[\n\\min_{\\beta} \\|y - X\\beta\\|^2_2 + \\lambda\\|\\beta\\|^2_2\n\\]\nWhere:\n\n\n\\(\\lambda\\) controls the strength of the regularization,\n\n\\(\\beta\\) are the regression coefficients,\n\n\\(y\\) is the vector of observed labels,\n\n\\(X\\) is the feature matrix produced by the MOSAIKS pipeline.\n\n16.3.2 Lasso regression\nLasso regression (L1 regularization) can actually set coefficients to exactly zero, effectively performing feature selection. The L1 penalty helps enforce sparsity, which can be valuable when interpretability or identification of key features is a priority. This property makes Lasso particularly valuable when you want to identify which MOSAIKS features contribute most strongly to predictions.\nThe lasso objective function:\n\\[\n\\min_{\\beta} \\|y - X\\beta\\|^2_2 + \\lambda\\|\\beta\\|_1\n\\]\nWhere:\n\n\n\\(\\lambda\\) again controls the strength of the penalty,\n\nThe \\(\\|\\beta\\|_1\\) term encourages some coefficients to be exactly zero.\n\nBoth can be easily implemented using scikit-learn:\nfrom sklearn.linear_model import Ridge, Lasso\n\n# Ridge regression\nridge = Ridge(alpha=1.0)  # alpha is the regularization strength (λ)\nridge.fit(X_train, y_train)\n\n# Lasso regression\nlasso = Lasso(alpha=1.0)\nlasso.fit(X_train, y_train)\n\n16.3.3 Why linear models work well\nThough the models themselves are linear, the features are not. MOSAIKS uses random convolutions, non-linear activation functions (ReLU), and average pooling to transform raw satellite imagery into highly expressive features. Because these transformations capture a broad range of non-linear spatial patterns, traditional linear methods can then perform well with minimal additional complexity.\n\n16.3.4 Evaluation metrics\nFor continuous outcomes, key evaluation metrics include:\n\n\nR² (coefficient of determination): Measures the proportion of variance in the label data explained by the model.\n\n\nRMSE (root mean squared error): Quantifies the average magnitude of the prediction errors.\n\n\nMAE (mean absolute error): Average absolute difference between predictions and true values, less sensitive to large outliers than RMSE.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#binary-classification",
    "href": "en/part-04-models/01-model-choice.html#binary-classification",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.4 Binary classification",
    "text": "16.4 Binary classification\nIn some MOSAIKS applications, your labels may be binary (e.g., building presence vs. absence, land use change vs. no change). Here, logistic regression often serves as a straightforward choice.\n\n16.4.1 Logistic regression\nLogistic regression models the probability that a given example belongs to the “positive” class:\n\\[\n\\text{logit}(p) = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_n x_n\n\\]\nwhere \\(p\\) is the probability of belonging to the positive class. Despite its simplicity, logistic regression provides robust and interpretable performance for many binary classification tasks with MOSAIKS features.\n\n16.4.2 Evaluation metrics\nFor binary classification, common metrics include:\n\n\nAUC-ROC: The area under the ROC curve, assessing the trade-off between true positive rate and false positive rate across different threshold settings.\n\n\nAccuracy: The proportion of correct predictions.\n\n\nPrecision: Of the positive predictions made, how many were correct?\n\n\nRecall: Of the actual positives in the dataset, how many did we correctly identify?\n\n\nF1 score: The harmonic mean of precision and recall, often used in imbalanced classification settings.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#multi-class-classification",
    "href": "en/part-04-models/01-model-choice.html#multi-class-classification",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.5 Multi-class classification",
    "text": "16.5 Multi-class classification\nSome applications require predicting multiple categories (e.g., land cover types, crop variety, building categories). These are multi-class classification problems. Several approaches are possible:\n\n\nOne-vs-Rest: Train a binary classifier for each class; each classifier distinguishes one class from “all others.”\n\n\nMultinomial (softmax) regression: A single model to predict probabilities across all classes simultaneously.\n\n\nOrdinal regression: For predicting ordered categories (e.g., mild, moderate, severe damage).\n\n\n\n\n\n\nFigure 16.2: Example of multiclass classification\n\n\n\n16.5.1 Evaluation metrics\nFor multi-class problems, consider:\n\n\nOverall accuracy: Percentage of examples correctly classified.\n\n\nPer-class accuracy: Accuracy within each class, useful if class sizes are imbalanced.\n\n\nConfusion matrix: Provides a detailed breakdown of predictions vs. actual classes.\n\n\nWeighted F1 score: Averages F1 across classes, weighting by class frequency.\n\n\nCohen’s kappa: Measures agreement between predicted and actual labels, adjusting for chance agreement.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#applying-the-model-to-make-predictions",
    "href": "en/part-04-models/01-model-choice.html#applying-the-model-to-make-predictions",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.6 Applying the model to make predictions",
    "text": "16.6 Applying the model to make predictions\nOnce you have selected a model and tuned it (e.g., via cross-validation), you can apply the model to new, unseen data. This step is often referred to as “inference” or “scoring”:\n\nPrepare features: The features for the new areas or times should be extracted using the same RCF model that was used to extract the original features. This means that a model made with custom made could not be able to features on the API. The features may be randomly created, but after the model is initialized, the weights are fixed.\nLoad the trained model: Ensure the model (along with any hyperparameters and preprocessing steps) is loaded exactly as it was trained. This consistency is critical for maintaining predictive accuracy.\n\nPredict: Pass the new feature matrix (X_new) into the trained model’s predict method to obtain predictions. For example, using scikit-learn:\ny_pred = ridge.predict(X_new)\nIf your task is classification, use predict_proba to get predicted probabilities:\np_pred = logistic_regression.predict_proba(X_new)\n\nInterpret and store results: Save the predictions in a structured format (e.g., CSV, GeoTIFF) for downstream analysis. Consider including metadata about the date and version of your model, the MOSAIKS feature extraction process, and any relevant notes on data quality.\n\nBy following these steps, you ensure that your MOSAIKS models are deployed effectively and consistently. From here, you can visualize the predictions, integrate them into downstream analyses, or inform policy and decision-making based on the model’s output.\n\n16.6.1 Addressing domain shift\nWhen applying your model to new geographic regions or under different conditions, be aware that the underlying data distribution (satellite imagery patterns, socioeconomic factors, land-use/land-cover types) may differ from your training set. This “domain shift” can lead to reduced predictive performance if the model has not been exposed to similar examples during training. To mitigate this, consider collecting additional representative training data from these new regions, adopting transfer learning or domain adaptation techniques, and quantifying predictive uncertainty so you can flag areas where the model may perform poorly. Periodic performance audits and retraining—especially when new data becomes available—help ensure robust generalization across diverse geographies.\nPredicting at higher resolution than the labels",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#quantifying-uncertainty",
    "href": "en/part-04-models/01-model-choice.html#quantifying-uncertainty",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.7 Quantifying uncertainty",
    "text": "16.7 Quantifying uncertainty",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#model-selection-workflow",
    "href": "en/part-04-models/01-model-choice.html#model-selection-workflow",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.8 Model selection workflow",
    "text": "16.8 Model selection workflow\n\n\nIdentify label type\n\nContinuous → Ridge or Lasso regression\n\nBinary → Logistic regression\n\nMulti-class → One-vs-Rest or Multinomial\n\n\n\nCross-validation\n\nSplit data into train, validation, and test sets, respecting spatial structure where possible (e.g., leave-cluster-out).\n\nSelect appropriate evaluation metrics (e.g., R² for continuous, ROC-AUC for binary).\n\nTune hyperparameters (\\(\\lambda\\) in ridge/lasso, regularization in logistic) using the validation set.\n\n\n\nModel deployment\n\nRetrain on the entire training set using the chosen hyperparameters.\n\nGenerate predictions on the test set (or new data).\n\nQuantify uncertainty (e.g., confidence intervals, out-of-sample error estimates).",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/01-model-choice.html#summary",
    "href": "en/part-04-models/01-model-choice.html#summary",
    "title": "16  Build, evaluate, deploy",
    "section": "\n16.9 Summary",
    "text": "16.9 Summary\n\n\nStart with simple linear models: Let MOSAIKS features do the heavy lifting of extracting non-linear patterns.\n\n\nMatch the metric to the task: R² or RMSE for continuous labels, AUC-ROC or F1 score for classification, etc.\n\n\nUse cross-validation: Always separate training and testing to maintain unbiased estimates of model performance.\n\n\nConsider spatial structure: When dealing with spatial data, standard random splits may lead to overly optimistic estimates of performance.\n\nThe key elements for successful model building include:\n\n\nAlgorithm Selection\n\nChoose based on label type\nConsider computational needs\nBalance complexity vs performance\n\n\n\nCross Validation\n\nUse spatial awareness in splits\nSelect appropriate metrics\nTune model parameters\n\n\n\nModel Evaluation\n\nTest out-of-sample performance\nValidate across space\nQuantify uncertainties\n\n\n\nDeployment\n\nTrain final model\nGenerate predictions\nDocument process\nMonitor performance\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter, we’ll discuss strategies for accounting for spatial dependencies in your modeling workflow, including methods for spatially stratified cross-validation, spatial interpolation, and spatial extrapolation.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Build, evaluate, deploy</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/02-model-spatial.html",
    "href": "en/part-04-models/02-model-spatial.html",
    "title": "17  Going over space",
    "section": "",
    "text": "17.1 Label super-resolution",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Going over space</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/02-model-spatial.html#label-super-resolution",
    "href": "en/part-04-models/02-model-spatial.html#label-super-resolution",
    "title": "17  Going over space",
    "section": "",
    "text": "HDI example",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Going over space</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/02-model-spatial.html#spatial-extrapolation",
    "href": "en/part-04-models/02-model-spatial.html#spatial-extrapolation",
    "title": "17  Going over space",
    "section": "\n17.2 Spatial extrapolation",
    "text": "17.2 Spatial extrapolation\n\nASM example (predicting mines in new countries)\nGo over feature space and show reduced dimension\n\nconvergence of countries vs divergence in labels\n\n\n\n\n\n\n\n\n\nClick the badge to run the demo in Google Colab!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓\nRemember to click File -&gt; Save a copy in Drive to save any changes you make.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Going over space</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/02-model-spatial.html#spatial-interpolation",
    "href": "en/part-04-models/02-model-spatial.html#spatial-interpolation",
    "title": "17  Going over space",
    "section": "\n17.3 Spatial interpolation",
    "text": "17.3 Spatial interpolation\n\nFilling in gaps from survey data. eg. you have population data for some areas but not all.\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter,",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Going over space</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html",
    "href": "en/part-04-models/03-model-temporal.html",
    "title": "18  Going over time",
    "section": "",
    "text": "18.1 Understanding temporal resolution\nTime series analysis in satellite-based ML applications requires careful attention to the temporal resolution of both your labels and imagery. In the context of MOSAIKS, you may opt for different strategies depending on the frequency of satellite acquisitions and how quickly your outcome of interest changes.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#understanding-temporal-resolution",
    "href": "en/part-04-models/03-model-temporal.html#understanding-temporal-resolution",
    "title": "18  Going over time",
    "section": "",
    "text": "Figure 18.1: ESRI visualization of pixel values for a given location changing over time.\n\n\n\n18.1.1 Temporal alignment\nWhen aligning data in time, consider:\n\nLabel frequency: How often are ground measurements collected? For instance, annual crop yields, monthly economic indicators, or even daily weather observations. The granularity of these data points will guide how to match them to your satellite-derived features.\nImagery availability: How frequently can you obtain clear satellite images of your area of interest? High revisit rates enable more frequent observations, but factors like cloud cover or sensor anomalies may reduce the actual number of usable images.\nChange detection: How quickly does your variable of interest change? Urban development may unfold over months or years, whereas flood events can occur within days. Matching the temporal granularity of your features to the dynamics of your phenomenon is crucial.\n\n18.1.2 Seasonal patterns\nBoth natural and human-driven processes often exhibit strong seasonal signals:\n\nNatural cycles: Vegetation growth, snow cover, and water extent are all influenced by seasons. For example, NDVI metrics might be more informative during peak growing seasons (Figure 18.2).\nHuman activities: Cropping cycles, holiday travel, and heating or cooling demand are just a few examples of how human behavior can vary throughout the year. These temporal rhythms can introduce systematic patterns in your data.\nFeature extraction: Because satellite observations reflect surface conditions, different times of the year may require distinct feature sets. For example, reflectance values change when vegetation is senescent vs. when it is fully grown. Similarly, atmospheric conditions (like haze) may be more prevalent in certain seasons.\n\n\n\n\n\n\nFigure 18.2: EOS Data Analytics time series visualization of the Normalized Difference Vegetation Index (NDVI) showing seasonal trends.\n\n\n\n18.1.3 Challenges in time series applications\nAlthough the potential benefits of time series analysis are significant, there are a few common pitfalls:\n\n18.1.3.1 Data gaps\n\nCloud cover: In regions with high cloud coverage, usable imagery can be sparse, leading to irregular time intervals between valid observations.\nSatellite maintenance or sensor dropout: Even short interruptions in satellite operations can reduce data availability.\nOrbital patterns: Some satellites have specific revisit schedules, meaning certain areas might not be imaged as frequently as others, leading to patchy time series data.\n\n\n\n\n\n\nFigure 18.3: Visualization of cloud cover over the Amazon rainforest.\n\n\n\n\n\n\n\n\nRecommended reading\n\n\n\nFor more information on cloud cover and its impact on satellite data, see Flores-Anderson et al. 2023.\n\n\n\n18.1.4 Pre-processed satellite products\nSeveral satellite providers offer pre-processed data products specifically designed for time series analysis. These products handle common challenges like cloud cover and normalization:\n\n18.1.4.1 MODIS vegetation indices\n\n16-day or monthly composites of vegetation indices (e.g., NDVI, EVI)\nAutomated cloud masking and quality control\nSurface reflectance values normalized for atmospheric effects\nGlobal coverage at 250m-1km resolution since 2000\nIdeal for monitoring seasonal vegetation dynamics\n\n18.1.4.2 Planet Basemap\n\nQuarterly visual composites from multiple PlanetScope satellites\nCloud-free mosaics using best available pixels\nColor-balanced and radiometrically calibrated\nGlobal coverage at ~4.7m resolution\nSuitable for tracking gradual land use changes\n\n18.1.4.3 Harmonized Landsat-Sentinel (HLS)\n\nCombined product using Landsat 8-9 and Sentinel-2 imagery\n2-3 day revisit frequency at 30m resolution\nAtmospherically corrected and co-registered\nConsistent surface reflectance values between sensors\nEnables dense time series from 2013-present\n\nThese products reduce the preprocessing burden for users but may not capture rapid changes that occur between compositing periods. The choice between using raw imagery or pre-processed products depends on the temporal resolution needed for your specific application. These data products and how to use them will be covered in greater detail in Chapter 31 and Chapter 32.\n\n18.1.4.4 Temporal consistency\n\nSensor drift: Over time, satellite sensors can degrade or drift, influencing the consistency of your data. Proper calibration can mitigate these issues.\nMulti-sensor calibration: If you are combining data from multiple satellites in a constellation, ensure that differences in sensor sensitivity or bands do not introduce spurious signals in your time series.\n\n\nVideo\nTime lapse imagery of North Platte, Nebraska. Imagery and visualization from planet Labs Inc.\n\n\n18.1.4.5 Storage and computation\n\nData volume: Each additional time step in your analysis increases the storage and processing requirements.\nTemporal correlation: Many time series phenomena exhibit autocorrelation, which can influence how you design and train models. Standard ML algorithms assume independence between samples, so specialized methods or features (such as lagged features) may be required to handle temporal dependencies.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#approaches-to-time-series-modeling",
    "href": "en/part-04-models/03-model-temporal.html#approaches-to-time-series-modeling",
    "title": "18  Going over time",
    "section": "\n18.2 Approaches to time series modeling",
    "text": "18.2 Approaches to time series modeling\nBelow are three common strategies for incorporating time series data within a MOSAIKS-like framework. Each approach has trade-offs in terms of complexity, computational cost, and interpretability.\n\n18.2.1 Feature stacking\nIn a feature-stacking approach, you generate MOSAIKS features for multiple time steps and then concatenate them into a single feature vector. This is straightforward but can lead to very large feature spaces if you have many time points.\n\nCompute features for each time period: Run your MOSAIKS feature extraction for each quarter, month, or year—whatever time granularity is relevant.\nConcatenate features: Combine them into a single vector, ensuring that naming conventions keep time steps distinguishable.\nModel training: Input the stacked features into your preferred machine learning algorithm (e.g., linear regression, random forest, or neural network).\n\nExample (quarterly stacking):\n# Create feature names for each quarter\nfeatures_Q1 = [f'X_{i}_Q1' for i in range(1000)]  # X_0_Q1, X_1_Q1, ..., X_999_Q1\nfeatures_Q2 = [f'X_{i}_Q2' for i in range(1000)]  # X_0_Q2, X_1_Q2, ..., X_999_Q2\nfeatures_Q3 = [f'X_{i}_Q3' for i in range(1000)]  # X_0_Q3, X_1_Q3, ..., X_999_Q3\nfeatures_Q4 = [f'X_{i}_Q4' for i in range(1000)]  # X_0_Q4, X_1_Q4, ..., X_999_Q4\n\n# Combine features names for all quarters\nfeatures_annual = features_Q1 + features_Q2 + features_Q3 + features_Q4\n\n# Total length = 4,000 features for four quarters\nfeatures_df = pd.DataFrame(data=features, columns=features_annual)\nThis approach is typically suitable for annual or seasonal data where the number of time steps remains manageable. However, it may be less practical if you have daily or weekly observations over several years.\n\n18.2.2 Temporal aggregation\nIn temporal aggregation, you compute features at a higher frequency but then summarize them over a time window:\n\nExtract features at a high frequency: This provides a rich temporal view.\nAggregate: Compute statistical summaries such as the mean, max, or variance of each feature across the chosen time window. Common windows include daily, weekly, monthly, and quarterly aggregations.\nModel with aggregated features: The aggregated features can represent dynamic processes while controlling the dimensionality of your dataset.\n\nThis method captures general trends and reduces noise from cloud cover or other transient factors. However, important temporal nuances (like specific short-lived events) might be lost in the aggregation.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#demeaning",
    "href": "en/part-04-models/03-model-temporal.html#demeaning",
    "title": "18  Going over time",
    "section": "\n18.3 Demeaning",
    "text": "18.3 Demeaning\nEvaluation over time\n\n18.3.1 Sequential modeling\nFor phenomena where temporal order is crucial and frequent observations exist, sequential modeling can be more powerful:\n\nFeature extraction: Maintain the time dimension in your feature matrix (e.g., one matrix per location, with time as rows and features as columns).\nApply time series modeling: Techniques like LSTM (Long Short-Term Memory) networks, temporal convolutional networks, or classical state-space models (e.g., ARIMA) can handle temporal dependencies explicitly.\nLagged relationships: Incorporate features from previous time steps to capture delayed effects (e.g., precipitation from last month affecting vegetation today).\n\nAlthough these methods provide a more nuanced view of temporal processes, they require additional modeling expertise and computational resources.\n\n\n\n\n\n\nStart with a simpler approach like feature stacking or temporal aggregation. If you find that your phenomenon has rapid or complex temporal dynamics that aren’t well-captured by these methods, then explore more advanced sequential models.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#hands-on-with-time-series-data",
    "href": "en/part-04-models/03-model-temporal.html#hands-on-with-time-series-data",
    "title": "18  Going over time",
    "section": "\n18.4 Hands on with time series data",
    "text": "18.4 Hands on with time series data\nIn lieu of time series MOSAIKS features, we will instead demonstrate similar examples using MODIS NDVI data. This will allow us to explore the challenges and opportunities of time series analysis without the need for custom feature extraction.\nNOTE: UPDATE ME with new notebook link.\n\n\n\n\n\n\nClick the badge to run the demo in Google Colab!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓\nRemember to click File -&gt; Save a copy in Drive to save any changes you make.",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#filling-temporal-gaps",
    "href": "en/part-04-models/03-model-temporal.html#filling-temporal-gaps",
    "title": "18  Going over time",
    "section": "\n18.5 Filling temporal gaps",
    "text": "18.5 Filling temporal gaps\nWhen working with time series data, you may encounter missing values due to cloud cover, sensor issues, or other factors. Here are some common strategies for filling these gaps:",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/03-model-temporal.html#summary",
    "href": "en/part-04-models/03-model-temporal.html#summary",
    "title": "18  Going over time",
    "section": "\n18.6 Summary",
    "text": "18.6 Summary\nHandling time series in satellite-based ML workflows requires balancing data volume, temporal alignment, and modeling complexity. While feature stacking can be effective for low-frequency or seasonal processes, more sophisticated techniques may be needed to capture high-frequency changes or long-range temporal dependencies. Ultimately, the “best” approach depends on the nature of your target variable, data availability, and the resources at your disposal.\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter we will look at",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Going over time</span>"
    ]
  },
  {
    "objectID": "en/part-04-models/04-model-demo.html",
    "href": "en/part-04-models/04-model-demo.html",
    "title": "19  Build a model",
    "section": "",
    "text": "This chapter is in early draft form and may be incomplete.\n\n\n\n\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nIn the next chapter we will look at",
    "crumbs": [
      "Task modeling",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Build a model</span>"
    ]
  },
  {
    "objectID": "en/part-05-responsible/00-responsible.html",
    "href": "en/part-05-responsible/00-responsible.html",
    "title": "Responsible SIML",
    "section": "",
    "text": "Section outline\nThe following chapters will discuss important aspects of model uncertainty and bias, as well as the ethical considerations in the context of MOSAIKS:\nThese chapters provide",
    "crumbs": [
      "Responsible SIML"
    ]
  },
  {
    "objectID": "en/part-05-responsible/00-responsible.html#section-outline",
    "href": "en/part-05-responsible/00-responsible.html#section-outline",
    "title": "Responsible SIML",
    "section": "",
    "text": "Chapter\nKey Topics\n\n\n\n42  Biais, capitaux propres et éthique\nResponsible use, communication, limitations\n\n\n43  Quantification de l’incertitude\nError sources, confidence intervals, validation\n\n\n44  Transparence (démo)\nDemonstrating how MOSAIKS can be used to characterize uncertainty\n\n\n\n\n\nTable 1: Outline of the uncertainty section\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nThe next chapter will",
    "crumbs": [
      "Responsible SIML"
    ]
  },
  {
    "objectID": "en/part-05-responsible/01-responsible-ethics.html",
    "href": "en/part-05-responsible/01-responsible-ethics.html",
    "title": "20  Bias, equity, & ethics",
    "section": "",
    "text": "This chapter is in early draft form and may be incomplete.\n\n\n\n\n\nhttps://www.earthcube.org/fair-training-materials\nhttps://www.fatml.org/\n\n\n\n\n\n\n\nLooking forward\n\n\n\nThe next chapter will\n\n\nCould include concepts from this paper: The politics of pixels: A review and agenda for critical remote sensing\nSociopolitical factors impact who collects remotely sensed data, how it is processed, and who benefits from the results. This paper discuses the politics of remote sensing and how it can be used to promote social justice and equity.",
    "crumbs": [
      "Responsible SIML",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Bias, equity, & ethics</span>"
    ]
  },
  {
    "objectID": "en/part-05-responsible/02-responsible-uncertainty.html",
    "href": "en/part-05-responsible/02-responsible-uncertainty.html",
    "title": "21  Quantifying uncertainty",
    "section": "",
    "text": "This chapter is in early draft form and may be incomplete.\n\n\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nThe next chapter will",
    "crumbs": [
      "Responsible SIML",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Quantifying uncertainty</span>"
    ]
  },
  {
    "objectID": "en/part-05-responsible/03-responsible-demo.html",
    "href": "en/part-05-responsible/03-responsible-demo.html",
    "title": "22  Transparency (demo)",
    "section": "",
    "text": "This chapter is in early draft form and may be incomplete.\n\n\n\n\n\n\n\n\n\n\nClick the badge to run the demonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOr to view a static version of the code on GitHub, click the badge below.\n\n\n\n\n\n\n\n\nLooking forward\n\n\n\nThe end! The only thing left is references.",
    "crumbs": [
      "Responsible SIML",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Transparency (demo)</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "This chapter is in early draft form and may be incomplete.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "fr/part-00-intro/00-intro.html",
    "href": "fr/part-00-intro/00-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Quand utiliser MOSAIKS?\nCette section présente les concepts fondamentaux de MOSAIKS (Multi-task Observation using Satellite Imagery & Kitchen Sinks) et fournit des conseils pratiques pour commencer à l’utiliser. Que vous soyez nouveau dans l’analyse des images satellites ou un praticien expérimenté, la compréhension de ces fondements est cruciale pour utiliser efficacement MOSAIKS dans votre travail.\nMOSAIKS comble le fossé entre le vaste potentiel de l’imagerie satellite et les applications pratiques en fournissant des:\nMOSAIKS est particulièrement précieux lorsque vous avez besoin de:\nCependant, MOSAIKS peut ne pas être le meilleur choix lorsque:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "fr/part-00-intro/00-intro.html#quand-utiliser-mosaiks",
    "href": "fr/part-00-intro/00-intro.html#quand-utiliser-mosaiks",
    "title": "Introduction",
    "section": "",
    "text": "Générer des prédictions dans de grandes zones géographiques\nTravailler avec des ressources de calcul limitées\nAnalyser plusieurs résultats en utilisant la même imagerie\nCréer des prédictions sans utiliser de l’apprentissage profond\nGénéraliser des analyses d’une application locale à une application globale\n\n\n\nVous avez besoin de prédictions à une résolution inférieure au kilomètre\nVotre résultat nécessite des bandes spectrales spécifiques\nLes prédictions en temps réel sont essentielles\nVotre application nécessite des features qui sont interprétables\n\n\n\n\n\n\n\nIl peut y avoir un outil existant qui répond à vos besoins.MOSAIKS n’est pas le meilleur choix pour chaque application.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "fr/part-00-intro/00-intro.html#aperçu-de-la-section",
    "href": "fr/part-00-intro/00-intro.html#aperçu-de-la-section",
    "title": "Introduction",
    "section": "Aperçu de la section",
    "text": "Aperçu de la section\nLes chapitres suivants vous guideront à travers le démarrage avec MOSAIKS:\n\n\n\n\n\n\n\n\n\n\nChapitre\nSujets clés\n\n\n\n\n23  Configuration\nGoogle Colab, Gestion des données, Pratiques de mise en œuvre\n\n\n24  C’est quoi MOSAIKS?\nConcepts de base, architecture système, capacités\n\n\n25  Accéder à MOSAIKS\nAccès à l’API, produits de données, authentification\n\n\n26  Essayer MOSAIKS\nWorkflow de base, analyse d’exemples, pièges communs\n\n\n\n\n\nTable 1: Aperçu de la section d’introduction\n\n\n\nCes chapitres fournissent à la fois la compréhension théorique et les compétences pratiques nécessaires pour commencer à travailler avec MOSAIKS. L’accent est mis sur la mise à disposition des prédictions par satellite tout en maintenant une rigueur scientifique et une efficacité informatique.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le chapitre suivant, nous allons configurer notre environnement informatique à l’aide de Google Colab. Ce cours utilise Colab pour démontrer divers aspects des MOSAIKS, dans un environnement gratuit et accessible.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html",
    "href": "fr/part-00-intro/01-intro-compute.html",
    "title": "23  Configuration",
    "section": "",
    "text": "23.1 Aperçu\nCe cours utilise Google Colab (Colab) pour nos besoins de calcul. Toutefois, tous les notebooks peuvent être exécutés en local sur votre ordinateur. Colab est une plate-forme gratuite basée sur le cloud qui permet d’écrire et d’exécuter du code Python via le navigateur. Il dispose de nombreuses bibliothèques préinstallées et offre un accès gratuit aux ressources informatiques, y compris les GPU.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#exigences",
    "href": "fr/part-00-intro/01-intro-compute.html#exigences",
    "title": "23  Configuration",
    "section": "23.2 Exigences",
    "text": "23.2 Exigences\nPour participer aux sections de codage de ce cours, vous aurez besoin:\n\nUn ordinateur portable ou un ordinateur de bureau\nUne connexion Internet fiable\nUn compte Google (si vous n’en avez pas, en créez un sur accounts.google.com) si vous souhaitez utilisez Google Colab\nUn navigateur Web (Chromium basé les navigateurs recommandés)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#démarrer-avec-google-colab",
    "href": "fr/part-00-intro/01-intro-compute.html#démarrer-avec-google-colab",
    "title": "23  Configuration",
    "section": "23.3 Démarrer avec Google Colab",
    "text": "23.3 Démarrer avec Google Colab\n\n23.3.1 Accès à Colab\n\nAllez sur colab.research.google.com\nConnectez-vous avec votre compte Google\nCliquez sur “Nouveau ordinateur portable”pour créer votre premier cahier Colab\n\n\n\n23.3.2 Comprendre l’interface\nL’interface Colab est similaire aux ordinateurs portables Jupyter, avec quelques composants clés:\n\nBarre de menu: Contient des options pour File,Edit, View,INSERT, Runtime, Outils et Help.\nBarre d’outils: Accès rapide aux actions courantes comme l’ajout de cellules de code/texte.\nZone de cellules: Où vous écrivez et exécutez du code ou du texte.\nÉtat d’exécution: Affiche l’état de la connexion de votre ordinateur portable aux serveurs de Google.\n\n\n\n23.3.3 Opérations de base\n\nCréation de cellules:\n\nCellules de code: cliquez sur + code. Prend en charge le code Python ou R en fonction de l’exécution sélectionnée\nCellules de texte: cliquez sur + Text. Prend en charge les balises Markdown et HTML pour la documentation\n\nLancer les cellules:\n\nCliquez sur le bouton de lecture à côté de la cellule ou utilisez Shift +Entrée\nPeut également sélectionner Runtime &gt; Exécutez la cellule (ou une autre option Exécuter) dans le menu\n\n\n\n\n23.3.4 Caractéristiques importantes\n\nType d’exécution:\n\n\nCliquez sur Runtime &gt; Changer le type d'exécution\nSélectionnez Python 3 comme l’exécution\nPour l’accès au GPU: modifiez l’accélérateur matériel en l’un des types GPU offerts en cas de besoin\n\n\nGestion des fichiers:\n\n\nLes fichiers téléchargés sur Colab sont temporaires et seront perdus lorsque le noyau se déconnecte.\nConnectez-vous à Google Drive et enregistrez-y des sorties pour le stockage persistant:\n\nfrom google.colab import drive\ndrive.mount ('/content/drive')\n\nInstallation du package:\n\nInstallez des packages supplémentaires en utilisant:\n\ncondaPip\n\n\n# AVERTISSEMENT: L'utilisation de \"!conda Install\" n'est pas recommandée. \n# En règle générale, utilisez la commande magique \"%conda install\" à la place.\n%conda install &lt;package_name&gt;\n\n\n# AVERTISSEMENT: L'utilisation de \"!pip install\" n'est pas recommandée. \n# En règle générale, utilisez à la place la commande magique \"%pip install\".\n%pip install &lt;package_name&gt;\n\n\n\n\n\n23.3.5 Meilleures pratiques\n\nEnregistrez votre travail:\n\n\nLes liens de ce livre créent une nouvelle copie d’un notebook car ils sont enregistrés sur Github.\nPour enregistrer toutes les modifications que vous apportez, cliquez sur Fichier &gt; Enregistrez une copie dans Drive\nTélécharger les notebooks sur votre ordinateur pour les sauvegarder également au besoin.\n\n\nGestion des ressources:\n\n\nFermer les notebooks inutilisés pour libérer les ressources\nSoyez conscient des délais d’attente inactifs (les notebooks se déconnectent après une inactivité prolongée)\n\n\nUtilisation de la mémoire:\n\n\nSurveiller l’utilisation de la mémoire via Runtime &gt; Afficher les ressources\nLe niveau libre de Colab fournit une mémoire très limitée (12 Go) et peut ne pas être suffisant pour les grands ensembles de données ou les modèles complexes\n\n\n\n23.3.6 Raccourcis clavier\nVoici quelques raccourcis clavier utiles pour travailler à Colab:\n\nWindows / LinuxMac\n\n\n\n\n\n\n\n\n\n\n\n\nRaccourci\nAction\n\n\n\n\nCtrl + M h\nAfficher les raccourcis clavier\n\n\nCtrl + Entrée\nExécutez la cellule actuelle\n\n\nShift + Entrée\nExécutez la cellule et passez à Suivant\n\n\nAlt + Entrée\nExécutez la cellule et insérer ci-dessous\n\n\nCtrl + M A\nInsérer la cellule de code ci-dessus\n\n\nCtrl + M B\nInsérer la cellule de code ci-dessous\n\n\nCtrl + M M\nConvertir en une cellule texte\n\n\nCtrl + M Y\nConvertir en une cellule de code\n\n\nCtrl + M D\nSupprimer la cellule actuelle\n\n\nCtrl + M L\nBasculer les numéros de ligne\n\n\nCtrl + M O\nBascule de sortie\n\n\nCtrl + M X\nCouper la cellule\n\n\nCtrl + M C\nCopier la cellule\n\n\nCtrl + M V\nColler la cellule ci-dessous\n\n\nShift + Up / Down\nSélectionnez plusieurs cellules\n\n\nCtrl + F\nTrouver et remplacer\n\n\nCtrl + S\nEnregistrer le cahier\n\n\n\n\n\nTable 23.1: Raccourcis clavier Windows/Linux\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccourci\nAction\n\n\n\n\n⌘ + M H\nAfficher les raccourcis clavier\n\n\n⌘ + Entrez\nExécutez la cellule actuelle\n\n\nShift + Entrée\nExécutez la cellule et passez à Suivant\n\n\nOption + Entrée\nExécutez la cellule et insérer ci-dessous\n\n\n⌘ + M A\nInsérer la cellule de code ci-dessus\n\n\n⌘ + M B\nInsérer la cellule de code ci-dessous\n\n\n⌘ + M M\nConvertir en une cellule texte\n\n\n⌘ + M Y\nConvertir en une cellule code\n\n\n⌘ + M D\nSupprimer la cellule actuelle\n\n\n⌘ + M L\nBasculer les numéros de ligne\n\n\n⌘ + M O\nBascule de sortie\n\n\n⌘ + M x\nCouper la cellule\n\n\n⌘ + M C\nCopier la cellule\n\n\n⌘ + M V\nColler la cellule ci-dessous\n\n\nShift + Up/Down\nSélectionnez plusieurs cellules\n\n\n⌘ + F\nTrouver et remplacer\n\n\n⌘ + S\nEnregistrer le cahier\n\n\n\n\n\nTable 23.2: Raccourcis clavier Mac\n\n\n\n\n\n\n\n\n23.3.7 Problèmes courants et solutions\n\nDéconnection du noyau:\n\n\nCliquez sur “Reconnecter” lorsque vous êtes invité\nVos variables seront réinitialisées, mais les modifications apportées au code demeurent\n\n\nProblèmes d’installation du package:\n\n\nRedémarrez le noyau après l’installation de nouveaux packages\nUtilisez Runtime&gt; Redémarrer runtime\n\n\nErreurs de mémoire:\n\n\nEffacer les variables inutiles au fur et à mesure\nEnvisagez d’utiliser des échantillons de données plus petits pendant le développement\n\n\n\n\n\n\n\nLes erreurs de mémoire sont courantes lorsque vous travaillez avec de grands ensembles de données ou des modèles complexes dans la version gratuite de Colab. Si vous rencontrez ces problèmes, envisagez d’utiliser une version payante de Colab ou de connecter une machine virtuelle de plateforme Google Cloud (VM).\n\n\n\n\n\n23.3.8 Obtenir de l’aide\n\nAccédez à la documentation de Colab: Aide &gt; Foire aux questions\nEssayez d’utiliser Google Gemini pour une assistance sur l’IA.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#assistance-ia-dans-colab",
    "href": "fr/part-00-intro/01-intro-compute.html#assistance-ia-dans-colab",
    "title": "23  Configuration",
    "section": "23.4 Assistance IA dans Colab",
    "text": "23.4 Assistance IA dans Colab\nGoogle Gemini est un puissant assistant IA intégré de manière transparente à Google Colab. Vous pouvez l’utiliser pour générer du code, des commentaires ou du texte Markdown pour améliorer vos notebooks.Gemini est accessible de plusieurs manières à Colab, tous commençant par sélectionner l’icône Gemini dans différentes parties de l’éditeur du notebook.\n\n\n\n\n\n\nIcône gemini\n\n\n\n\nRecherchez cette icône pour indiquer où vous pouvez cliquer pour accéder à Gemini dans Colab.\n\n\nVoici quelques façons d’utiliser Google Gemini efficacement dans Colab:\n\n23.4.1 Prise en charge du chat\nCliquez sur le bouton Gemini dans le coin supérieur droit pour ouvrir une interface de chat où vous pouvez poser des questions sur votre code, déboguer les problèmes ou obtenir des explications sur les concepts. Cette option est particulièrement utile pour les débutants ou pour s’attaquer aux problèmes complexes.\n\n\n23.4.2 Génération de code\nUtilisez l’option “Générer du code” (l’icône Étoile) au-dessus de n’importe quelle cellule de code vide pour générer un nouveau code en fonction de votre description. Vous pouvez lui demander de faire beaucoup de choses différentes, notamment:\n\nCharger un ensemble de données appelé my_data.csv\nConstruire un histogramme des données\nConstruire un modèle pour prédire Y de X\n\n\n\n23.4.3 Explication du code\nUtilisez l’option “Expliquer le code” (l’icône Étoile) au-dessus de n’importe quelle cellule de code complète pour ouvrir une interface de chat qui expliquera automatiquement le code dans la cellule. Ceci est utile pour comprendre le code écrit par quelqu’un d’autre, apprendre de nouveaux concepts ou obtenir un deuxième avis sur votre travail.\n\n\n23.4.4 Suggestion de code\nColab fournit une saisie semi-automatique intelligente au fur et à mesure que vous tapez:\n\nAppuyez sur Tab pour accepter les suggestions\nUtilisez Ctrl+Space (CMD+Space sur Mac) pour déclencher manuellement les suggestions\nObtenez de la documentation en temps-réel et des suggestions sur les paramètres\n\n\n\n\n\n\n\nBien que ces outils d’IA soient utiles, révisez et comprenez toujours le code qu’ils suggèrent avant de l’utiliser dans votre travail.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#accès-aux-notebooks-de-cours",
    "href": "fr/part-00-intro/01-intro-compute.html#accès-aux-notebooks-de-cours",
    "title": "23  Configuration",
    "section": "23.5 Accès aux notebooks de cours",
    "text": "23.5 Accès aux notebooks de cours\nTous les notebooks de cours sont hébergés sur GitHub et sont accessibles directement dans Google Colab. Il y a deux façons de les ouvrir:\n\n23.5.1 Méthode 1: Liens directs\nChaque section de ce livre comprend des liens directs “Ouvrir Dans Colab” pour les notebooks pertinents. Cliquez simplement sur l’insigne pour ouvrir le cahier.\nExemple \nCette méthode ouvrira une nouvelle copie du cahier car elle est enregistrée sur GitHub.Si vous avez déjà cliqué sur le badge une fois, apporté des modifications et enregistré votre cahier, vous devrez accéder à votre dossier de lecteur où il est enregistré pour accéder à ces modifications.\n\n\n\n\n\n\nCliquer sur le badge de ce livre ouvrira toujours une nouvelle copie.\n\n\n\n\n\n23.5.2 Méthode 2: cloner le cahier\nPour sélectionner un ordinateur portable dans le référentiel Référentiel de notebooks:\n\nOuvrir Google Colab (colab.research.google.com)\nCliquez sur Fichier &gt; Open Notebook\nSélectionnez l’onglet Github\nEntrez l’URL du référentiel: https://github.com/[nom_utilisateur]/[repo] (MISE A JOUR AVEC REPO)\nSélectionnez le notebook que vous souhaitez ouvrir\n\n\n\n23.5.3 Enregistrer votre travail\nLorsque vous ouvrez un notebook de GitHub dans Colab, il crée une copie temporaire. Pour enregistrer votre travail:\n\nCliquez sur Fichier&gt; Enregistrer une copie dans Drive\nCela crée votre propre copie modifiable dans votre Google Drive\nToutes les modifications futures seront enregistrées à votre copie\n\n\n\n23.5.4 Organisation du notebook\nLes notebooks de cours sont organisés en:\n\ndemos/: Notebooks de démonstration complets\nexercices/: Notebooks interactifs avec des exercices à compléter\nsolutions/: Versions complètes des notebooks d’exercice\n\nChaque notebook comprend:\n\nDes instructions et explications claires dans les cellules Markdown\nDes cellules de code avec des exemples ou des exercices\nDes sections À FAIRE pour des exercices\nDes cellules de validation pour vérifier votre travail",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#accès-et-gestion-des-données",
    "href": "fr/part-00-intro/01-intro-compute.html#accès-et-gestion-des-données",
    "title": "23  Configuration",
    "section": "23.6 Accès et gestion des données",
    "text": "23.6 Accès et gestion des données\nIl existe plusieurs façons d’accéder aux données dans les notebooks Colab. Voici les principales approches:\n\n23.6.1 Téléchargements directs\nPour les données hébergées sur des référentiels comme Zenodo, vous pouvez télécharger directement à l’aide de wget:\n# Téléchargez les données\n! wget https://zenodo.org/records/14040658/files/data.zip\n\n# Dézip les données\n! unzip data.zip\n\n\n23.6.2 Intégration avec Google Drive\n\n23.6.2.1 Monter Google Drive\nPour les données stockées dans Google Drive:\n\nTout d’abord, montez votre Google Drive:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nAccédez à vos données à l’aide du chemin monté:\ndrive_path = \"/content/drive/MyDrive/&lt;project_folder&gt;\"\n\n\n\n23.6.2.2 Copier les données sur la machine virtuelle (facultative)\nPour de meilleures performances, faites des copies locales des données sur la machine virtuelle (VM):\nimport os\nimport shutil\n\n# Create local directory\nlocal_dir = \"/content/data/\"\nos.makedirs(local_dir, exist_ok=True)\n\n# Copy data from Drive to VM\ndrive_data = os.path.join(drive_path, \"my_data\") \nshutil.copytree(drive_data, local_dir, dirs_exist_ok=True)\n\n\n\n\n\n\nN’oubliez pas que le stockage de la machine virtuelle est temporaire - les fichiers seront supprimés lorsque l’exécution sera déconnecté. Gardez toujours une sauvegarde de vos données dans le lecteur ou un autre emplacement de stockage permanent.\n\n\n\n\n23.6.2.2.1 Pourquoi copier des données dans la machine virtuelle?\nLorsque vous travaillez avec des données dans Colab, la copie de fichiers de Google Drive vers la machine virtuelle (VM) peut considérablement améliorer les performances:\n\nAccès plus rapide: La lecture directement depuis Google Drive nécessite que les données soient transférées sur le réseau pour chaque opération. Le stockage VM local offre des vitesses de lecture/écriture beaucoup plus rapides.\nRéduction de latence: la latence du réseau entre Colab et Google Drive peut ralentir les opérations qui nécessitent plusieurs accès de données. Les données locales éliminent cette latence.\nPlus fiable: Les problèmes de connectivité réseau ou les problèmes d’accès à la conduite n’interrompent pas votre analyse une fois les données copiées localement.\nMieux pour le traitement itératif: Si votre code doit lire les mêmes données plusieurs fois (comme dans les boucles d’entraînement d’apprentissage automatique), l’accès local est beaucoup plus efficace.\n\nPar exemple, la lecture d’un ensemble de données de 1 Go de Drive peut prendre 30 secondes, tandis que la lecture du stockage VM local pourrait ne prendre que quelques secondes. Le temps passé à copier des données une fois au début de votre session peut gagner un temps important pendant l’analyse. Cela est particulièrement vrai dans un environnement de notebook où un utilisateur peut développer un code qui accède à plusieurs reprises aux mêmes fichiers de données, mais ne peut pas tout stocker en mémoire (par exemple, de nombreux fichiers d’image).\n\n\n\n23.6.2.3 Enregistrer les sorties sur Google Drive\nPour enregistrer les sorties ou les modèles sur Google Drive:\n# Définissez le répertoire de sortie\noutput_dir = \"/ content / drive / mydrive / project_folder / output\"\n\n# Enregistrer les sorties\nshuttil.copyTree (local_output, output_dir, dirs_exist_ok = true)\nCela garantit que tout travail effectué dans le cahier est enregistré sur votre Google Drive pour référence future.Si les fichiers de sortie ne sont pas copiés et restent dans la machine virtuelle, ils seront perdus lorsque l’exécution se déconnecter.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/01-intro-compute.html#configuration-de-lenvironnement-local",
    "href": "fr/part-00-intro/01-intro-compute.html#configuration-de-lenvironnement-local",
    "title": "23  Configuration",
    "section": "23.7 Configuration de l’environnement local",
    "text": "23.7 Configuration de l’environnement local\nBien que l’approche principale de ce livre soit d’utiliser Google Colab, certains apprenants peuvent préférer ou doivent exécuter le code localement. Le livre est largement configuré pour ce faire, bien que l’utilisateur devra gérer son propre environnement informatique. À cette fin, nous fournissons un fichier environment.yml (situé dans le répertoire environment de ce livre). Vous trouverez ci-dessous les étapes pour vous permettre de configurer avec MiniConda et créer un environnement local.\n\n\n\n\n\n\nBien que les environnements locaux puissent offrir plus de contrôle, nous recommandons fortement Google Colab pour la cohérence et les ressources cloud gratuites. Cette configuration locale est purement facultative et peut être plus adaptée à ceux qui ont des dépendances particulières ou des configurations avancées.\n\n\n\n\n23.7.1 Téléchargement et installation de miniconda\nMiniConda est un installateur minimal pour Conda. Choisissez l’installateur de votre système d’exploitation dans les liens ci-dessous et suivez les invites.\n\nWindowsMacOSLinux\n\n\n\nAccédez à la Miniconda Windows Installer.\nTéléchargez l’installateur .exe pour votre système Windows (64 bits recommandé).\nDouble-cliquez sur l’installateur et suivez les instructions à l’écran.\nLorsque vous êtes invité, vérifiez l’option pour ajouter MiniConda au chemin ou sélectionnez Installer pour tous les utilisateurs qui ajoute généralement conda au chemin automatiquement.\n\n\n\n\nAllez au Miniconda MacOS Installer.\nTéléchargez l’installateur .pkg (ou.sh si vous préférez) pour macOS (64 bits).\nDouble-cliquez sur l’installateur et suivez les instructions à l’écran.\nLorsque vous êtes invité, vérifiez l’option pour ajouter MINICONDA au chemin ou ajouter les lignes de chemin appropriées à votre fichier ~/.zshrc ou ~ /.bash_profile le fichier manuellement.\n\n\n\n\nAllez à la Miniconda Linux Installer.\nTéléchargez l’installateur .sh pour votre distribution Linux (64 bits recommandés).\nOuvrez un terminal et exécutez bash miniconda3-latest-linux-x86_64.sh.\nSuivez les invites;Envisagez de permettre au programme d’installation d’initialiser MiniConda pour votre coquille (ajoutant Conda à votre chemin).\n\n\n\n\n\n\n23.7.2 Ajout de conda à votre chemin\nSi vous n’avez pas ajouté de conda à votre chemin pendant l’installation, vous pouvez le faire manuellement en ajoutant une ligne à votre fichier de configuration de shell (~/.bashrc, ~/.zshrc, ou similaire):\n# Exemple pour les utilisateurs de Linux / MacOS\nexport PATH=\"$HOME/miniconda3/bin:$PATH\"\nPour Windows, assurez-vous que vous avez sélectionné l’option pour ajouter Conda au chemin pendant l’installation, ou exécutez l’invite Anaconda (qui a automatiquement Conda disponible) pour gérer votre environnement.\n\n\n23.7.3 Création d’un environnement local à partir du fichier environment.yml\nDans le répertoire environment du référentiel de cours, vous trouverez un fichier nommé environment.yml. Ce fichier répertorie tous les packages nécessaires à la configuration locale.\n\nClone ou télécharger le référentiel de livres sur votre machine locale.\nOuvrez un terminal (ou invite anacondasur Windows).\nNaviguez vers le dossier contenant environment.yml.\n\ncd path/to/MOSAIKS-Training-Manual/environment\n\nCréer l’environnement:\n\nconda envate -f environnement.yml\n\nActiver l’environnement:\n\nconda activate &lt;environment_name&gt;\nOù &lt;environment_name&gt; est le nom spécifié dans environment.yml (vérifiez le champ name: dans le fichier). Dans ce cas, le nom est mosaiks.\n\n\n23.7.4 Utilisation du nouvel environnement dans VS Code\nVisual Studio Code (VS Code) peut détecter et utiliser votre nouvel environnement Conda pour le développement de Python.\n\nOuvrir VS Code.\nInstallez l’extension Python (si elle n’est pas déjà installée).\nAppuyez sur Ctrl+Shift+P (ou CMD+Shift+P sur MacOS) et type “Python: Sélectionnez l’interpréteur”.\nSélectionnez l’interprète associé à votre environnement nouvellement créé (il doit être répertorié par nom ou chemin).\nOuvrez ou créez un nouveau fichier ou un cahier Python et vérifiez que le code VS utilise l’environnement correct (vous pouvez voir l’environnement choisi dans le coin inférieur droit du code vs).\n\n\n\n23.7.5 Autres gestionnaires de l’environnement\nBien que conda soit un outil commun pour gérer les environnements Python, il existe d’autres options populaires telles que:\n\nPoetry\n\npipenv\n\nvirtualenv\n\nChacun a ses propres fichiers de configuration et ses instructions de configuration.Si vous préférez ces outils ou que vous les utilisez déjà, vous pouvez généralement reproduire les packages répertoriés dans environment.yml. Vérifiez la documentation de l’outil respectif pour des instructions spécifiques sur la façon de traduire les dépendances.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le chapitre suivant, nous examinerons de plus près le cadre Mosaiks, ses concepts principaux et comment il peut être appliqué pour résoudre des problèmes réels.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Configuration</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html",
    "href": "fr/part-00-intro/02-intro-mosaiks.html",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "",
    "text": "24.1 Le défi\nÀ l’heure actuelle, de nombreux systèmes de satellites publics collectent tous les jours d’énormes quantités de données sur le monde. Mais il y a tellement d’images (téraoctets par jour) que c’est difficile de les trier à la main ; et elles sont trop complexes et non structurées pour être utilisable sous leur forme brute pour la plupart des applications.\nC’est pourquoi lier l’imagerie par satellite à l’apprentissage automatique (parfois appelé SIML ou SatML) est incroyablement puissant.Il permet de transformer de grandes quantités de données d’image non structurées en informations structurées qui peuvent être utilisées pour la planification, la recherche et la prise de décision.\nNotre but est de démocratiser l’accès et l’utilisation des technologies SIML, mais nous reconnaissons que beaucoup de ceux qui bénéficieraient de ces outils n’ont pas le temps ou les ressources pour gérer d’énormes ensembles de données d’imagerie satellite et à apprendre comment les exploiter avec l’apprentissage automatique.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#le-défi",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#le-défi",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "",
    "text": "Figure 24.1: Représentation visuelle des satellites en orbite autour de la Terre.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#la-solution",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#la-solution",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.2 La solution",
    "text": "24.2 La solution\nC’est pourquoi nous avons développé MOSAIKS. MOSAIKS vise à réduire les obstacles à l’entrée dans SIML, afin de diversifier les utilisateurs de cette technologie puissante ainsi que les problèmes qu’il aide à résoudre.\nMOSAIKS est conçu pour fonctionner hors de la boîte pour un large éventail d’applications SIML, pour les personnes sans expertise SIML qui travaillent sur des ordinateurs de bureau ou ordinateurs portable normaux. Pour de nombreuses applications, les utilisateurs de MOSAIKS n’ont jamais à toucher eux-mêmes l’imagerie par satellite et n’ont besoin que d’une formation statistique de base.\n\nSi vous pouvez exécuter une régression, vous pouvez utiliser MOSAIKS!\n\nMOSAIKS permet aux utilisateurs de créer leurs propres nouveaux ensembles de données à partir d’images satellites. Nous ne contrôlons pas les variables que les utilisateurs regardent et nous n’avons jamais besoin de savoir. MOSAIKS est un système qui permet aux utilisateurs de transformer rapidement de grandes quantités d’images en cartes de nouvelles variables, en utilisant leurs propres données de formation.\nSi vous avez déjà été curieux d’essayer l’apprentissage automatique avec l’imagerie par satellite, mais que vous ne connaissez rien de l’apprentissage automatique ou de l’imagerie par satellite, MOSAIKS est pour vous.\nEt si vous en savez beaucoup sur l’apprentissage automatique et l’imagerie satellite, MOSAIKS pourrait toujours être pour vous, car il fonctionne aussi bien que des méthodes d’apprentissage profond mais est beaucoup plus simple et moins cher à utiliser.\n\n\n\n\n\n\nFigure 24.2: Framework des modèles d’apprentissage profond (c’est-à-dire l’apprentissage automatique avec des réseaux de neurones artificiels) appliqué à l’imagerie. Dans cet exemple, le modèle tente de classer le véhicule de l’image.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#comment-fonctionne-mosaiks",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#comment-fonctionne-mosaiks",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.3 Comment fonctionne MOSAIKS?",
    "text": "24.3 Comment fonctionne MOSAIKS?\n\n\n\n\n\n\nLecture recommandée\n\n\n\nUne approche généralisable et accessible de l’apprentissage automatique avec l’imagerie par satellite mondiale (Rolf et al. 2021)\n\n\n\n24.3.1 Dissocier les utilisateurs des images\nL’idée de base de MOSAIKS est de séparer les utilisateurs du processus coûteux et difficile de transformer les images en variables d’entrée (appelées “features”) pour un algorithme d’apprentissage automatique en aval (Images → X). L’équipe de MOSAIKS a calculé ces features à l’échelle mondiale. Ainsi, dans de nombreux cas d’utilisation, les utilisateurs n’ont jamais à télécharger ou à gérer eux-mêmes les images. Au lieu de cela, ils téléchargent un tableau des features de MOSAIKS (X) ; ils les lient ensuite à leurs propres données géocodées sur le résultat (Y) qu’ils sont intéressés à prédire à partir de l’imagerie satellite (nous appelons ces données étiquettes). Puis ils exécutent une régression linéaire (ou tout autre modèle de ML) pour prédire leurs étiquettes en utilisant ces caractéristiques MOSAIKS (y = Xβ). Cette prédiction peut être effectuée dans des emplacements, des périodes de temps et à des résolutions spatiales pour lesquelles les étiquettes ne sont pas disponibles.\n\n\n\n  \n\n\nFigure 24.3: Cette image fausse montre des sommets enneigés et des crêtes de l’Himalaya oriental entre les principales rivières du sud-ouest de la Chine. L’Himalaya est composé de trois chaînes de montagnes parallèles qui s’étendent ensemble sur plus de 1800 miles (2900 kilomètres). Cette image particulière a été prise par le radiomètre avancé à émission thermique et de réflexion d’origine spatiale de la NASA (ASTER), volant à bord du satellite Terra, le 27 février 2002. L’image est un composite fabriqué en combinant des longueurs d’onde proche infrarouge, rouge et verte. (Source: NASA)\n\n\n\n\n\n24.3.2 Généralisation de MOSAIKS\nÉtant donné que les features MOSAIKS synthétisent les informations contenues dans des images brutes qui ne sont pas adaptées à une tâche spécifique (par exemple, la biodiversité, le revenu des ménages, l’utilisation des terres), de nombreux utilisateurs peuvent utiliser les mêmes features de MOSAIKS et les associer simplement à leurs propres étiquettes en fonction de l’emplacement. Les utilisateurs peuvent exécuter leur analyse sur tous les logiciels statistiques avec lesquels ils sont à l’aise. Pour la plupart des applications, les demandes informatiques ne nécessiteront pas que les utilisateurs travaillent avec des machines spécialisées, car les ordinateurs de bureau et les ordinateurs portables fonctionnent.\n\n\n\n\n\n\nFigure 24.4: MOSAIKS est conçu pour résoudre rapidement un nombre illimité de tâches à l’échelle de la planète. Après une unique étape de création de features non-supervisée utilisant des filtre de convolution aléatoires, MOSAIKS stocke et distribue des features agnostiques des tâches aux utilisateurs ; chaque utilisateur génère ensuite des prédictions dans un nouveau contexte. A L’imagerie satellite est partagée sur plusieurs tâches potentielles. B Schéma du processus de MOSAIKS. N images sont transformées en utilisant des filtres de convolution aléatoires en un vecteur de fonctionnalité compressé et hautement descriptif K avant que les étiquettes soient connues. Une fois les features calculées, ils peuvent être stockés sous forme tabulaire (matrice X) et utilisés pour les tâches illimitées sans aucun nouveau calcul. Les utilisateurs intéressés par une(s) tâche(s) fusionnent leurs propres étiquettes (ys) avec les features pour l’entraînement. Ici, l’utilisateur 1 a des étiquettes de couverture forestière pour les emplacements p + 1 à N et l’utilisateur 2 a des étiquettes de densité de population pour les emplacements 1 à q. Chaque utilisateur entraîne ensuite une seule régression linéaire pour βs.Les prédictions obtenues en utilisant βs et l’échantillon complet des features de MOSAIKS X permettent de générer des estimations SIML pour les valeurs d’étiquette à tous les emplacements. Le caractère généralisable permet à différents utilisateurs de résoudre différentes tâches en utilisant une procédure identique et le même tableau des features, en changeant uniquement les données d’étiquette fournies par l’utilisateur pour l’entraînement. Chaque tâche peut être résolue par un utilisateur sur un ordinateur de bureau en quelques minutes sans que les utilisateurs ne manipulent les images. C Illustration du calcul unique non supervisé des filtres/patchs de convolution aléatoires. Les patchs K sont échantillonnés au hasard à travers les images N. Chaque patch est convolué sur chaque image, générant une carte d’activation non linéaire pour chaque patch. Les cartes d’activation sont moyennées sur des pixels pour générer un seul vecteur de fonctionnalité K-dimensionnel pour chaque image. (Source: Rolf et al. 2021 Figure 1)\n\n\n\n\n\n24.3.3 Pourquoi ça marche\nMOSAIKS fonctionne parce que les features MOSAIKS capturent une énorme quantité d’informations sur les couleurs, les motifs et les textures qui apparaissent dans l’imagerie satellite. Nous ne savons pas quels motifs/ couleurs/textures seront importants pour l’application que les utilisateurs ont (car nous ne savons pas quelles applications les utilisateurs essaieront), nous essayons donc de tout capturer. Le but de l’étape de régression est d’entraîner un modèle à apprendre les motifs/couleurs/textures qui prédisent les étiquettes, puis d’utiliser cette compréhension pour faire des prédictions dans les endroits où les utilisateurs n’ont pas d’étiquettes. De plus, MOSAIKS encode les informations des images de sorte que les relations non linéaires entre les étiquettes et les images sont présentes dans les features même si la régression que les utilisateurs implémente est généralement une régression linéaire.\n\n\n\n\n\n\nFigure 24.5: Exemple de 4 (sur 4000) features de MOSAIKS (à droite) calculées à partir d’images satellites (à gauche). Ces features ont été choisies au hasard parmi ce qui est disponible sur l’API MOSAIKS.\n\n\n\nPour en savoir plus sur ces features, voir Chapitre 34 où nous essayons de fournir une intuition pour ce qu’est une fonctionnalité et comment elle est faite.\n\n\n24.3.4 Cinq étapes pour utiliser MOSAIKS\n\n\n\n\n\n\nCette section est un aperçu très large des étapes pour utiliser les MOSAIKS. Les chapitres ultérieurs fourniront des conseils plus détaillés sur chaque étape.\n\n\n\nDans de nombreux cas, les utilisateurs cherchant à prédire un résultat (une tâche) à partir des satellitaires peuvent le faire en utilisant des features d’imagerie pré-calculées (X) dans un cadre de régression linéaire simple. Plus tard dans ce cours, nous détaillerons des workflows plus personnalisés qui restent traitables mais offrirons plus de flexibilité. Cependant dans le cas standard, la procédure d’utilisation de MOSAIKS comporte cinq étapes (la figure correspondante de Rolf et al. est ci-dessous):\n\nTélécharger les features de MOSAIKS pré-calculées (X) correspondant aux emplacements où vous avez des étiquettes (Chapitre 25).\nFusionner les features avec vos étiquettes (Y) en fonction de l’emplacement (donc les features en position P sont liées à des étiquettes en position P) (Chapitre 29).\nExécutez une régression de la crête validée de vos étiquettes sur les caractéristiques MOSAIKS (Y = Xβ + e; ou tout autre modèle que vous choisissez! Voir Chapitre 38).\nÉvaluer les performances.\nUtilisez les résultats du modèle de régression (β) pour faire des prédictions (Xβ) dans une nouvelle région d’intérêt où vous n’avez pas d’étiquettes, en utilisant uniquement les caractéristiques MOSAIKS (X) qui correspondent à ces nouveaux emplacements.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#que-peuvent-prédire-les-mosaiks",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#que-peuvent-prédire-les-mosaiks",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.4 Que peuvent prédire les MOSAIKS?",
    "text": "24.4 Que peuvent prédire les MOSAIKS?\n\n\n\n\n\n\nCette question est répondue plus en détail dans Chapitre 27\n\n\n\nMOSAIKS a été utilisé avec succès pour prédire un large éventail de tâches, notamment:\n\nConditions environnementales (couverture forestière, élévation)\nModèles de population (densité, lumières nocturnes)\nIndicateurs économiques (revenu, prix des logements)\nInfrastructure (réseaux routiers)\n\nLa figure ci-dessous provient de la publication originale des MOSAIKS (Rolf et al. 2021). Les cartes à gauche montrent les étiquettes d’entrée.Les cartes de droite montre les prédictions du modèle. Le nuage de points représente les prédictions du modèle contre les véritables étiquettes et rapporte le coefficient de détermination (R²) comme mesure des performances.\n\n\n\n\n\n\nFigure 24.6: (100000 images diurnes ont été converties en 8192 caractéristiques et stockées. Sept tâches ont ensuite été sélectionnées en fonction de la couverture et de la diversité. Des prédictions ont été générées pour chaque tâche en utilisant la même procédure. Cartes gauche: 80000 observations utilisées pour l’entraînement et la validation, agrégés jusqu’à 20 km × 20 km par cellule pour l’affichage. Nuages de points: Estimations de l’ensemble de validation (axe vertical) par rapport à la vérité (axe horizontal) : chaque point correspond à une cellule 1 km x 1 km. La ligne noire correspond à la première bissectrice (droite à 45°). Les performances des ensembles de test et de validation sont quasiment identiques ; Les estimations de l’ensemble de validation sont affichées uniquement pour enrichir les graphes. Dans les 3 premières tâches, l’échantillonnage est uniforme sur tout l’espace ; les 4 tâches du bas ont un échantillonnage pondéré par la population. Les zones grises n’ont pas été échantillonnées dans l’expérience. Source: Rolf et al.2021 Figure 2)\n\n\n\nIl est important de noter que toutes ces prédictions utilisent le même ensemble de features satellites - il n’est pas nécessaire de retraiter les images pour différentes tâches. MOSAIKS atteint une précision comparable aux méthodes d’apprentissage profond plus complexes, mais à une fraction du coût de calcul. C’est le pouvoir des MOSAIKS, il supprime la nécessité de retraiter les images après l’encodage initial.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#mosaiks-est-il-toujours-le-meilleur-choix",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#mosaiks-est-il-toujours-le-meilleur-choix",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.5 MOSAIKS est-il toujours le meilleur choix?",
    "text": "24.5 MOSAIKS est-il toujours le meilleur choix?\nNon! MOSAIKS est un outil puissant, mais ce n’est pas toujours le meilleur choix pour chaque application. En fait, ce n’est généralement pas le “meilleur” choix pour toute application. Nous visons à être compétitifs avec les principaux modèles, donc le véritable avantage de MOSAIKS est dans sa simplicité, son accessibilité et son évolutivité pour l’utilisateur moyen.\nNous vous recommandons de commencer par rechercher des méthodes existantes développées pour votre application, avant d’investir du temps et des ressources dans MOSAIKS. Un excellent endroit pour commencer cette recherche est à Satellite-image-deep-learning où vous pouvez trouver une liste de méthodes d’apprentissage profond qui ont été développées pour l’imagerie satellitaire, ainsi que les ensembles de données existants, les outils et tutoriels.\nLe monde du SIML est vaste et en évolution rapide. Cela signifie qu’il y a un bon choix que vous n’avez pas à faire vous-même des prédictions à l’échelle mondiale. Au lieu de cela, vous pourriez être en mesure d’utiliser ou de construire à partir du travail acharné de beaucoup d’autres sur le terrain.\nSi vous avez un contexte spécifique où vous voulez des informations sur mesure ou une variable/tâche que personne d’autre n’a prédit auparavant, alors vous voulez des MOSAIKS. Non seulement MOSAIKS vous permettra de faire des prédictions dans un nouveau contexte, mais cela vous permettra également de le faire rapidement et avec un minimum de ressources informatiques.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#matériaux-de-cours",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#matériaux-de-cours",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.6 Matériaux de cours",
    "text": "24.6 Matériaux de cours\nTODO: Ajouter une conférence enregistrée ici.\nDiapositives de la conférence.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/02-intro-mosaiks.html#résumé",
    "href": "fr/part-00-intro/02-intro-mosaiks.html#résumé",
    "title": "24  C’est quoi MOSAIKS?",
    "section": "24.7 Résumé",
    "text": "24.7 Résumé\nMOSAIKS est un outil puissant qui permet aux utilisateurs de prédire un large éventail de résultats de l’imagerie satellite à l’aide de features pré-rémunérées.Le système est conçu pour être accessible aux utilisateurs sans expérience préalable de l’apprentissage automatique ou de l’imagerie satellite. Le cadre MOSAIKS implique cinq étapes simples\n\nTélécharger les features\nFusionner avec les étiquettes\nExécutez une régression\nÉvaluer les performances\nFaire des prédictions\n\nDans ce livre, nous explorerons toutes les façons dont il s’agit d’une simplification excessive.Vous apprendrez à adapter ce cadre à vos propres besoins et à comprendre les limites et les hypothèses du système MOSAIKS.De nombreuses compétences présentées dans ce manuel de formation seront applicables à d’autres workflows d’imagerie par satellite et d’apprentissage automatique.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le chapitre suivant, vous serez présenté à l’API MOSAIKS qui est une ressource gratuite et ouverte pour accéder aux features de MOSAIKS pré-calculées.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>C'est quoi MOSAIKS?</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/03-intro-api.html",
    "href": "fr/part-00-intro/03-intro-api.html",
    "title": "25  Accéder à MOSAIKS",
    "section": "",
    "text": "25.1 Introduction\nÀ la base, MOSAIKS nécessite deux entrées principales: les features du satellite et les données de vérité au sol. Notre objectif est de rendre ces features aussi accessibles que possible afin que la majorité des utilisateurs n’aient pas à se soucier des détails techniques du traitement des images satellites.\nÀ cette fin, nous avons travaillé pour développer plusieurs façons d’accéder aux features de MOSAIKS:\n:Résumé des sources de caractéristiques de MOSAIKS. La colonne de pondération indique que les caractéristiques ont été générées à une résolution de 0,01 degrés et sont pondérées lorsqu’elles sont agrégées jusqu’à des résolutions plus faibles. Les schémas de pondération disponibles sont basés sur la zone du polygone d’agrégation, ou par la population du polygone d’agrégation. {#tbl-features-options}\nL’API de MOSAIKS doit être considérée comme le principal moyen d’accéder aux features. Il s’agit d’une interface conviviale qui vous permet de télécharger des features pour n’importe quel emplacement sur la terre. L’API est conçue pour être accessible aux utilisateurs de tout niveau technique, des débutants jusqu’aux experts.Pour plus de détails sur les features disponibles sur l’API, voir Chapitre 35.\nCependant, il existe de nombreux paramètres où les utilisateurs souhaiteront ou devront calculer leurs propres features personnalisées. Chapitre 36 détaille le processus.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Accéder à MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/03-intro-api.html#introduction",
    "href": "fr/part-00-intro/03-intro-api.html#introduction",
    "title": "25  Accéder à MOSAIKS",
    "section": "",
    "text": "Option\nSource d’imagerie\nCouverture spatiale\nRésolution spatiale\nRésolution temporelle\nPondération\n\n\n\n\nAPI MOSAIKS\nPlanet Labs Visual Basemap\nZones terrestres mondiales\n0,01 °\n2019 Q3\nNon pondéré\n\n\nAPI MOSAIKS\nPlanet Labs Visual Basemap\nZones terrestres mondiales\n0,1 °, 1 °\n2019 Q3\nZone et population\n\n\nAPI MOSAIKS\nPlanet Labs Visual Basemap\nZones terrestres mondiales\nADM0, ADM1, ADM2\n2019 Q3\nZone et population\n\n\nRolf et al 2021\nGoogle Static Maps\nÉtats-Unis continentaux (~ 100 000 emplacements)\n0,01°\n2019\nnon pondéré\n\n\n\n\n\n\n\n\n\n\n\n\nChapitres - Chapitre 23 à - Chapitre 8 couvrent les features accessibles au public\nChapitres - Chapitre 31 à - Chapitre 37 couvrent le calcul des features à partir des images",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Accéder à MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/03-intro-api.html#api-mosaiks",
    "href": "fr/part-00-intro/03-intro-api.html#api-mosaiks",
    "title": "25  Accéder à MOSAIKS",
    "section": "25.2 API MOSAIKS",
    "text": "25.2 API MOSAIKS\n\n\n\n\n\n\nLien API MOSAIKS\n\n\n\napi.mosaiks.org\n\n\nL’API de MOSAIKS est une interface conviviale qui vous permet de télécharger des features pour n’importe quel emplacement terrestre sur Terre.L’API est conçue pour être accessible aux utilisateurs ayant une gamme d’horizons techniques, des débutants aux experts.Pour profiter de l’API, vous devrez vous inscrire à un compte.\n\n25.2.1 Créer à un compte\nVisitez api.mosaiks.org.\n\n\n\n\n\n\nFigure 25.1: Page de connexion pour l’API MOSAIKS\n\n\n\nSélectionnez Register pour créer un compte.Vous devrez fournir un nom d’utilisateur, un e-mail et un mot de passe.\n! Page d’inscription pour l’API Mosaiks.\nUne fois enregistré, vous pouvez vous connecter pour commencer à télécharger des features MOSAIKS.\n\n\n\n\n\n\nFigure 25.2: Mosaiks API Page de destination.\n\n\n\n\n\n25.2.2 Ressources de l’API\nDepuis la page de destination, vous pouvez lire des informations supplémentaires sur les mosaïques et les ressources d’accès pour vous aider à démarrer.\n\n\n\n\n\n\nCe livre est développé pour vous fournir toutes les informations dont vous avez besoin pour utiliser MOSAIKS.\n\n\n\nL’API contient les pages suivantes:\n\n\n\n\n\n\n\n\n\n\nPage\nDescription\n\n\n\n\nHome\nPage de destination pour l’API.Contient des informations générales sur l’utilisation des MOSAIKS et de l’API\n\n\nFichiers précomposés\nCaractéristiques pré-composées à des échelles de limites administratives\n\n\nHDI\nIndice de développement humain mondial (HDI) estime aux niveaux de la municipalité et de la grille\n\n\nGlobal Grids\nPrécompagne et sur zone ou population à 0,1 ° et 1 ° Résolution\n\n\nMap Query\nCaractéristiques pré-composées à une résolution de 0,01 degré, l’utilisateur définit la boîte de délimitation sur la zone d’intérêt\n\n\nFichier Query\nfeatures pré-composées à une résolution de 0,01 degré, le fichier de téléchargement de l’utilisateur avec des coordonnées de latitude et de longitude\n\n\nMes fichiers\nFichiers que vous avez interrogés à partir de l’API, disponibles en téléchargement\n\n\nRessources\nExemple de notebooks Python et R pour utiliser le cadre MOSAIKS\n\n\n\n\n\nTable 25.1: Pages et descriptions de l’API MOSAIKS.\n\n\n\n\n\n25.2.3 features de l’API\nActuellement, l’API MOSAIKS a un seul ensemble de features globales (avec plusieurs niveaux d’agrégation). Les features sont disponibles gratuitement au public pour télécharger;C’est le moyen le plus rapide et le plus simple de commencer à utiliser MOSAIKS.\nLes features de l’API utilisent l’imagerie d’entrée de Planet Labs, Inc. Visual Basemap Produit mondial trimestriel 2019 (trimestre 3). La qualité de l’image, et donc la qualité des caractéristiques, peut être affectée par des conditions locales. Par exemple, une zone subissant une saison des pluies au troisième trimestre (de juillet à septembre) est susceptible de contenir des artefacts d’image de la couverture nuageuse. Cela affectera à son tour les calculs des features.Pour plus de détails sur l’imagerie d’entrée Chapitre 31.\nCompte tenu de la nature statique de l’API, le moyen le plus simple de commencer avec les MOSAIKS est d’avoir des données d’étiquette pendant une période récente (idéalement à partir de 2019 pour les étiquettes en évolution rapide, ou une année claire pour des étiquettes plus stables).\n\n\n\n\n\n\nFigure 25.3: Planet Labs BasEmap Imagery (à gauche) et 4 des 4 000 features MOSAIKS téléchargées à partir de l’API (à droite).\n\n\n\n\n\n\n\n\n\nL’utilisation de MOSAIKS pour des données de séries chronologiques est possible et peut bien fonctionner, mais cela nécessite actuellement de calculer vos propres features personnalisées.Voir Chapitre 36 et Chapitre 40 pour plus d’informations.\n\n\n\nLes caractéristiques MOSAIKS sont créées à l’aide d’une grille terrestre mondiale de latitude de latitude de 0,01 x 0,01 degrés.Ce sont les features natives disponibles en téléchargement à partir de l’API, mais il propose également des features pré-agrégées à une résolution de 0,1 et 1 degré, ainsi que des limites administratives (ADM0, ADM1 et ADM2).\n\n\n25.2.4 Caractéristiques haute résolution\nLa requête de fichier et la requête MAP sont les deux méthodes pour obtenir les features haute résolution (0,01 degrés) via l’API.Pour plus de simplicité, nous stockons ces features dans un format tabulaire avec des coordonnées de latitude et de longitude.Ces coordonnées sont le centre de chaque cellule de grille.\nLorsque vous téléchargez les features haute résolution (0,01 degré), vous les recevrez dans un format .csv tabulaire où:\n\nChaque ligne (N) représente une cellule de grille unique\nLes deux premières colonnes contiennent des coordonnées de latitude et de longitude (grille centroïdes)\nLes colonnes restantes représentent K features (actuellement * k * = 4000 features)\n\n\nRemarque: Il y a une limite de N = 100000 enregistrements par requête\n\n\n25.2.4.1 Requête de carte\n\nCréer des boîtes rectangulaires en spécifiant les coordonnées de latitude et de longitude\nPlusieurs boîtes peuvent être créées\nLe système affiche un nombre estimé d’enregistrements pour chaque boîte\nNotez que les estimations sont basées sur la zone de la boîte et peuvent ne pas refléter le nombre d’enregistrements réels, en particulier pour les zones contenant des mers et des océans\n\n\n\n\n\n\n\nFigure 25.4: MOSAIKS API Map Query Page.\n\n\n\n\n\n\n\n\n\nUtilisez Geojson.io pour trouver les coordonnées de la boîte de délimitation pour votre zone d’intérêt.\n\n\n\n\n\n25.2.4.2 Requête de fichier\n\nSoumettre un fichier avec des coordonnées de latitude et de longitude personnalisées\nL’API renvoie les features des cellules de grille les plus proches de vos coordonnées d’entrée\nLes points sont alloués au point de grille le plus proche s’ils ne correspondent pas exactement\nLe fichier de sortie peut avoir un nombre différent de lignes de votre entrée\nLa commande de points peut changer dans la sortie\n\n\n\n\n\n\n\nFigure 25.5: Query de fichier API\n\n\n\n\n\n\n25.2.5 Caractéristiques agrégées\nDe nombreux utilisateurs peuvent trouver plus facile de travailler avec des features agrégées à un certain niveau.L’API MOSAIKS propose des features pré-agrégées pour répondre à ces besoins.L’API propose plusieurs niveaux, y compris les plus grandes cellules de grille (0,1 et 1 degré) ou résumées aux limites administratives (ADM0, ADM1 et ADM2).Ces fichiers sont disponibles en téléchargement en tant que fichiers simples ou en morceaux en fonction de la résolution.\n\n\n\n\n\n\nFigure 25.6: Exemple montrant de 3 caractéristiques de convolution aléatoires représentatives (lignes).Les caractéristiques sont téléchargées à partir de l’API MOSAIKS à une résolution de 0,01 ° (la résolution native) et agrégées à 3 niveaux, y compris (a) des cellules de grille plus grandes (0,1 °), (b) les comtés et (c) états.\n\n\n\n\n25.2.5.1 schémas de pondération\nÀ chaque niveau d’agrégation, nous proposons des caractéristiques pondérées et des caractéristiques pondérées par la population.Les poids de la population proviennent de la population grillée du monde (GPWv4) ensemble de données de densité de la population.Le schéma de pondération de la zone est basé sur la zone des cellules de grille haute résolution.\n\n\n25.2.5.2 Quand utiliser des features agrégées\nLes features agrégées sont particulièrement utiles dans quelques scénarios:\n\nVous avez des données à une échelle plus grande que les cellules de grille de 0,01 degrés.De nombreux ensembles de données viennent au niveau du pays, de l’État ou du comté.\nVos données ont beaucoup de bruit qui peut être lissée en agrégeant à plus grande échelle.Un exemple courant de cela peut être des données d’enquête auprès des ménages qui sont bruyantes au niveau individuel mais se lissent lorsqu’elles sont agrégées au niveau du village ou du district.\nVous voulez effectuer une analyse globale et n’avez pas les ressources de calcul pour travailler avec les cellules de la grille complètes de 0,01 degrés.\n\nDans tous les cas, l’utilisation des features pré-agrégées peut vous faire gagner du temps et des ressources de calcul.\n\nScénario: Vous travaillez avec une étude de mesure des normes de vie - Des enquêtes intégrées sur l’agriculture (LSMS-ISA). Cet ensemble de données propose des données d’enquête avec les coordonnées géographiques au niveau du ménage.Pour protéger, la vie privée des répondants, les données sont gênées dans un rayon de 5 km, mais elle reste toujours dans les limites administratives locales.Vous pouvez donc résumer vos étiquettes aux unités administratives et créer un modèle avec les features agrégées.\n\n\n\n\n\n\n\nSi vous souhaitez faire des prédictions haute résolution, avec des données d’étiquette à basse résolution, vous pouvez créer votre modèle avec des features agrégées et utiliser les features haute résolution pour faire des prédictions.Cela sera couvert dans Chapitre 39.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Accéder à MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/03-intro-api.html#utilisation-de-features-mosaiks-pour-la-prédiction",
    "href": "fr/part-00-intro/03-intro-api.html#utilisation-de-features-mosaiks-pour-la-prédiction",
    "title": "25  Accéder à MOSAIKS",
    "section": "25.3 Utilisation de features MOSAIKS pour la prédiction",
    "text": "25.3 Utilisation de features MOSAIKS pour la prédiction\n\n\n\n\n\n\nCeci est un bref aperçu.Des instructions détaillées apparaissent plus tard dans le manuel (Chapitre 38).\n\n\n\nFlux de travail de base:\n\nObtenez des mesures de vérité au sol (“étiquettes”; voir Chapitre 27)\nTéléchargez les features de correspondance (voir Chapitre 35 pour plus de détails).\nFusionner les étiquettes et les features spatialement (voir Chapitre 29)\nUtiliser la régression pour modéliser la relation entre l’imagerie et les résultats (voir Chapitre 38)\nUtiliser les résultats de la régression pour prédire les résultats dans de nouveaux emplacements (voir Chapitre 38)\n\nVous pouvez expérimenter diverses approches d’apprentissage automatique à l’étape de régression.Pour les débutants, nous vous recommandons de commencer avec notre exemple de cahier Jupyter (Chapitre 26) qui démontre une approche de régression de crête simple (adaptée aux utilisateurs R et Python).\n\n\n\n\n\n\nFigure 25.7: En utilisant MOSAIKS, une conception simplifiée du flux de travail.\n\n\n\nCe sujet sera abordé plus en profondeur dans les chapitres ultérieurs (voir Chapitre 38). Dans le chapitre suivant, vous verrez un simple flux de travail MOSAIKS qui reproduit les résultats de Rolf et al.2021.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Accéder à MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/03-intro-api.html#exigences-de-citation",
    "href": "fr/part-00-intro/03-intro-api.html#exigences-de-citation",
    "title": "25  Accéder à MOSAIKS",
    "section": "25.4 Exigences de citation",
    "text": "25.4 Exigences de citation\nLorsque vous faites référence à la méthodologie MOSAIKS ou lors de la génération de features de MOSAIKS, veuillez référence: Rolf et al.«Une approche généralisable et accessible de l’apprentissage automatique avec l’imagerie par satellite mondiale.»Nature Communications (2021).\nVous pouvez utiliser le bibtex suivant:\n@article{article,\n    author = {Rolf, Esther and Proctor, Jonathan and Carleton, Tamma and Bolliger, Ian and Shankar, Vaishaal and Ishihara, Miyabi and Recht, Benjamin and Hsiang, Solomon},\n    year = {2021},\n    month = {07},\n    pages = {},\n    title = {A generalizable and accessible approach to machine learning with global satellite imagery},\n    volume = {12},\n    journal = {Nature Communications},\n    doi = {10.1038/s41467-021-24638-z}\n}\nSi vous utilisez des features téléchargées à partir de l’API, veuillez référence, en plus de la publication ci-dessus, l’API MOSAIKS.\nVous pouvez citer l’API en utilisant le bibtex suivant:\n @misc{MOSAIKS API,\n    author = {{Carleton, Tamma and Chong, Trinetta and Druckenmiller, Hannah and Noda, Eugenio and Proctor, Jonathan and Rolf, Esther and Hsiang, Solomon}},\n    title = {{Multi-Task Observation Using Satellite Imagery and Kitchen Sinks (MOSAIKS) API}},\n    howpublished = \"\\url{ https://api.mosaiks.org }\",\n    version = {1.0},\n    year = {2022},\n}\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le chapitre suivant, vous aurez la chance d’essayer les MOSAIKS sur Google Colab avec les données de Rolf et al 2021.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Accéder à MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html",
    "href": "fr/part-00-intro/04-intro-demo.html",
    "title": "26  Essayer MOSAIKS",
    "section": "",
    "text": "26.1 Aperçu\nCette démo reproduit les résultats clés de la publication originale de MOSAIKS (Rolf et al. 2021). Alors que MOSAIKS a un grand potentiel pour améliorer l’accès à la prédiction par satellite dans des régions avec de faibles données, l’article d’origine s’est concentré sur la démonstration de performances aux États-Unis où des données d’entraînement de haute qualité étaient facilement disponibles.\nLes États-Unis ont servi de terrain d’essai idéal pour plusieurs raisons:\nCette validation dans un environnement riche en données était cruciale pour établir des MOSAIKS comme un outil fiable avant de les déployer dans des contextes où les données de vérité au sol sont rares ou peu fiables.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html#aperçu",
    "href": "fr/part-00-intro/04-intro-demo.html#aperçu",
    "title": "26  Essayer MOSAIKS",
    "section": "",
    "text": "De nombreuses données de vérité au sol disponibles sur plusieurs variables\nréférence spatiale fiable des données\nDivers paysages et environnements construits\nCapacité à comparer les méthodes existantes\nValidation systématique des prédictions",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html#code-de-démonstration",
    "href": "fr/part-00-intro/04-intro-demo.html#code-de-démonstration",
    "title": "26  Essayer MOSAIKS",
    "section": "26.2 code de démonstration",
    "text": "26.2 code de démonstration\n\n26.2.1 Workflow\nVous trouverez ci-dessous un lien vers un Jupyter Notebook destiné à démontrer l’utilisation pratique des mosaïques avec des données réelles.En fait, ce notebook utilise les données d’entrée et les features d’origine de Rolf et al.2021. Le code démontre:\n\nChargement des fonctionnalités et étiquettes de MOSAIKS pré-calculés\nFusion des features et des étiquettes\nFormation d’un modèle de régression de la crête\nÉvaluation des prédictions\nVisualiser les résultats\n\n\n\n26.2.2 Données d’étiquette\nLa démo présente MOSAIKS prédisant plusieurs variables et avec un sous-ensemble des données utilisées dans le papier d’origine. Les variables incluent:\n\nCover ForestÉlévationDensité de populationLumières nocturnesRevenuLa longueur des routes\n\n\n\n\n\n\n\n\nFigure 26.1: Données d’entrée de la couverture forestière (à gauche) de Global Land Analysis & Discover (GLAD) Global 2010 Tree Cover (30 m)\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.2: Données d’entrée d’altitude (à gauche) fournies par Mapzen, et accessible via le service de carreaux de terrain Amazon Web Services (AWS). Le code de téléchargement peut être trouvé ici.\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.3: Données d’entrée de densité de population (à gauche) de l’ensemble de données Gridded Population of the World (GPW).Ces données sont accessibles ici.\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.4: Nighttime Lights Luminosité Données d’entrée (à gauche) générées par l’imagerie satellite nocturne, qui est fournie par le groupe d’observations de la Terre à la National Oceanic and Atmospheric Administration (NOAA) et au National Geophysical Data Center (NGDC).Ces données sont accessibles ici.\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.5: Données sur l’apport de revenus (à gauche) de l’American Community Survey (ACS) Estimations à 5 ans du revenu annuel médian des ménages en 2015. Ces données sont accessibles à l’aide du package ACS Dans R (48), numéro de tableau B19013\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.6: Données d’entrée de la longueur des routes (à gauche) de l’ensemble de données national des transports du United States Geological Survey (USGS), qui est basé sur les données Tiger / Line fournies par le Bureau du recensement américain en 2016. Ces données sont accessibles ici.\n\n\n\n\n\n\nUn utilisateur doit simplement sélectionner la variable qu’il souhaite prévoir, et aucune autre modification ne doit être apportée au code.Toutes les données ont été prétraitées et le code téléchargera les fichiers nécessaires à partir de Zenodo.\n\n\n26.2.3 Contraintes\nPour rester dans les limites de niveau libre de la mémoire Colab, nous sous-ensembles les données.Nous prenons un échantillon aléatoire de 50% des deux fonctionnalités (K=4000 au lieu de 8192) et des observations (N=50000 au lieu de 100000) par rapport au papier d’origine. Malgré l’utilisation de cet ensemble de données réduit, la démo obtient toujours de fortes performances prédictives, mettant en évidence l’efficacité de MOSAIKS.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html#exécutez-le-code",
    "href": "fr/part-00-intro/04-intro-demo.html#exécutez-le-code",
    "title": "26  Essayer MOSAIKS",
    "section": "26.3 Exécutez le code!",
    "text": "26.3 Exécutez le code!\n\n\n\n\n\n\nCliquez sur l’insigne pour exécuter la démonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n\nN’oubliez pas de cliquer sur Fichier -&gt; Enregistrez une copie dans Drive pour enregistrer toutes les modifications que vous apportez.\n— Ou pour afficher une version statique du code sur GitHub, cliquez sur l’insigne ci-dessous.\n\n\n\nPour les instructions et les conseils sur l’utilisation de Google Colab, veuillez vous référer à Chapitre 23.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html#vous-ne-voulez-pas-exécuter-de-code",
    "href": "fr/part-00-intro/04-intro-demo.html#vous-ne-voulez-pas-exécuter-de-code",
    "title": "26  Essayer MOSAIKS",
    "section": "26.4 Vous ne voulez pas exécuter de code?",
    "text": "26.4 Vous ne voulez pas exécuter de code?\nPensez plutôt à regarder cette démonstration!\n\n\n\n\n\n\nFigure 26.7: Un aperçu des MOSAIKS et une démonstration en direct de la génération de nouvelles prédictions à l’aide du système.Vidéo enregistrée par la télédétection planétaire généralisée cigare - Session de convention 2020.Présenté par Esther Rolf et Tamma Carleton.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-00-intro/04-intro-demo.html#quelle-est-la-prochaine-étape",
    "href": "fr/part-00-intro/04-intro-demo.html#quelle-est-la-prochaine-étape",
    "title": "26  Essayer MOSAIKS",
    "section": "26.5 Quelle est la prochaine étape?",
    "text": "26.5 Quelle est la prochaine étape?\nAprès avoir établi les capacités de MOSAIKS dans le contexte américain, l’équipe de développement de MOSAIKS a réussi à démontrer le système dans de nombreux contextes supplémentaires. Cela inclut à l’échelle globale ou dans les paramètres avec des données de qualité inférieure ou de faible qualité.Dans les prochains chapitres, nous explorerons certaines de ces applications, montrant comment les MOSAIKS peuvent aider à combler les lacunes de données dans les régions où la collecte traditionnelle des données est difficile ou coûteuse.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans la section suivante, nous examinerons de plus près les données d’étiquette qui peuvent être utilisées avec MOSAIKS.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Essayer MOSAIKS</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/00-labels.html",
    "href": "fr/part-01-labels/00-labels.html",
    "title": "Données étiquetées",
    "section": "",
    "text": "Aperçu\nCette section explore les données de référence (étiquettes) pouvant être utilisées pour entraîner un modèle prédictif avec MOSAIKS. Bien que le système soit conçu pour être flexible quant aux types de variables cibles qu’il peut prédire, comprendre ce qui définit de bonnes données d’étiquettes et savoir comment les préparer correctement est essentiel pour obtenir de bons résultats.\nLes données étiquetées représentent la « réalité » que MOSAIKS cherche à prédire – qu’il s’agisse de rendements de culture, de densité de population, d’indicateurs économiques ou de toute autre variable potentiellement visible (directement ou indirectement) dans des images satellitaires. La qualité et les caractéristiques de ces données influencent fortement les performances du modèle.",
    "crumbs": [
      "Données étiquetées"
    ]
  },
  {
    "objectID": "fr/part-01-labels/00-labels.html#quels-sont-les-critères-qui-garantissent-la-qualité-dun-jeu-de-données-étiquetées",
    "href": "fr/part-01-labels/00-labels.html#quels-sont-les-critères-qui-garantissent-la-qualité-dun-jeu-de-données-étiquetées",
    "title": "Données étiquetées",
    "section": "Quels sont les critères qui garantissent la qualité d’un jeu de données étiquetées ?",
    "text": "Quels sont les critères qui garantissent la qualité d’un jeu de données étiquetées ?\nPour des performances optimales avec MOSAIKS, les données étiquetées doivent présenter plusieurs caractéristiques clés :\n\nInformations précises sur la localisation géographique\n\nRésolution spatiale adéquate (typiquement ≥1 km²)\n\nAlignement temporel raisonnable avec les caractéristiques d’imagerie\n\nTaille d’échantillon suffisante (en général ≥300 observations)\n\nLien observable avec des caractéristiques de surface",
    "crumbs": [
      "Données étiquetées"
    ]
  },
  {
    "objectID": "fr/part-01-labels/00-labels.html#plan-de-la-section",
    "href": "fr/part-01-labels/00-labels.html#plan-de-la-section",
    "title": "Données étiquetées",
    "section": "Plan de la section",
    "text": "Plan de la section\nLes chapitres suivants vous guideront à travers les considérations essentielles pour travailler avec des données d’étiquettes dans MOSAIKS :\n\n\n\n\n\n\n\n\nChapitre\nSujets clés\n\n\n\n27  Quelles étiquettes fonctionnent ?\nExemples d’applications, analyse de performance, validation\n\n\n28  Données d’enquête\nIntégration d’enquêtes, conception d’échantillonnage, référencement géographique\n\n\n29  Préparation des étiquettes\nNettoyage des données, jointures spatiales, contrôle de la qualité\n\n\n8  Label data demo\nExemple pratique, flux de travail opérationnel, dépannage\n\n\n\n\n\nTable 1: Plan de la section sur les données d’étiquettes\n\n\nCes chapitres fournissent à la fois des conseils pratiques pour préparer vos propres données d’étiquettes et une compréhension plus approfondie des types de variables que MOSAIKS peut prédire efficacement.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le prochain chapitre, nous examinerons plus de 100 variables différentes qui ont été testées avec MOSAIKS, en analysant ce qui fonctionne bien et ce qui fonctionne moins bien.",
    "crumbs": [
      "Données étiquetées"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html",
    "href": "fr/part-01-labels/01-labels-100-maps.html",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "",
    "text": "27.1 Aperçu\nMOSAIKS est conçu pour être utile dans la prédiction de tout ce qui peut être visible dans l’imagerie satellitaire. Certaines choses sont plus faciles à prédire que d’autres, mais le système est conçu pour être flexible. Par exemple, certaines variables peuvent être observées directement dans l’imagerie elle-même, comme le couvert forestier, qui émet un signal vert clairement visible. D’autres résultats ne peuvent être prédits que par des relations indirectes entre les données d’imagerie et les étiquettes. Par exemple, le revenu et le prix des logements ne sont pas directement visibles dans les images brutes, mais leurs valeurs peuvent être estimées de manière fiable à partir d’objets (ex. : voitures), de textures (ex. : matériau de toiture) et de couleurs (ex. : infrastructure routière grise) contenues dans l’imagerie.\nDans ce chapitre, nous discuterons d’un nouvel article en cours de rédaction (Proctor et al., in prep.) qui explore la question de ce qui peut et ne peut pas être prédit de manière fiable à partir de l’imagerie satellitaire en utilisant MOSAIKS. Cet article examine plus de 100 résultats différents et rapporte la performance prédictive de chacun avec MOSAIKS. Nous analyserons les résultats d’une sélection de ces résultats en détail et donnerons un aperçu général des autres. Bien entendu, cette liste de résultats n’est pas exhaustive et la performance rapportée peut varier considérablement selon le contexte et, en particulier, en fonction de la qualité des données de vérité terrain. Ces résultats constituent une première exploration de ce qui pourrait être possible avec SIML en utilisant MOSAIKS, mais nous encourageons les utilisateurs à mener leurs propres expériences, car les résultats sont susceptibles de différer dans de nouveaux contextes. L’article préliminaire de Proctor et al. sera publié ici lorsqu’il sera disponible publiquement.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html#aperçu",
    "href": "fr/part-01-labels/01-labels-100-maps.html#aperçu",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "",
    "text": "Figure 27.1: La polyvalence de MOSAIKS en fait un outil parfait pour un large éventail d’applications.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html#cent-cartes",
    "href": "fr/part-01-labels/01-labels-100-maps.html#cent-cartes",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "\n27.2 Cent cartes",
    "text": "27.2 Cent cartes\n\n27.2.1 Publication originale\nDans Rolf et al. 2021, les auteurs ont testé MOSAIKS sur 7 variables cibles : le couvert forestier, le revenu, le prix des logements, la densité de population, la luminosité nocturne et l’altitude. La zone d’étude est axée sur la partie continentale des Etats-unis. C’est un excellent point de départ pour comprendre les capacités de MOSAIKS, Vu que la qualité des données est élevée pour un ensemble varié de résultats. Bien que les résultats aient montré un potentiel significatif et démontré l’utilité de MOSAIKS, le véritable test réside dans son application à de nouvelles variables et à de nouvelles régions géographiques.\n\n27.2.2 Passer à l’échelle mondiale\nPour tester l’applicabilité mondiale de MOSAIKS sur un ensemble varié de thématique, deux éléments principaux ont été nécessaires :\n1. La création d’un ensemble global de features\n\n\n\n\n\nFigure 27.2: Imagerie de la carte de base visuelle de Planet Labs du troisième trimestre 2019 (à gauche) et 4 des 4 000 features MOSAIKS téléchargées depuis l’API (à droite).\n\n\n2. Constituer et organiser un vaste ensemble d’indicateurs présentant une grande diversité de structures spatiales et de catégories\n\n\n\n\n\n\n\n\n\nCatégorie\nNombre d’étiquettes\nExemple d’étiquette\n\n\n\nActifs agricoles\n5\nPropriété foncière agricole\n\n\nAgriculture\n16\nRendement du maïs\n\n\nInfrastructures\n9\nBâtiments\n\n\nDémographie\n5\nÂge médian\n\n\nÉducation\n10\nAnnées de scolarité attendues\n\n\nSanté\n15\nPaludisme chez les enfants\n\n\nBiens ménagers\n21\nTéléphones mobiles\n\n\nRevenu\n9\nIndice de développement humain\n\n\nSystèmes naturels\n8\nCouverture arborée\n\n\nEmploi\n17\nChômage\n\n\n\n\n\nTable 27.1: Les auteurs ont sélectionné 115 variables réparties en 10 catégories et ont entrepris de tester chacune d’elles dans le système MOSAIKS.\n\n\nAvec la prise en main de ces données, ils ont pu formuler quelques questions simples à tester :\n\nQuelles variables peuvent être mesurées efficacement ?\nQuelles sont les applications les plus prometteuses ?\nQuelles sont les défaillances potentielles ?",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html#résultats",
    "href": "fr/part-01-labels/01-labels-100-maps.html#résultats",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "\n27.3 Résultats",
    "text": "27.3 Résultats\n\n27.3.1 Performance globale\nLes résultats de l’expérience des 100 cartes sont présentés dans le nuage de points ci-dessous (Figure 27.3). Chaque point dans chaque sous-graphe de dispersion représente un emplacement dans l’étude pour une étiquette donnée. L’axe des x représente la valeur observée de l’étiquette, et l’axe des y représente la valeur prédite par MOSAIKS. La ligne diagonale à 45° dans chaque sous-graphe représente une prédiction parfaite. Le coefficient de détermination (R²) est utilisé ici comme mesure principale de précision.\nQuelques observations générales ressortent :\n\nVariation substantielle : Même au sein d’une même catégorie, nous observons des degrés de pouvoir prédictif variables. Par exemple, dans la catégorie « Agriculture », certaines étiquettes (comme les moyennes de rendement élevées) sont prédites avec précision, tandis que d’autres (comme certaines cultures spécialisées ou pratiques de gestion) restent plus difficiles à estimer.\nDifférences par catégorie : Certaines catégories ont systématiquement des scores R² plus élevés. Par exemple, les « Systèmes naturels » (ex. : couverture forestière) ont souvent de meilleurs scores car les modèles spatiaux sont directement visibles depuis l’espace – pensez aux vastes zones forestières contrastant avec les champs ouverts ou les centres urbains. En revanche, « Emploi » ou « Démographie » incluent des variables (comme les taux de chômage) qui sont largement socio-économiques, nécessitant des indices plus subtils et indirects.\nCas d’échec : Certains résultats montrent des performances quasi aléatoires, suggérant que les features des images satellites seules sont insuffisantes pour capturer leurs modèles spatiaux ou que les signaux sont noyés dans le bruit (voir Échecs ci-dessous).\n\n\n\n\n\n\nFigure 27.3: Les résultats de l’expérience des 100 cartes avec l’axe des x affichant les valeurs observées et l’axe des y les valeurs prédites. Chaque point représente un emplacement de l’étude. La ligne diagonale (45°) représente une prédiction parfaite. La performance est mesurée avec le coefficient de détermination (R²).\n\n\nDans le diagramme en boîte (Figure 27.4), nous voyons la distribution des valeurs de R² pour chaque catégorie sur les 115 étiquettes. Cela confirme l’importante variation des performances.\n\n\n\n\n\nFigure 27.4: Les résultats de l’expérience des 100 cartes.\n\n\nCes résultats démontrent à la fois la puissance et les limites de MOSAIKS. Bien qu’il excelle à prédire de nombreux résultats importants à l’échelle mondiale, il ne s’agit pas d’une solution universelle. Le succès dépend en grande partie de la relation existante entre l’élément étudié et les features visibles dans l’imagerie satellitaire.\n\n27.3.2 Succès\n\n27.3.2.1 Rendement du maïs\n\n27.3.2.1.1 Données sur le maïs\nLes données de rendement du maïs proviennent de données sur les rendements agricoles collectées au deuxième niveau administratif (par exemple, les comtés aux États-Unis) aux États-Unis, en Chine, au Brésil et dans l’Union européenne. Les rendements sont calculés en divisant la quantité de grain récolté par la superficie plantée, bien que, dans certains cas, la superficie récoltée soit utilisée à la place de la superficie plantée. Les données couvrent la période de 1983 à 2009, la dernière année disponible étant retenue pour chaque localité.\n\n27.3.2.1.2 Résultats du rendement du maïs\nUn exemple remarquable d’une étiquette performante est le rendement du maïs (Figure 27.5). Ce résultat se prête naturellement à la détection par imagerie satellite :\n\n\nSignal visuel direct : Les champs agricoles présentent des features spécifiques, telles que la texture des cultures, la couverture de la canopée et les motifs phénologiques (stades de croissance), qui peuvent tous être capturés dans les signaux spectraux et spatiaux des images satellites.\n\n\n\nContiguïté spatiale : De vastes étendues continues de maïs réduisent le bruit et facilitent l’extraction des features pertinentes.\n\nDans le nuage de points situé à gauche de Figure 27.5, les valeurs de rendement prédites correspondent bien aux valeurs observées, se regroupant souvent le long de la ligne à 45°. À droite, on observe que les motifs visuellement identifiables dans les régions de culture du maïs se reflètent clairement dans les cartes prédites. Cette forte concordance illustre comment MOSAIKS peut rapidement fournir des prédictions robustes pour des résultats qui se manifestent nettement dans l’imagerie satellite.\n\n\n\n\n\nFigure 27.5: Performance de MOSAIKS sur le rendement du maïs (illustrée à gauche), avec les valeurs observées tracées par rapport aux prédictions du modèle. Les données d’étiquetage observées sont affichées en haut à droite, tandis que les prédictions correspondantes apparaissent en bas à droite.\n\n\n\n27.3.2.1.3 Pourquoi cela fonctionne\nLes rendements agricoles constituent un cas d’utilisation classique de la télédétection, car les terres agricoles sont souvent vastes, dispersées géographiquement et sujettes à des changements rapides dus aux conditions météorologiques et aux pratiques de gestion — des conditions que l’imagerie satellite peut surveiller à grande échelle. En mesurant des indices de végétation (par exemple, NDVI, EVI), les chercheurs obtiennent des informations sur la santé des plantes, la densité de la canopée et l’activité photosynthétique, autant d’éléments fortement corrélés à la productivité agricole. Cette approche non invasive, opportune et spatialement exhaustive est inestimable pour la prévision des rendements, la détection de stress et l’orientation de l’allocation des ressources. Par conséquent, la télédétection est devenue une pierre angulaire des méthodes modernes d’estimation des rendements des cultures de base dans le monde entier. MOSAIKS s’inscrit naturellement dans cette tendance, tirant parti des dernières avancées en apprentissage automatique pour extraire des informations exploitables à partir de l’imagerie satellite.\n\n\n\n\n\nFigure 27.6: Champs agricoles dans la région du Midwest des États-Unis. Cet exemple illustre la nette démarcation des parcelles, dont les variations d’intensité de couleur facilitent la détection des caractéristiques sur l’imagerie satellite. Source: NASA\n\n\n\n27.3.2.2 Indice de richesse inclusive (IWI)\n\n27.3.2.2.1 Données de l’IWI\nLes données de l’Indice international de richesse proviennent du programme Demographic and Health Surveys (DHS). L’indice est exprimé par une valeur comprise entre 0 et 100, des valeurs plus élevées indiquant une richesse plus importante. Il est calculé à partir des données ménagères portant sur la possession d’appareils durables, les caractéristiques du logement et l’accès à des services de base comme l’eau et l’électricité. Les données sont traitées et fournies par le Global Data Lab avec l’autorisation du DHS, les valeurs étant moyennées sur l’ensemble des ménages de chaque groupe d’enquête. Ces groupes sont décalés jusqu’à 2 km en zone urbaine et jusqu’à 5 km en zone rurale afin de protéger la vie privée, tout en restant dans les mêmes limites administratives.\n\n27.3.2.2.2 Résultats de l’IWI\nUn autre succès notable est l’Indice international de richesse (IWI; Figure 27.7). Cette mesure composite de la richesse des ménages est dérivée d’une variété d’indicateurs tels que la qualité du logement, l’accès aux services et la possession de biens durables. Bien que la richesse en tant que telle ne soit pas directement visible depuis l’espace, les facteurs qui y contribuent le sont souvent. Par exemple, les zones plus aisées disposent généralement d’infrastructures mieux développées, de maisons plus grandes et d’un plus grand nombre de véhicules — autant d’indices qui laissent des signatures distinctes dans l’imagerie satellite.\n\n\n\n\n\nFigure 27.7: Performance de MOSAIKS sur l’indice de richesse inclusive (en anglais, Inclusive Wealth Index, IWI), illustrée par un graphique comparant les valeurs observées aux prédictions du modèle (à gauche). Les données d’étiquetage observées sont affichées en haut à droite, tandis que les prédictions correspondantes apparaissent en bas à droite.\n\n\n\n27.3.2.2.3 Pourquoi cela fonctionne\nBien qu’il s’agisse d’une mesure composite du statut socioéconomique, les indicateurs sous-jacents de l’IWI — conditions de logement, accès aux services et possession d’actifs — se manifestent souvent dans l’environnement bâti sous forme de caractéristiques que les satellites captent efficacement. Par exemple, les quartiers plus aisés présentent généralement une densité plus élevée de bâtiments substantiels, de routes pavées, d’agencements formels et d’équipements visibles (par exemple, piscines, véhicules stationnés). Ces indices se traduisent par des motifs distinctifs dans les données spectrales et spatiales extraites par les fonctionnalités de MOSAIKS. De plus, le développement des infrastructures et les matériaux de construction (comme les toits en métal par opposition aux toits en chaume) peuvent générer des différences détectables en termes de réflectance, facilitant ainsi la détection des gradients socioéconomiques par l’algorithme.\n\n\n\n\n\n\nCela met en lumière l’un des principaux avantages de MOSAIKS : même lorsque la variable cible n’est pas directement « visible », le système est capable d’en extraire les indicateurs à partir d’indices visuels variés, conduisant ainsi à des prédictions robustes des indices de richesse à travers le monde.\n\n\n\n\n27.3.3 Échecs\n\n27.3.3.1 Infrastructure des pipelines\n\n27.3.3.1.1 Données sur les pipelines\nLes données sur les pipelines proviennent de l’Energy Information Association (EIA) et incluent les lignes principales interétatiques ainsi que certaines lignes intraétatiques, réparties en trois types : pipelines de pétrole brut, pipelines de liquides de gaz d’hydrocarbures (HGL) et pipelines de produits pétroliers. Les données représentent l’infrastructure des pipelines en date de janvier 2020 et couvrent les 48 États contigus des États-Unis. La variable mesure la longueur, en kilomètres, de chaque type de pipeline au sein de chaque cellule de grille.\n\n27.3.3.1.2 Résultats des pipelines\nCertaines étiquettes affichent des valeurs de R² extrêmement faibles, indiquant en effet une absence de capacité prédictive avec cette approche. Un exemple notable est la présence de pipelines souterrains Figure 27.8.\n\n\n\n\n\nFigure 27.8: Les échecs\n\n\n\n27.3.3.1.3 Pourquoi cela échoue\nContrairement aux forêts ou aux champs agricoles, l’infrastructure des pipelines est généralement cachée à l’inspection visuelle directe — souvent située entièrement sous terre ou dissimulée de manière à ne pas fournir d’indicateurs de surface reconnaissables dans l’imagerie (Figure 27.9).\n\nAbsence de features visibles : Il n’existe aucun indice spectral ou structurel (par exemple, coloration, texture, forme) qui indique de manière fiable la présence d’un pipeline.\nLes indices indirects sont peu fiables : On pourrait supposer que les pipelines suivent des routes ou des corridors distincts, mais ces corrélations varient fortement d’une région à l’autre et n’apparaissent pas de manière constante dans l’imagerie.\nRapport signal/bruit : Dans de nombreuses zones, le corridor des pipelines peut apparaître visuellement indiscernable des terres agricoles ou d’autres types de végétation, ne laissant qu’une signature satellite peu ou pas distincte.\n\nEn conséquence, MOSAIKS a peu de chances d’identifier et d’apprendre des features prédictifs pour une telle infrastructure cachée. Cela contraste fortement avec des cibles visuellement plus évidentes, telles que les champs de maïs ou la couverture forestière.\n\n\n\n\n\nFigure 27.9: Why it fails - buried\n\n\n\n27.3.3.2 Diversité des abeilles\n\n27.3.3.2.1 Données sur les abeilles\nLes données sur la diversité des abeilles proviennent du US Geological Survey Eastern Ecological Science Center Native Bee Laboratory, qui fournit des relevés d’occurrence d’espèces pour les abeilles, guêpes et autres insectes, qu’ils soient indigènes ou non, collectés par diverses méthodes de piégeage. Chaque enregistrement inclut une identification taxonomique et des coordonnées géographiques. À partir de données ponctuelles recueillies de 2009 à 2019, la diversité des abeilles est calculée en comptant le nombre d’espèces uniques documentées dans chaque cellule de grille de 0,01° × 0,01° en Amérique du Nord (y compris les territoires américains et les îles mineures éloignées). Pour les cellules comportant plusieurs événements d’échantillonnage, chaque espèce n’est comptée qu’une seule fois. Il est important de noter que la base de données inclut uniquement les enregistrements de présence des espèces — les absences n’étant pas enregistrées — ce qui peut entraîner un biais d’échantillonnage dans les mesures de diversité.\n\n27.3.3.2.2 Résultats sur la diversité des abeilles\nUn autre cas d’échec notable concerne la diversité des abeilles. Bien que les abeilles jouent un rôle crucial dans les écosystèmes et l’agriculture, leur présence et leur diversité ne peuvent être directement observées à partir de l’imagerie satellite. Plusieurs facteurs contribuent à cette limitation :\n\n\nInadéquation d’échelle : Les abeilles évoluent à une échelle spatiale bien plus fine que la résolution de l’imagerie satellite typique.\n\nRelations indirectes : Bien que les abeilles dépendent de la végétation, le lien entre la couverture végétale visible depuis l’espace et les populations d’abeilles est complexe et varie selon le contexte.\n\nDynamiques temporelles : Les populations d’abeilles fluctuent de manière saisonnière et peuvent changer rapidement, tandis que l’imagerie ne capture que des instantanés statiques.\n\nFacteurs cachés : Des éléments essentiels de l’habitat, tels que les sites de nidification, sont souvent dissimulés sous la canopée ou dans de petits espaces invisibles depuis le dessus.\n\nCe cas illustre un principe important : MOSAIKS fonctionne mieux lorsqu’il s’agit de prédire des résultats qui présentent des relations constantes et visibles avec les features de surface capturées par l’imagerie satellite. Lorsque ces relations deviennent trop indirectes ou complexes, les performances en pâtissent généralement.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html#types-de-variables",
    "href": "fr/part-01-labels/01-labels-100-maps.html#types-de-variables",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "\n27.4 Types de variables",
    "text": "27.4 Types de variables\nMOSAIKS peut travailler à la fois avec des variables de résultat continues et catégorielles, bien que l’approche et les métriques d’évaluation diffèrent selon le type.\n\n\n\n\n\n\nCette section offre un aperçu des deux types de variables ainsi que de quelques métriques utilisées pour les évaluer. Ce sujet sera abordé plus en détail dans Chapitre 38.\n\n\n\n\n27.4.1 Variables continues\nLes variables continues prennent des valeurs numériques sur un spectre, telles que :\n\nRendements agricoles (par exemple, tonnes par hectare)\nDensité de population (habitants par kilomètre carré)\nPourcentage de couverture forestière (0-100 %)\nNiveaux de revenus (en dollars)\nHauteur des bâtiments (en mètres)\n\nPour les variables continues, MOSAIKS utilise généralement des approches de régression et évalue la performance à l’aide de métriques telles que le R² (coefficient de détermination) ou la RMSE (erreur quadratique moyenne). Les valeurs de R² rapportées tout au long de ce chapitre indiquent la proportion de variance du résultat expliquée par les prédictions de MOSAIKS.\n\n\n\n\n\nFigure 27.10: Continuous variable example showing the breeding bird species diversity over the continental United States\n\n\n\n27.4.2 Variables catégorielles\nLes variables catégorielles regroupent les observations en classes ou catégories distinctes, telles que :\n\nTypes d’utilisation des sols (urbain/agriculture/forêt)\nTypes de bâtiments (résidentiel/commercial/industriel)\nTypes de cultures (maïs/blé/riz)\nPrésence/absence de features (routes, bâtiments)\nCatégories de développement (faible/moyen/élevé)\n\nPour les variables catégorielles, MOSAIKS peut être utilisé de deux manières :\n\nClassification binaire : Pour les variables comportant deux catégories (par exemple, présence/absence), MOSAIKS peut fournir des prédictions de probabilité comprises entre 0 et 1. La performance est généralement évaluée à l’aide de métriques telles que l’exactitude, la précision, le rappel ou l’aire sous la courbe ROC (AUC-ROC).\n\nClassification multi-classes : Pour les variables comportant plusieurs catégories, MOSAIKS peut soit :\n\nUtiliser une approche one-vs-all, traitant chaque catégorie comme un problème de classification binaire distinct,\nFournir des probabilités pour chaque catégorie possible qui s’additionnent à 1,\nConvertir les catégories en valeurs numériques si elles possèdent un ordre naturel.\n\n\n\n\n\n\n\n\nFigure 27.11: Classifier example showing Ecoregions of the world.\n\n\n\n27.4.3 Choix des métriques appropriées\nLe choix de la métrique d’évaluation doit correspondre au type de variable :\n\n\n\n\n\n\n\nType de variable\nMétriques courantes\nInterprétation\n\n\n\nContinue\nR², RMSE, MAE\nR² varie de 0 à 1, plus la valeur est élevée, mieux c’est\n\n\nBinaire\nAccuracy, AUC-ROC\nVarie de 0 à 1, plus la valeur est élevée, mieux c’est\n\n\nMulti-classes\nAccuracy, F1-score\nVarie de 0 à 1, plus la valeur est élevée, mieux c’est",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/01-labels-100-maps.html#résumé",
    "href": "fr/part-01-labels/01-labels-100-maps.html#résumé",
    "title": "27  Quelles étiquettes fonctionnent ?",
    "section": "\n27.5 Résumé",
    "text": "27.5 Résumé\nCette exploration de plus de 100 résultats différents révèle plusieurs points clés à propos de MOSAIKS :\n\nLa performance varie significativement : La capacité prédictive va d’une très forte (R² &gt; 0.8) à une quasi absence de pouvoir prédictif, en fonction du résultat.\nLa visibilité directe compte : Les résultats directement observables dans l’imagerie (comme la couverture forestière) ou disposant de forts indices visuels (comme les indices de richesse) tendent à être mieux prédits.\nLes tendances par catégorie : Certaines catégories, comme les Systèmes naturels et l’Agriculture, affichent une performance systématiquement plus forte que d’autres, telles que la Santé ou la Démographie.\n\nImplications pratiques : La compréhension de ces tendances aide les utilisateurs à :\n\nFixer des attentes réalistes pour de nouvelles applications,\nIdentifier quels types de résultats sont les plus adaptés,\nReconnaître quand des approches alternatives pourraient être nécessaires.\n\n\n\nCes résultats démontrent à la fois la puissance et les limites de MOSAIKS. Bien qu’il excelle dans la prédiction de nombreux résultats importants à l’échelle mondiale, il ne constitue pas une solution universelle. Le succès dépend en grande partie de la relation significative entre le résultat d’intérêt et les caractéristiques visibles dans l’imagerie satellite.\n\n\n\n\n\n\nPerspectives\n\n\n\nDans le prochain chapitre, nous explorerons plus en détail les données d’étiquetage issues des enquêtes.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Quelles étiquettes fonctionnent ?</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html",
    "href": "fr/part-01-labels/02-labels-survey.html",
    "title": "28  Données d’enquête",
    "section": "",
    "text": "28.1 Pourquoi les données d’enquête nécessitent-elles leur propre chapitre ?\nNotes :\nLes données d’enquête présentent des défis et opportunités uniques lorsqu’on travaille avec MOSAIKS. Contrairement à de nombreuses autres sources de données, souvent collectées de manière systématique via des systèmes automatisés ou des registres administratifs, les données d’enquête :",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html#pourquoi-les-données-denquête-nécessitent-elles-leur-propre-chapitre",
    "href": "fr/part-01-labels/02-labels-survey.html#pourquoi-les-données-denquête-nécessitent-elles-leur-propre-chapitre",
    "title": "28  Données d’enquête",
    "section": "",
    "text": "Capturent des informations détaillées au niveau des ménages et des individus qui seraient autrement inobservables\nSuivent souvent des conceptions d’échantillonnage complexes nécessitant un traitement spécifique\nPeuvent présenter des références géographiques incohérentes entre différentes enquêtes\nNécessitent une attention particulière aux questions de confidentialité et d’éthique\nPeuvent être coûteuses et longues à collecter, rendant la validation des prédictions de MOSAIKS particulièrement précieuse",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html#types-de-données-denquête",
    "href": "fr/part-01-labels/02-labels-survey.html#types-de-données-denquête",
    "title": "28  Données d’enquête",
    "section": "\n28.2 Types de données d’enquête",
    "text": "28.2 Types de données d’enquête\nPlusieurs grandes catégories d’enquêtes sont couramment utilisées avec MOSAIKS :\n\n28.2.1 Enquêtes auprès des ménages\n\nÉtude sur la mesure des niveaux de vie (LSMS)\nEnquêtes démographiques et de santé (DHS)\nEnquêtes en grappes à indicateurs multiples (MICS)\nEnquêtes sur la main-d’œuvre\nDonnées de recensement national\n\n28.2.2 Enquêtes agricoles\n\nRecensements agricoles\nEnquêtes de rendement des cultures\nEnquêtes sur la gestion des exploitations agricoles\nEnquêtes agricoles auprès des ménages\n\n28.2.3 Enquêtes économiques\n\nEnquêtes auprès des entreprises\nEnquêtes sur les prix du marché\nEnquêtes sur les dépenses des consommateurs",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html#accès-aux-données-denquête",
    "href": "fr/part-01-labels/02-labels-survey.html#accès-aux-données-denquête",
    "title": "28  Données d’enquête",
    "section": "\n28.3 Accès aux données d’enquête",
    "text": "28.3 Accès aux données d’enquête\nL’accès aux données d’enquête varie selon la source et le type :\n\n28.3.1 Référentiels publics\n\nBibliothèque de microdonnées de la Banque mondiale\nIPUMS International\nSite web du programme DHS\nBases de données statistiques de la FAO\n\n28.3.2 Offices statistiques nationaux\n\nBureaux de recensement\nMinistères de l’agriculture\nAgences économiques\n\n28.3.3 Institutions de recherche\n\nUniversités\nGroupes de réflexion (think tanks)\nOrganismes de recherche",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html#travailler-avec-les-données-denquête",
    "href": "fr/part-01-labels/02-labels-survey.html#travailler-avec-les-données-denquête",
    "title": "28  Données d’enquête",
    "section": "\n28.4 Travailler avec les données d’enquête",
    "text": "28.4 Travailler avec les données d’enquête\n\n28.4.1 Données LSMS\nL’Étude sur la mesure des niveaux de vie (LSMS) nécessite certaines considérations spécifiques :\n\nEnquêtes multi-thématiques complexes auprès des ménages\nInformations géographiques détaillées\nStructure en panel dans certains pays\nIntégration avec les données agricoles\nMéthodes de référencement spatial variables\n\n28.4.2 Données DHS\nLes Enquêtes démographiques et de santé (DHS) présentent des caractéristiques uniques :\n\nStandardisation entre les pays\nÉchantillonnage en grappes\nCoordonnées GPS déplacées\nIndicateurs riches en santé et démographie\nCycle de mise à jour régulier",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/02-labels-survey.html#conception-denquête-informée-par-la-télédétection",
    "href": "fr/part-01-labels/02-labels-survey.html#conception-denquête-informée-par-la-télédétection",
    "title": "28  Données d’enquête",
    "section": "\n28.5 Conception d’enquête informée par la télédétection",
    "text": "28.5 Conception d’enquête informée par la télédétection\nMOSAIKS peut améliorer la conception des enquêtes de plusieurs façons :\n\n28.5.1 Planification avant enquête\n\nOptimiser la base d’échantillonnage à l’aide d’informations dérivées des satellites\nIdentifier les zones d’intérêt en fonction des caractéristiques physiques\nStratifier l’échantillonnage en fonction des caractéristiques prédites\n\n28.5.2 Pendant la mise en œuvre de l’enquête\n\nValider les informations de localisation\nGuider les équipes de terrain avec des images à jour\nSuivre la progression de l’enquête\n\n28.5.3 Analyse post-enquête\n\nValider les réponses de l’enquête par rapport aux indicateurs satellitaires\nCombler les lacunes de données dans les zones difficiles d’accès\nCréer des prédictions haute résolution à partir des échantillons d’enquête\n\nExemple d’utilisation des caractéristiques MOSAIKS pour la planification des enquêtes :\nCette intégration de MOSAIKS avec les données d’enquête représente une approche puissante à la fois pour améliorer les méthodes d’enquête traditionnelles et pour étendre leur portée grâce à la prédiction basée sur l’imagerie satellitaire.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le prochain chapitre, nous examinerons des conseils pratiques pour préparer les données d’étiquettes à utiliser avec MOSAIKS, y compris le nettoyage des données, l’agrégation et la liaison aux features satellitaires.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Données d'enquête</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html",
    "href": "fr/part-01-labels/03-labels-data-prep.html",
    "title": "29  Préparation des étiquettes",
    "section": "",
    "text": "29.1 Aperçu\nDans ce chapitre, nous abordons le processus de préparation des étiquettes pour leur utilisation avec les caractéristiques MOSAIKS. Les étiquettes sont les valeurs observées que nous cherchons à prédire avec notre modèle—comme les rendements agricoles, le couvert forestier ou toute autre variable d’intérêt. Elles peuvent se présenter sous différents formats spatiaux (ex. : points, polygones ou rasters en grille), mais elles doivent inclure une composante spatiale. Cette information spatiale est utilisée pour associer les étiquettes aux caractéristiques MOSAIKS, qui sont également explicitement spatiales.\nBien que MOSAIKS offre de nombreuses étapes optionnelles, deux éléments sont essentiels :\nLes deux jeux de données doivent être alignés en résolution spatiale et contenir des informations géographiques appropriées pour être fusionnés.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#aperçu",
    "href": "fr/part-01-labels/03-labels-data-prep.html#aperçu",
    "title": "29  Préparation des étiquettes",
    "section": "",
    "text": "Observations terrain (étiquettes)\n\nCaractéristiques satellitaires",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#grille-mosaiks",
    "href": "fr/part-01-labels/03-labels-data-prep.html#grille-mosaiks",
    "title": "29  Préparation des étiquettes",
    "section": "\n29.2 Grille MOSAIKS",
    "text": "29.2 Grille MOSAIKS\nAvant d’aborder les étiquettes, il est essentiel de comprendre la résolution dans laquelle les caractéristiques MOSAIKS sont fournies. La résolution choisie servira de référence pour le résumé de vos étiquettes.\n\n29.2.1 Résolution\nLa résolution standard de MOSAIKS est une grille mondiale à une résolution de 0,01°. Chaque cellule de la grille représente environ 1 km² à l’équateur. La grille est souvent représentée sous forme de points, où chaque point est le centre d’une cellule de grille. Cela signifie que les caractéristiques MOSAIKS standard sont fournies avec des coordonnées de latitude et de longitude correspondant au centre de la cellule de grille.\n\n\n\n\n\n\nLes centroïdes des cellules de la grille MOSAIKS sont arrondis à 0,005 degré et espacés de 0,01 degré (ex. : 10.005, 10.015, 10.025,…).\n\n\n\n\n\n\n\n\nFigure 29.1: Représentation visuelle des grilles standardisées à différentes résolutions (δ), avec la résolution la plus élevée à gauche et les résolutions plus basses vers la droite. Source : Rolf et al. 2021 Figure 3 c.\n\n\n\n29.2.2 Avantages de la grille MOSAIKS\nLa grille MOSAIKS présente plusieurs avantages. Le principal avantage est qu’elle évite le chevauchement des étiquettes. Souvent, les données d’étiquettes sont fournies avec des coordonnées irrégulièrement espacées. En les alignant sur une grille et en les résumant au sein des cellules, on évite le débordement d’une étiquette sur une autre. Cela est particulièrement important lorsque l’on travaille avec des données ayant un fort degré d’autocorrélation spatiale.\n\n\n\n\n\n\nL’API MOSAIKS est conçue pour prédire des résultats à des échelles de 1 km² ou plus. Des solutions personnalisées sont possibles pour des applications à plus haute résolution (voir Chapitre 36).\n\n\n\n\n29.2.3 Inconvénients de la grille MOSAIKS\nLa grille MOSAIKS est définie en degrés, ce qui signifie que la superficie d’une cellule varie en fonction de la latitude. Près de l’équateur, chaque cellule mesure environ 1 km², tandis qu’aux latitudes élevées, la superficie diminue à mesure que la distance entre les méridiens (lignes de longitude) converge.\n\n\n\n\n\nFigure 29.2: Superficie d’une cellule de grille selon la latitude.\n\n\n\n29.2.4 Choisir votre résolution\nNous savons d’après Chapitre 25 que l’API MOSAIKS propose des caractéristiques à des résolutions de 0.01°, 0.1°, 1°, ADM2, ADM1 et ADM0. Dans tous les cas, les caractéristiques sont calculées à 0.01° et ensuite agrégées à la résolution souhaitée. Si vous prévoyez d’utiliser l’API pour télécharger des caractéristiques, vous devez vous assurer que vos étiquettes sont à la même résolution que celles des caractéristiques que vous téléchargez.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#observations-terrain",
    "href": "fr/part-01-labels/03-labels-data-prep.html#observations-terrain",
    "title": "29  Préparation des étiquettes",
    "section": "\n29.3 Observations terrain",
    "text": "29.3 Observations terrain\n\n29.3.1 Résolution\nLa préparation des données d’étiquettes pour MOSAIKS dépend de l’emplacement, de l’étendue, du temps et de la résolution. Lorsque les observations ont une résolution plus fine que 1 km², il faut les sélectionner ou les agréger pour correspondre aux caractéristiques utilisées. MOSAIKS peut incorporer des étiquettes sous forme de données raster, points, polygones ou vecteurs.\n\n\n\n\n\nFigure 29.3: Exemples de formats de données d’étiquettes intégrables au pipeline MOSAIKS.\n\n\n\n29.3.2 Données administratives\nDans certains cas, les étiquettes sont disponibles pour des régions administratives (états, districts, etc.) et ne contiennent que des noms de lieux sans information géographique explicite. Une solution est d’utiliser une base de données de frontières administratives, comme la base Global Administrative Areas (GADM), qui fournit ces limites gratuitement.\n\n\n\n\n\nFigure 29.4: Données de l’indice de développement humain (IDH) au niveau administratif 1 (ADM1).\n\n\n\n29.3.3 Défis liés aux données administratives\nLes données administratives posent deux défis principaux :\n\n\nCorrespondance des noms : Les noms dans votre jeu de données peuvent ne pas correspondre exactement à ceux de la base GADM ou de l’API MOSAIKS. Trouver une correspondance exhaustive peut être complexe.\n\nChangements des limites : Les limites administratives évoluent avec le temps. Il faut s’assurer que les données correspondent aux limites des caractéristiques utilisées.\n\n29.3.4 Taille de l’échantillon\nAugmenter la taille de l’échantillon (N) améliore souvent la performance du modèle. MOSAIKS fonctionne bien sur une large gamme de N, mais un minimum de 300 observations est recommandé.\n\n\n\n\n\nFigure 29.5: Performance du modèle en fonction de N.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#fusion-des-données",
    "href": "fr/part-01-labels/03-labels-data-prep.html#fusion-des-données",
    "title": "29  Préparation des étiquettes",
    "section": "\n29.4 Fusion des données",
    "text": "29.4 Fusion des données\n\n29.4.1 Associer les étiquettes aux caractéristiques MOSAIKS\nPour fusionner les étiquettes avec les caractéristiques MOSAIKS, il faut aligner la localisation géographique des deux jeux de données. Les fichiers de caractéristiques MOSAIKS contiennent des colonnes pour la longitude, la latitude et les caractéristiques. Les étiquettes doivent inclure ces mêmes colonnes.\n\n29.4.2 Exemple de structure de données fusionnées\nUn exemple simple : les étiquettes de rendement des cultures au niveau des districts pourraient ressembler à :\n\n\n\n\nObservation\nDistrict\nAnnée\nRendement des cultures\n\n\n\n1\nChibombo\n2019\n1.520\n\n\n2\nKabwe\n2019\n1.878\n\n\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n2.383\n\n\n\n\n\nTable 29.1: Données fictives sur le rendement des cultures pour les districts de Zambie.\n\n\nLes caractéristiques MOSAIKS à la même résolution pourraient ressembler à :\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nDistrict\nAnnée\nCaractéristique 1\nCaractéristique 2\n…\nCaractéristique K\n\n\n\n\n1\nChibombo\n2019\n4.2\n11.6\n…\n12.7\n\n\n2\nKabwe\n2019\n2.9\n5.3\n…\n11.2\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n10.6\n1.1\n…\n2.2\n\n\n\n\n\nTable 29.2: Données fictives des caractéristiques MOSAIKS pour les mêmes districts.\n\n\nAprès une jointure spatiale, vous obtenez un jeu de données fusionné :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nDistrict\nAnnée\nRendement des cultures\nCaractéristique 1\nCaractéristique 2\n…\nCaractéristique K\n\n\n\n\n1\nChibombo\n2019\n1.520\n4.2\n11.6\n…\n12.7\n\n\n2\nKabwe\n2019\n1.878\n2.9\n5.3\n…\n11.2\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\nN\nKitwe\n2019\n2.383\n10.6\n1.1\n…\n2.2\n\n\n\n\n\nTable 29.3: Exemple de données fusionnées avec étiquettes et features.\n\n\nDans l’exemple ci-dessus, notre localisation géographique est le district et notre étiquette est le rendement des cultures (mt/ha). Nous avons ensuite K colonnes contenant les caractéristiques et N observations.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#considérations-sur-le-nettoyage-des-données",
    "href": "fr/part-01-labels/03-labels-data-prep.html#considérations-sur-le-nettoyage-des-données",
    "title": "29  Préparation des étiquettes",
    "section": "\n29.5 Considérations sur le nettoyage des données",
    "text": "29.5 Considérations sur le nettoyage des données\n\n29.5.1 Systèmes de référence des coordonnées (SRC)\nLe système de référence des coordonnées par défaut utilisé par MOSAIKS est le World Geodetic System 84 (WGS 84). Le code standardisé qui définit le WGS 84 est “EPSG:4326”. EPSG signifie European Petroleum Survey Group, qui maintient une base de données des systèmes de coordonnées et des projections. Le système de coordonnées WGS 84 est le système le plus couramment utilisé pour les données GPS.\n\n\n\n\n\nFigure 29.6: Neuf projections cartographiques à petite échelle.\n\n\nSi vos données ne sont pas en WGS 84, vous devrez les reprojeter dans ce système de référence avant de les joindre aux caractéristiques MOSAIKS.\n\n29.5.2 Qualité des étiquettes\nVérifiez que les valeurs des étiquettes se situent dans les plages attendues, traitez les éventuelles valeurs aberrantes ou les données manquantes, et assurez-vous que les unités sont cohérentes et que les champs numériques sont correctement formatés. Ce livre n’entre pas dans les détails du nettoyage des données désordonnées. Ce sujet est traité de manière exhaustive dans le livre R for Data Science.\n\n29.5.3 Alignement temporel\nSi vous disposez d’étiquettes de séries temporelles, vous devrez calculer des caractéristiques personnalisées pour chaque période. Voir Chapitre 36 pour plus d’informations sur la manière de procéder et ?sec-model-temporal pour des conseils sur la modélisation des données de séries temporelles avec les caractéristiques MOSAIKS.\n\n29.5.4 Formats des données\nMOSAIKS fonctionne avec plusieurs formats spatiaux :\n\n\n\n\nType de données\nFormats courants\nExemple\n\n\n\nPoints\nCSV, GeoJSON\nLieux d’intérêt\n\n\nLignes\nGeoJSON, Shapefile\nRoutes, rivières\n\n\nPolygones\nGeoJSON, Shapefile\nZones géographiques\n\n\nRaster\nGeoTIFF, NetCDF\nForêt, élévation\n\n\nAdministratif\nCSV\nDistricts, états\n\n\n\n\n\nTable 29.4: Formats spatiaux pris en charge par MOSAIKS.\n\n\n\n\n\n\n\n\nL’utilisation de formats optimisés comme Parquet ou Feather peut améliorer la rapidité du traitement.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/03-labels-data-prep.html#résumé",
    "href": "fr/part-01-labels/03-labels-data-prep.html#résumé",
    "title": "29  Préparation des étiquettes",
    "section": "\n29.6 Résumé",
    "text": "29.6 Résumé\nLes points clés pour préparer les étiquettes pour MOSAIKS :\n\nAlignement géographique et temporel\nAgrégation à ≥ 1 km²\nÉchantillon de taille suffisante (N≥300)\nDonnées propres et formatées\n\n\n\n\n\n\n\nÀ venir\n\n\n\nLe prochain chapitre abordera le nettoyage et l’agrégation des étiquettes pour MOSAIKS.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Préparation des étiquettes</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/04-labels-demo.html",
    "href": "fr/part-01-labels/04-labels-demo.html",
    "title": "\n30  Démonstration des données d’étiquetage\n",
    "section": "",
    "text": "30.1 Aperçu\n{#sec-labels-demo}\nCette démonstration vous présentera quelques concepts clés concernant les données d’étiquettes dans MOSAIKS.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Démonstration des données d'étiquetage</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/04-labels-demo.html#code-de-démonstration",
    "href": "fr/part-01-labels/04-labels-demo.html#code-de-démonstration",
    "title": "\n30  Démonstration des données d’étiquetage\n",
    "section": "\n30.2 Code de démonstration",
    "text": "30.2 Code de démonstration\nVous trouverez ci-dessous un lien vers un notebook Jupyter destiné à démontrer la préparation pratique des données d’étiquettes pour une utilisation avec MOSAIKS. Ce notebook vous guidera à travers le processus de préparation d’un jeu de données, notamment :\n\nConstruction et utilisation d’une grille standardisée MOSAIKS\nPréparation des étiquettes géographiques sous forme de points (coordonnées latitude et longitude)\nPréparation des étiquettes géographiques sous forme de lignes (ex. : shapefiles)\nPréparation des étiquettes géographiques sous forme de polygones (ex. : shapefiles)\nPréparation des étiquettes sous forme de rasters (ex. : GeoTIFFs)\n\n\n\n\n\n\n\nCliquez sur l’icône ci-dessous pour exécuter la démonstration !\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ N’oubliez pas de cliquer sur File -&gt; Save a copy in Drive pour enregistrer toute modification que vous apportez.\n\nOu pour voir une version statique du code sur GitHub, cliquez sur l’icône ci-dessous.\n\n\nPour des instructions et des conseils sur l’utilisation de Google Colab, veuillez consulter Chapitre 23.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Démonstration des données d'étiquetage</span>"
    ]
  },
  {
    "objectID": "fr/part-01-labels/04-labels-demo.html#quelle-est-la-prochaine-étape",
    "href": "fr/part-01-labels/04-labels-demo.html#quelle-est-la-prochaine-étape",
    "title": "\n30  Démonstration des données d’étiquetage\n",
    "section": "\n30.3 Quelle est la prochaine étape ?",
    "text": "30.3 Quelle est la prochaine étape ?\nMaintenant que nous avons couvert les bases des données d’étiquettes, nous allons passer à la section suivante, où nous aborderons les considérations liées au choix et au traitement des images satellitaires. Cette section n’est pas nécessaire pour les utilisateurs qui :\na) sont d’accord pour utiliser l’API MOSAIKS pour accéder aux caractéristiques, ou\nb) ont déjà de l’expérience avec le traitement des images satellitaires.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans la prochaine partie, nous examinerons les considérations relatives au choix et au traitement des images satellitaires.",
    "crumbs": [
      "Données étiquetées",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Démonstration des données d'étiquetage</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/00-satellite.html",
    "href": "fr/part-02-satellite/00-satellite.html",
    "title": "Imagerie satellitaire",
    "section": "",
    "text": "Aperçu\nCette section du manuel vise à faciliter la navigation dans l’univers complexe de l’imagerie satellitaire, en mettant l’accent sur son application dans le cadre de MOSAIKS. Bien que les fonctionnalités de l’API MOSAIKS suffisent pour de nombreuses applications, certains cas d’usage nécessitent de travailler directement avec des images satellitaires. Dans ces situations, comprendre comment sélectionner et traiter les images appropriées devient essentiel.",
    "crumbs": [
      "Imagerie satellitaire"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/00-satellite.html#aperçu",
    "href": "fr/part-02-satellite/00-satellite.html#aperçu",
    "title": "Imagerie satellitaire",
    "section": "",
    "text": "Les compétences abordées dans ces chapitres sont principalement pertinentes pour les utilisateurs qui doivent générer des caractéristiques MOSAIKS personnalisées. Si vous prévoyez d’utiliser les fonctionnalités de l’API MOSAIKS, vous pouvez ignorer cette section.",
    "crumbs": [
      "Imagerie satellitaire"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/00-satellite.html#quand-aller-au-delà-de-lapi-mosaiks",
    "href": "fr/part-02-satellite/00-satellite.html#quand-aller-au-delà-de-lapi-mosaiks",
    "title": "Imagerie satellitaire",
    "section": "Quand aller au-delà de l’API MOSAIKS ?",
    "text": "Quand aller au-delà de l’API MOSAIKS ?\nL’API MOSAIKS fournit des caractéristiques pré-calculées à partir d’images satellites Planet Labs de 2019. Bien que ces caractéristiques permettent un large éventail d’applications, vous pourriez avoir besoin de travailler directement avec des images satellites dans les cas suivants :\n\nVotre analyse nécessite des données issues d’une autre période temporelle\n\nVous avez besoin d’une résolution spatiale ou temporelle plus fine\n\nVotre application requiert des bandes spectrales spécifiques\n\nVous souhaitez valider ou comparer les caractéristiques extraites par MOSAIKS\n\nVous développez de nouvelles méthodologies d’analyse",
    "crumbs": [
      "Imagerie satellitaire"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/00-satellite.html#satellites-dobservation-de-la-terre-passé-présent-et-futur",
    "href": "fr/part-02-satellite/00-satellite.html#satellites-dobservation-de-la-terre-passé-présent-et-futur",
    "title": "Imagerie satellitaire",
    "section": "Satellites d’observation de la Terre : passé, présent et futur",
    "text": "Satellites d’observation de la Terre : passé, présent et futur\nL’observation de la Terre par satellite a révolutionné notre compréhension de la planète depuis le lancement du premier satellite Landsat en 1972. Aujourd’hui, des centaines de satellites d’observation terrestre collectent quotidiennement des téraoctets d’images, soutenant des applications allant de la prévision météorologique à l’agriculture de précision.\nLa diversité des données satellitaires disponibles s’est considérablement élargie, avec des options incluant :\n\nSatellites publics gratuits (Landsat, Sentinel)\n\nFournisseurs commerciaux (Planet Labs, Maxar)\n\nCapteurs spécialisés (radar, hyperspectral)\n\nConstellations de satellites offrant une couverture fréquente\n\nImagerie à très haute résolution (&lt;1 m par pixel)\n\nCette abondance d’options crée à la fois des opportunités et des défis lorsqu’il s’agit de sélectionner l’imagerie la plus adaptée à vos besoins spécifiques.",
    "crumbs": [
      "Imagerie satellitaire"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/00-satellite.html#plan-de-la-section",
    "href": "fr/part-02-satellite/00-satellite.html#plan-de-la-section",
    "title": "Imagerie satellitaire",
    "section": "Plan de la section",
    "text": "Plan de la section\nLes chapitres suivants vous guideront à travers les considérations essentielles pour travailler avec l’imagerie satellitaire :\n\n\n\n\n\n\n\n\nChapitre\nSujets clés\n\n\n\n31  Choisir l’imagerie satellitaire\nTypes de résolution, sources de données, critères de sélection\n\n\n32  Traitement de l’imagerie satellitaire\nÉtapes de prétraitement, contrôle qualité, besoins en calcul\n\n\n\n\n\nTable 1: Plan de la section sur l’imagerie satellitaire\n\n\nCes chapitres offrent des conseils pratiques pour intégrer l’imagerie satellitaire dans votre flux de travail MOSAIKS tout en soulignant les considérations techniques et logistiques importantes.\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le prochain chapitre, nous verrons comment choisir l’imagerie satellitaire la plus adaptée à votre application.",
    "crumbs": [
      "Imagerie satellitaire"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html",
    "href": "fr/part-02-satellite/01-satellite-imagery.html",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "",
    "text": "31.1 Contexte\nLe nombre de satellites d’observation de la Terre a connu une croissance exponentielle ces dernières années, portée par les avancées technologiques, la réduction des coûts de lancement et une demande croissante en informations environnementales, économiques et sociétales.\nEn parallèle, la qualité de l’imagerie satellitaire s’est considérablement améliorée, avec des résolutions spatiales, temporelles et spectrales plus fines devenues la norme. Cette prolifération de satellites, associée à des capacités d’imagerie accrues, a généré un volume de données sans précédent. Cette abondance offre aux chercheurs et aux professionnels de nombreuses opportunités, mais pose également des défis en termes de navigation dans la diversité des produits de données et de sélection des plus adaptés aux besoins spécifiques.\nMOSAIKS exploite l’imagerie satellitaire pour générer des données d’entraînement de haute qualité pour les modèles d’apprentissage automatique. Dans ce chapitre, nous explorerons les facteurs clés à prendre en compte lors du choix d’une imagerie satellitaire pour une utilisation avec MOSAIKS, notamment la résolution spatiale et spectrale, la fréquence temporelle, la couverture nuageuse et les niveaux de traitement des images.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#contexte",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#contexte",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "",
    "text": "Figure 31.1: Croissance du nombre de satellites au fil des années. Source : Union of Concerned Scientists\n\n\n\n\n\n\n\n\nFigure 31.2: Évolution de la résolution des images satellites au fil du temps. Source : FlyPix AI\n\n\n\n\n\n\n\n\n\nAccédez à la base de données des satellites de l’UCS pour une liste complète des satellites d’observation de la Terre, comprenant leurs spécifications et détails opérationnels.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#aperçu",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#aperçu",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.2 Aperçu",
    "text": "31.2 Aperçu\nLors de la sélection d’une imagerie satellitaire pour MOSAIKS, plusieurs facteurs clés doivent être pris en compte. Le choix de l’imagerie doit être guidé par vos besoins spécifiques en recherche, les caractéristiques des étiquettes et les contraintes pratiques telles que le coût et les exigences de traitement. Différents cas d’utilisation, comme le suivi de la végétation, la cartographie des zones urbaines ou le suivi des variables climatiques, peuvent nécessiter des capacités d’imagerie spécifiques, ce qui rend essentiel l’alignement des caractéristiques du satellite avec votre application.\nPar exemple, les données haute résolution provenant de satellites commerciaux peuvent offrir des détails précis, mais elles peuvent être trop coûteuses pour des applications à grande échelle. À l’inverse, des ensembles de données accessibles au public, comme Sentinel-2, offrent des options économiques mais avec des résolutions potentiellement plus grossières ou une couverture spectrale limitée. Comprendre ces compromis est essentiel pour une utilisation optimale des ressources.\n\n\n\n\n\n\n\n\nCritère\nDescription\n\n\n\nDisponibilité\nL’accessibilité et le coût des images provenant de sources publiques et privées.\n\n\nPériode temporelle\nLa période durant laquelle les images satellites sont disponibles.\n\n\nRésolution temporelle\nLa fréquence à laquelle les images satellites sont capturées (ex. : quotidienne, hebdomadaire).\n\n\nRésolution spatiale\nLa résolution du capteur satellite (ex. : 10 m, 30 m, 250 m).\n\n\nRésolution spectrale\nLes longueurs d’onde spécifiques captées par le capteur (ex. : RVB, NIR, SWIR).\n\n\nType de capteur\nLe type de capteur utilisé (ex. : optique, radar, thermique).\n\n\nCouverture nuageuse\nLa présence de nuages ou d’autres interférences atmosphériques.\n\n\nNiveau de traitement\nLe prétraitement appliqué (ex. : orthorectification, correction atmosphérique).\n\n\n\n\n\nTable 31.1: Principaux facteurs à considérer lors du choix d’une imagerie satellitaire.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#disponibilité",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#disponibilité",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.3 Disponibilité",
    "text": "31.3 Disponibilité\n\n31.3.1 Satellites publics\nLes programmes satellitaires publics offrent des images gratuites ou peu coûteuses avec une couverture mondiale. Financés par des agences gouvernementales, ces programmes fournissent des données précieuses pour la recherche scientifique et la surveillance environnementale. Ils sont particulièrement utiles pour les études à long terme, grâce à des archives de données remontant sur plusieurs décennies.\n\n\n\n\n\n\n\n\n\n\n\nSatellite\nType de capteur\nRésolution\nTemps de revisite\nCaractéristiques spéciales\n\n\n\nSentinel-2\nOptique\n10-60 m\n5 jours\n13 bandes spectrales\n\n\nLandsat 8/9\nOptique\n15-100 m\n16 jours\n11 bandes spectrales\n\n\nMODIS\nOptique\n250 m-1 km\nQuotidien\n36 bandes spectrales\n\n\nSentinel-1\nRadar (bande C)\n5-40 m\n6-12 jours\nRadar à synthèse d’ouverture (SAR)\n\n\nNISAR\nRadar (bande L & S)\nÀ déterminer\nLancement 2024\nSAR double bande\n\n\nVIIRS\nAutre\n375 m-750 m\nQuotidien\nCouverture globale quotidienne\n\n\nASTER\nAutre\n15-90 m\n16 jours\n14 bandes spectrales\n\n\nNICFI\nOptique\n4.77 m\nComposite mensuel\nSurveillance des forêts tropicales\n\n\n\n\n\nTable 31.2: Exemples de satellites publics et leurs spécifications.\n\n\n\n31.3.2 Satellites privés\nLes programmes satellitaires privés offrent souvent des images de résolution plus élevée, une spécialisation accrue et des revisites plus fréquentes que les programmes publics, mais généralement à un coût plus élevé. Ces satellites sont particulièrement utiles pour des applications nécessitant un niveau de détail précis, telles que la cartographie urbaine, la surveillance des infrastructures ou l’agriculture de précision.\nLes fournisseurs privés proposent souvent des produits de données personnalisés, des délais de livraison adaptés et des analyses avancées, ce qui peut être inestimable pour des projets sensibles au facteur temps ou à vocation commerciale. Cependant, les coûts plus élevés associés aux images privées peuvent limiter leur utilisation pour des études à grande échelle ou à long terme sans un financement significatif.\n\n\n\n\n\n\n\n\n\n\n\nSatellite\nType de capteur\nRésolution\nTemps de revisite\nCaractéristiques spéciales\n\n\n\nMaxar WorldView\nOptique\n31 cm (panchromatique), 1,24 m (multispectral)\nVariable\nTrès haute résolution\n\n\nPlanet SkySat\nOptique\n50 cm (panchromatique), 1 m (multispectral)\nVariable\nSatellites compacts et agiles\n\n\nAirbus Pleiades\nOptique\n50 cm (panchromatique), 2 m (multispectral)\nVariable\nTrès haute résolution\n\n\nPlanet PlanetScope\nOptique\n3-5 m\nQuotidien\nGrande constellation\n\n\nPlanet RapidEye\nOptique\n5 m\n5,5 jours\nConçu pour l’agriculture\n\n\nSPOT\nOptique\n1,5-6 m\n26 jours\nProgramme de longue date\n\n\nICEYE\nRadar (bande X)\n&lt;1 m\nFréquent\nSAR à revisite élevée\n\n\nCapella Space\nRadar (bande X)\n50 cm\nFréquent\nSAR à très haute résolution\n\n\nGHGSat\nSpécialisé\nÀ déterminer\nVariable\nSurveillance des gaz à effet de serre\n\n\n\n\n\nTable 31.3: Exemples de satellites privés et leurs spécifications.\n\n\n\n31.3.3 Considérations sur les coûts\n\n\n\n\n\n\nRappelez-vous que l’imagerie la plus coûteuse ou à la résolution la plus élevée n’est pas toujours le meilleur choix. Équilibrer vos besoins avec des contraintes pratiques — telles que le budget, la capacité de stockage et l’expertise en traitement — peut souvent aboutir à de meilleurs résultats à long terme que de simplement opter pour l’option la plus performante.\n\n\n\nLa sélection d’images satellites implique non seulement le coût direct de l’acquisition des données, mais aussi une série de coûts indirects ou « cachés ». Lorsque vous intégrez ces éléments dans votre budget global, tenez compte de la fréquence à laquelle vous avez besoin de mises à jour, de l’étendue du pré- ou post-traitement requis, ainsi que de la capacité de votre équipe à travailler avec des ensembles de données complexes. Certains satellites et portails de données regroupent également l’analyse et le stockage en cloud dans le cadre de services par abonnement, ce qui peut alléger les exigences en infrastructure moyennant un coût supplémentaire.\nVoici un exemple de répartition des coûts d’imagerie, offrant une référence rapide des gammes de prix typiques et des considérations selon différentes sources de données :\n\n\n\n\n\n\n\n\n\n\nNiveau de coût\nFourchette approximative\nMissions/Programmes exemples\nConsidérations clés\n\n\n\nDonnées publiques gratuites\n$0\nLandsat (30 m), Sentinel (10 m), MODIS (250 m–1 km), VIIRS (375 m–750 m)\nFinancé par le gouvernement ; largement utilisé pour des projets à grande échelle ou sur le long terme ; résolution modérée.\n\n\nRésolution moyenne\n$1–5 par km²\nSPOT (1,5–6 m)\nRelativement abordable pour un niveau de détail modéré ; adapté aux analyses régionales.\n\n\nHaute résolution\n$5–15 par km²\nPlanet (3–5 m), RapidEye (5 m)\nUtile pour des études plus détaillées ; la fréquence des revisites peut augmenter le coût si la couverture est étendue.\n\n\nTrès haute résolution\n$15–25 par km²\nWorldView (sub-mètre), SkySat (0,5–1 m)\nOffre un niveau de détail très fin mais à un prix premium ; le coût peut augmenter rapidement pour de grandes surfaces.\n\n\nServices par abonnement\nVariable\nCertains fournisseurs commerciaux regroupent stockage et analyses\nSouvent une solution « tout-en-un » pratique, mais la tarification peut être imprévisible ou mal adaptée à grande échelle.\n\n\n\n\n\nTable 31.4: Niveaux de coûts pour l’imagerie satellite et considérations clés.\n\n\nEn plus de ces coûts d’acquisition de base, vous devez également prendre en compte :\n\n\nStockage de données et informatique : De grands volumes d’imagerie à haute résolution nécessitent un espace de stockage plus important et une puissance de calcul accrue pour le traitement.\n\nExpertise et formation : L’interprétation d’ensembles de données complexes (comme le radar ou l’hyperspectral) requiert souvent des compétences spécialisées.\n\nLicences logicielles : Les logiciels propriétaires de SIG ou de traitement d’images peuvent s’ajouter à votre budget opérationnel.\n\nInfrastructure cloud : Les solutions cloud commerciales peuvent gérer un traitement à grande échelle, mais peuvent entraîner des frais d’abonnement récurrents.\n\nPeser soigneusement ces dépenses directes et indirectes vous aidera à choisir une imagerie qui optimise à la fois la valeur scientifique et la rentabilité.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#période-temporelle",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#période-temporelle",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.4 Période temporelle",
    "text": "31.4 Période temporelle\nLa durée de vie opérationnelle et l’historique de lancement d’une mission satellite sont des considérations essentielles lors de la sélection d’images pour votre projet. Des programmes plus anciens tels que Landsat offrent des archives de données s’étalant sur plusieurs décennies, ce qui les rend précieux pour la détection de changements à long terme ou pour des analyses historiques. En revanche, des satellites plus récents comme Sentinel, lancé en 2014, fournissent des données avec des technologies de capteurs plus avancées, mais couvrent une fenêtre temporelle plus courte.\nLorsqu’il s’agit de déterminer une plage temporelle, il est important d’évaluer la profondeur historique requise par votre étude, ainsi que la cohérence de la technologie des capteurs au fil du temps. Les projets nécessitant des comparaisons sur plusieurs années bénéficient de missions dotées de procédures d’étalonnage bien documentées et d’une performance stable des capteurs au fil du temps. Vous devrez également prendre en compte si la continuité des données futures est garantie par des lancements prévus ou par des budgets opérationnels prolongés. Par exemple, le programme multigénérationnel de Landsat assure un enregistrement des données relativement cohérent, tandis que des constellations plus récentes peuvent offrir des capacités supérieures, mais faire face à des incertitudes de financement susceptibles d’affecter leur disponibilité à long terme.\n\n\n\n\n\nFigure 31.3: Chronologie du service de la constellation de satellites Landsat. Source : NASA",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#résolution-temporelle",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#résolution-temporelle",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.5 Résolution temporelle",
    "text": "31.5 Résolution temporelle\nLa résolution temporelle, ou fréquence de revisite, détermine la fréquence à laquelle un satellite capture des images du même endroit. Des taux de revisite plus élevés permettent de surveiller des phénomènes en rapide évolution, tels que les cycles de croissance de la végétation ou la dynamique des inondations, et d’intervenir plus rapidement face aux événements changeants. Cependant, les satellites offrant des passages fréquents font souvent des compromis sur la résolution spatiale ou spectrale.\nLors de la sélection de la résolution temporelle, il convient de prendre en compte la vitesse de variation des variables que vous ciblez. La surveillance quotidienne des conditions agricoles nécessite des séries temporelles plus denses qu’une évaluation annuelle de la déforestation. Les conditions nuageuses dans votre zone d’étude peuvent également influer sur le taux de revisite effectif : si les nuages obscurcissent fréquemment la surface terrestre, il peut être nécessaire d’utiliser une constellation de satellites offrant plusieurs opportunités d’imagerie ou un capteur capable de « voir » à travers les nuages, comme le radar (SAR). Votre budget et vos capacités de traitement des données jouent également un rôle dans votre décision, car des acquisitions fréquentes entraînent des besoins accrus en stockage et en calcul.\n\n\n\n\n\nFigure 31.4: Comparaison de la résolution temporelle de différents systèmes satellitaires. Source : Radiant Earth",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#résolution-spatiale",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#résolution-spatiale",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.6 Résolution spatiale",
    "text": "31.6 Résolution spatiale\nLa résolution spatiale du capteur satellite détermine le niveau de détail capturé dans l’imagerie satellite. À des résolutions plus élevées, des éléments tels que des arbres individuels, des véhicules ou de petits bâtiments sont discernables. À des résolutions plus faibles, on obtient une vue d’ensemble plus large des paysages — adaptée aux études à l’échelle régionale comme l’analyse climatique ou la cartographie des couvertures terrestres sur de vastes zones — mais on peut manquer de détecter des changements fins sur de petits éléments.\nBien que l’imagerie à très haute résolution (inférieure à un mètre) puisse fournir des informations riches, elle entraîne souvent des coûts et des exigences de stockage plus élevés. En revanche, les résolutions modérées (10–30 m) offrent un bon compromis entre un niveau de détail significatif, un coût abordable et des volumes de données gérables. Votre choix doit tenir compte de la taille physique des éléments pertinents pour vos étiquettes, de l’échelle de votre zone d’étude et des ressources informatiques dont vous disposez. Dans de nombreux cas, des missions publiques comme Sentinel-2 ou Landsat offrent des résolutions pratiques (10–30 m) suffisantes pour des analyses à grande échelle, sans les coûts élevés associés à l’imagerie commerciale à haute résolution.\n\n\n\n\n\nFigure 31.5: Résolution spatiale de l’imagerie satellite de 3 satellites publics (première rangée) et de 3 satellites commerciaux (deuxième rangée). Source : Radiant Earth",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#résolution-spectrale",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#résolution-spectrale",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.7 Résolution spectrale",
    "text": "31.7 Résolution spectrale\nLa résolution spectrale se réfère à la capacité du capteur à mesurer des longueurs d’onde discrètes à travers le spectre électromagnétique. Différents matériaux — tels que la végétation, l’eau et les infrastructures urbaines — présentent des signatures spectrales distinctes, de sorte que la capture de plusieurs bandes peut améliorer la précision de la classification et la cartographie thématique. Par exemple, les bandes proche infrarouge (NIR) sont extrêmement précieuses pour quantifier la santé de la végétation, tandis que les bandes infrarouges à ondes courtes (SWIR) aident à distinguer les minéraux de la teneur en humidité.\nChoisir une résolution spectrale appropriée implique d’équilibrer le nombre et la largeur des bandes avec l’information thématique spécifique dont vous avez besoin. Les capteurs qui ne capturent que la lumière visible (RGB) peuvent suffire pour une discrimination générale des couvertures terrestres, tandis que des applications comme la surveillance de la santé agricole bénéficient souvent d’une couverture NIR ou SWIR supplémentaire. Les bandes thermiques ou micro-ondes peuvent également être cruciales dans des domaines spécialisés — comme la détection d’anomalies thermiques ou l’estimation de l’humidité du sol — et influencer l’utilité de certaines plateformes satellites pour des objectifs scientifiques ou opérationnels spécifiques.\n\n\nRésolution spectrale et ses applications. Source : Radiant Earth",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#type-de-capteur",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#type-de-capteur",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.8 Type de capteur",
    "text": "31.8 Type de capteur\nLes capteurs satellitaires peuvent généralement être classés en instruments passifs ou actifs. Les deux catégories présentent des avantages et des limites qui influencent leur pertinence pour certaines applications.\nLes capteurs passifs mesurent le rayonnement naturel, généralement la lumière du soleil réfléchie (optique) ou la chaleur émise (thermique). Étant donné qu’ils dépendent de sources d’énergie externes, la collecte des données peut être limitée par la disponibilité de la lumière solaire et les conditions atmosphériques. Cependant, l’imagerie optique issue de capteurs passifs offre souvent des représentations colorées intuitives, ce qui la rend plus facile à interpréter. Les bandes thermiques peuvent révéler des signatures de chaleur utiles dans les études de température de surface.\nLes capteurs actifs émettent leur propre énergie et enregistrent le signal rétrodiffusé. Les systèmes radar (ex. SAR) et les instruments LiDAR appartiennent à cette catégorie. Ils peuvent pénétrer les nuages, fonctionner de nuit et mesurer des caractéristiques de surface telles que la rugosité ou l’élévation. En revanche, les données issues de ces capteurs sont souvent plus complexes à traiter et à interpréter, nécessitant une expertise et des logiciels spécialisés.\n\n\n\n\n\nFigure 31.6: Illustration des différences entre capteurs actifs et passifs. Source : Radiant Earth\n\n\nLe tableau ci-dessous présente une comparaison simple de ces types de capteurs :\n\n\n\n\n\n\n\n\n\n\n\nType de capteur\nExemples\nPrincipe de fonctionnement\nAvantages\nInconvénients\n\n\n\nPassif\nOptique, Thermique\nMesure l’énergie réfléchie naturellement disponible (lumière du soleil ou chaleur émise)\nFacile à interpréter ; souvent intuitif (ex. images RGB)\nSensible à la couverture nuageuse et aux conditions atmosphériques\n\n\nActif\nRadar (SAR), LiDAR\nÉmet de l’énergie et mesure les signaux de retour\nPeut pénétrer les nuages, capturer des données de jour comme de nuit\nDonnées souvent plus complexes à traiter\n\n\n\n\n\nTable 31.5: Types de capteurs et leurs principales caractéristiques.\n\n\nComprendre quel type de capteur correspond le mieux à vos besoins de recherche est crucial. Par exemple, si votre zone d’étude est fréquemment nuageuse, une approche basée sur le radar peut offrir une couverture plus fiable. À l’inverse, les capteurs optiques peuvent suffire pour les régions avec des périodes saisonnières sans nuages ou pour une classification générale de l’occupation du sol lorsque la lumière du soleil est disponible.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#couverture-nuageuse",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#couverture-nuageuse",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.9 Couverture nuageuse",
    "text": "31.9 Couverture nuageuse\nLa couverture nuageuse est l’un des défis les plus persistants dans l’utilisation de l’imagerie satellitaire optique, car les nuages et les ombres peuvent dégrader la qualité des données collectées. Dans les régions où la couverture nuageuse est fréquente, les images peuvent nécessiter un traitement supplémentaire ou une période d’acquisition plus longue pour obtenir une couverture acceptable. Les stratégies pour résoudre ce problème incluent l’application d’algorithmes de masquage des nuages, la fusion de plusieurs images pour créer un composite sans nuages, ou l’utilisation de satellites radar capables de pénétrer les nuages.\nLes capteurs optiques, tels que ceux présents sur Sentinel-2 ou Landsat, incluent souvent des couches de qualité qui signalent les pixels affectés par les nuages. L’exclusion de ces pixels améliore la fiabilité des données, mais réduit également la quantité d’images exploitables, limitant ainsi la couverture temporelle dans les régions nuageuses. En revanche, les missions radar comme Sentinel-1 ou ICEYE sont largement insensibles aux conditions nuageuses, garantissant une couverture cohérente, mais au prix de caractéristiques de données différentes et d’une expertise supplémentaire nécessaire à leur interprétation. Peser ces compromis vous aidera à choisir l’imagerie qui répond le mieux à vos exigences en matière de précision et de contraintes pratiques.\n\n\n\n\n\nFigure 31.7: Couverture nuageuse obscurcissant l’Amérique du Nord. Source : NASA Earth Observatory",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#niveaux-de-traitement",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#niveaux-de-traitement",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.10 Niveaux de traitement",
    "text": "31.10 Niveaux de traitement\nLes données satellitaires sont distribuées à différents niveaux de traitement, allant des mesures brutes de l’instrument aux produits dérivés presque prêts pour l’analyse. Sélectionner un niveau de traitement adapté aux exigences techniques de votre projet peut optimiser les flux de travail et garantir des résultats cohérents.\nLe tableau ci-dessous présente les niveaux de traitement les plus courants :\n\n\n\n\n\n\n\n\n\nNiveau\nDescription\nCas d’utilisation typique\n\n\n\nNiveau 0\nDonnées brutes de l’instrument avec un minimum ou aucun prétraitement. Souvent non orthorectifiées ou non calibrées radiométriquement.\nRarement utilisé pour l’analyse générale en raison de sa complexité.\n\n\nNiveau 1\nCalibrage radiométrique et corrections géométriques de base. Parfois subdivisé (ex. 1A, 1B, 1C).\nAdapté si vous avez besoin de contrôler les corrections atmosphériques finales ou de mettre en place des flux de travail personnalisés.\n\n\nNiveau 2\nProduits de réflectance de surface avec corrections atmosphériques appliquées, incluant souvent des masques de nuages et d’ombres.\nCouramment utilisé pour des analyses nécessitant des valeurs de réflectance précises et des comparaisons multi-temporelles.\n\n\nNiveau 3\nProduits dérivés ou composites (ex. mosaïques, NDVI, données corrigées des lacunes).\nIdéal pour des applications thématiques bénéficiant de données prétraitées et agrégées.\n\n\n\n\n\nTable 31.6: Niveaux de traitement des images satellitaires et leurs cas d’utilisation typiques.\n\n\nD’autres processus sont souvent appliqués à ces niveaux, notamment :\n\n\nOrthorectification : Suppression des distorsions géométriques causées par l’inclinaison du capteur, le relief du terrain et la courbure de la Terre. Assure une représentation spatiale précise pour la cartographie et l’analyse.\n\nCorrection atmosphérique : Ajustement des effets atmosphériques (aérosols, vapeur d’eau) pour normaliser les valeurs de réflectance à travers différentes périodes et capteurs.\n\nCalibrage radiométrique : Conversion des valeurs brutes des capteurs en unités physiques telles que la réflectance ou la température de brillance, garantissant des comparaisons cohérentes entre images provenant de capteurs et de dates d’acquisition différents.\n\n\n\n\n\n\nFigure 31.8: Histogrammes des valeurs brutes de pixels de l’imagerie satellite NICFI pour chaque bande (R, G, B, NIR). Ces données incluent des corrections atmosphériques, des corrections de nuages et des valeurs normalisées des pixels. Après avril 2022, un filtre d’affûtage a également été appliqué aux images.\n\n\nConnaître les étapes de traitement déjà effectuées par votre fournisseur de données vous permet d’éviter un travail redondant et de vous assurer que vous obtenez des données répondant à vos exigences de précision. Par exemple, si vous avez besoin de comparaisons multi-temporelles cohérentes, optez pour un niveau 2 ou supérieur afin de minimiser les variations atmosphériques. En revanche, si vous préférez effectuer vous-même les corrections et les calibrations, le niveau 1 peut offrir une plus grande flexibilité, mais au prix d’une complexité accrue.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#choisir-la-bonne-combinaison",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#choisir-la-bonne-combinaison",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.11 Choisir la bonne combinaison",
    "text": "31.11 Choisir la bonne combinaison\nSélectionner la bonne combinaison de caractéristiques spatiales, spectrales, temporelles et de capteur peut sembler complexe, étant donné le grand nombre de satellites et de produits de données disponibles. Ce choix repose souvent sur les compromis que vous êtes prêt à faire entre coût, résolution, fréquence de revisite, couverture spectrale et disponibilité des données.\n\n\n\n\n\n\n\n\n\n\n\nApplication\nRésolution spatiale\nFréquence temporelle\nBandes clés\nCapteurs recommandés\n\n\n\nAgriculture\n5–30m\nHebdomadaire–mensuelle\nNIR, Rouge, SWIR\nPlanet, Sentinel-2, Landsat 8/9\n\n\nZones urbaines\n0.5–10m\nMensuelle–annuelle\nRGB, NIR\nWorldView, Planet, Sentinel-2\n\n\nSurveillance des forêts\n10–30m\nMensuelle–annuelle\nNIR, SWIR, Rouge\nLandsat, Sentinel-2\n\n\nRessources en eau\n10–30m\nHebdomadaire–mensuelle\nNIR, SWIR, Bleu\nSentinel-2, Landsat 8/9\n\n\n\n\n\nTable 31.7: Exemples de caractéristiques satellitaires pour différentes applications.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/01-satellite-imagery.html#prendre-la-décision-finale",
    "href": "fr/part-02-satellite/01-satellite-imagery.html#prendre-la-décision-finale",
    "title": "31  Choisir l’imagerie satellitaire",
    "section": "\n31.12 Prendre la décision finale",
    "text": "31.12 Prendre la décision finale\nPosez-vous ces questions avant de choisir votre imagerie satellitaire :\n\nQuelle est la résolution spatiale minimale nécessaire ?\nÀ quelle fréquence les observations doivent-elles être effectuées ?\nQuelles bandes spectrales sont requises ?\nQuelle est la période d’intérêt ?\nQuel est votre budget ?\nQuel niveau de traitement est requis ?\nComment allez-vous gérer la couverture nuageuse et les lacunes dans les données ?\nQuelles sont vos ressources en stockage et en calcul ?\n\nLes réponses à ces questions vous orienteront vers la source d’imagerie la plus adaptée à votre application spécifique.\n\n\n\n\n\nFigure 31.9: Image générée par DALL-E illustrant la sélection du satellite parfait.\n\n\n\n\n\n\n\n\n\nÀ suivre\n\n\n\nDans le prochain chapitre, nous explorerons comment accéder aux images satellites et les traiter pour une utilisation avec MOSAIKS.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Choisir l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html",
    "href": "fr/part-02-satellite/02-satellite-processing.html",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "",
    "text": "32.1 Aperçu\nAprès avoir sélectionné une imagerie satellitaire appropriée (Chapitre 31), l’étape suivante consiste à y accéder et à la traiter pour son utilisation avec MOSAIKS. Ce chapitre couvre les considérations clés et les approches pratiques pour travailler avec les données satellitaires.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#aperçu",
    "href": "fr/part-02-satellite/02-satellite-processing.html#aperçu",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "",
    "text": "Source : Microsoft Planetary Computer",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#accès-aux-images-satellites",
    "href": "fr/part-02-satellite/02-satellite-processing.html#accès-aux-images-satellites",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.2 Accès aux images satellites",
    "text": "32.2 Accès aux images satellites\n\n32.2.1 Cloud vs local\nPlusieurs plateformes cloud permettent d’accéder à une large gamme d’imageries satellitaires et de données géospatiales. Ces plateformes offrent des ressources de calcul évolutives, des environnements préconfigurés et intègrent souvent des jeux de données courants.\nLes avantages de ces plateformes incluent :\n\nPas besoin de télécharger les images brutes\n\nAccès à des ressources de calcul évolutives\n\nEnvironnements de traitement préconfigurés\n\nAccès aux bases de données communes\n\nPossibilité de télécharger les données sur un stockage local ou cloud\n\n\n32.2.1.1 Google Earth Engine\nGoogle Earth Engine (GEE) offre un vaste catalogue d’images satellitaires et de données géospatiales accessibles via une API Python. L’API GEE repose sur l’API Earth Engine Python, qui permet d’interagir avec les serveurs Earth Engine et d’exécuter des analyses géospatiales dans le cloud.\n\n32.2.1.2 Microsoft Planetary Computer\nMicrosoft Planetary Computer propose un catalogue multi-pétaoctets de données environnementales mondiales accessibles via des API. L’API MPC est basée sur la spécification STAC (SpatioTemporal Asset Catalog), un standard émergent visant à améliorer l’interopérabilité des données géospatiales, notamment celles issues de l’imagerie satellitaire.\nPour plus d’informations, voir Lecture des données à partir de l’API STAC.\n\n\n\n\n\n\nPour des conseils pratiques sur l’accès aux données via Microsoft Planetary Computer, consultez la section STAC specification du cours MEDS EDS 220.\n\n\n\n\n32.2.2 Planet API\n\n\nNICFI (Norwegian International Climate and Forest Initiative) est gratuit\n\nInscription : NICFI\n\nAccès aux basemaps Visual (RVB) et Analytic (RVB+NIR)\n\n\n\nPlanet est payant\n\nInscription : Planet\n\nAPI permettant d’accéder aux images PlanetScope, RapidEye, SkySat et Dove\nLicences institutionnelles disponibles\n\n\n\n\n32.2.2.1 Sentinel Hub\nSentinel Hub est une plateforme cloud qui fournit un accès aux images satellites Sentinel-1, Sentinel-2 et Landsat. L’API Sentinel Hub permet d’accéder aux images et de les traiter à l’aide d’une interface Python simplifiée.\n\n32.2.3 API Sentinelsat\n\nL’API Python sentinelsat permet de rechercher et de télécharger des images satellites depuis le Copernicus Open Access Hub. Elle offre une interface simple pour l’accès aux données Sentinel-1 et Sentinel-2.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#comprendre-les-données",
    "href": "fr/part-02-satellite/02-satellite-processing.html#comprendre-les-données",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.3 Comprendre les données",
    "text": "32.3 Comprendre les données\nUne fois que vous avez défini votre mode d’acquisition des images satellites, il est crucial de comprendre les données pour garantir un traitement adapté. La meilleure ressource est souvent la documentation du fournisseur de données. En complément, explorer les données visuellement permet d’obtenir une meilleure compréhension.\n\n\n\n\n\n\nPour une approche pratique, passez au chapitre suivant, où vous pourrez accéder à l’imagerie NICFI dans un notebook Google Colab (Chapitre 33).\n\n\n\n\n32.3.1 Formats de stockage\nLes images satellites peuvent être stockées sous plusieurs formats, dont :\n\n\nGeoTIFF\n\n\nNetCDF\n\n\nHDF5\n\nZarr\n\nDes bibliothèques Python comme rasterio, xarray, rioxarray et h5py permettent de lire et d’écrire ces formats.\n\n32.3.2 Métadonnées essentielles\nLes métadonnées associées aux images satellites comprennent plusieurs paramètres importants :\n\n\nType de données (INT8, UINT16, FLOAT32)\n\n\nSystème de coordonnées (CRS)\n\n\nBandes spectrales (Rouge, Vert, Bleu, Proche-infrarouge, etc.)\n\n\nRésolution spatiale (taille de la scène, taille des pixels)\n\n\nDate d’acquisition (image unique ou multi-temporelle)\n\n\nCouverture nuageuse\n\nIndicateurs de qualité des données\n\n32.3.3 Visualisation des images\nPlusieurs méthodes permettent d’améliorer la visualisation des images satellites. Parmi les techniques courantes :\n\n32.3.3.1 Normalisation\n\n32.3.3.2 Couleurs réelles (True Color)\n\n32.3.3.3 Couleurs fausses (False Color)\n\n32.3.3.4 Amélioration et fusion des images (Sharpening)",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#calcul-des-indices",
    "href": "fr/part-02-satellite/02-satellite-processing.html#calcul-des-indices",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.4 Calcul des indices",
    "text": "32.4 Calcul des indices\nSelon l’application, il peut être pertinent de calculer des indices de végétation ou d’autres indicateurs. Dans le domaine agricole, plusieurs indices sont utilisés pour surveiller la santé des cultures, notamment :\n\n\nNDVI (Normalized Difference Vegetation Index)\n\n\nEVI (Enhanced Vegetation Index)\n\nSAVI (Soil Adjusted Vegetation Index)\n\nLe NDVI est un indicateur simple et couramment utilisé, basé sur la différence entre les bandes proche-infrarouge (NIR) et rouge, qui permet de quantifier la santé de la végétation.\n\n\n\n\n\nFigure 32.1: NDVI évoluant sur l’Afrique. Créé avec l’API Google Earth Engine.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#traitement-de-limagerie-satellitaire",
    "href": "fr/part-02-satellite/02-satellite-processing.html#traitement-de-limagerie-satellitaire",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.5 Traitement de l’imagerie satellitaire",
    "text": "32.5 Traitement de l’imagerie satellitaire\nDeux approches principales existent pour accéder et traiter les images satellites :\n\n32.5.1 1. Traitement sur plateforme cloud\nLes plateformes cloud modernes offrent plusieurs avantages :\n\nPas besoin de télécharger les images brutes\n\nRessources de calcul évolutives\n\nEnvironnements préconfigurés\n\nAccès à des jeux de données standards\n\nPaiement uniquement selon l’usage\n\nExemples de plateformes :\n\n\nGoogle Earth Engine\n\n\nMicrosoft Planetary Computer\n\n\nAmazon Web Services\n\n\nPlanet Platform\n\nEuro Data Cube\n\n32.5.2 2. Traitement local\nUn traitement local peut être préférable lorsque :\n\nLa connexion Internet est limitée\n\nLa confidentialité des données est critique\n\nDes algorithmes propriétaires sont utilisés\n\nLes besoins en calcul sont modérés\n\nLes mêmes images doivent être réutilisées fréquemment\n\nCritères de choix :\n\nVolume de données\n\nComplexité du traitement\n\nContraintes budgétaires\n\nDélais d’exécution\n\nExigences de sécurité",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#étapes-du-traitement",
    "href": "fr/part-02-satellite/02-satellite-processing.html#étapes-du-traitement",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.6 Étapes du traitement",
    "text": "32.6 Étapes du traitement\n\n32.6.1 Évaluation de la qualité\n\nDétection des nuages\n\nMasquage des ombres\n\nIdentification des pixels défectueux\n\nCorrection des artefacts du capteur\n\n32.6.2 Correction atmosphérique\n\nConversion en réflectance de surface\n\nCorrection des effets atmosphériques\n\nStandardisation des valeurs\n\n32.6.3 Correction géométrique\n\nOrthorectification\n\nCo-enregistrement\n\nAlignement des projections\n\n32.6.4 Mosaïquage\n\nAssemblage d’images\n\nFusion et équilibrage des couleurs\n\nRemplissage des lacunes\n\n32.6.5 Composition temporelle\n\nSélection des meilleurs pixels\n\nMoyenne pondérée\n\nLissage des séries temporelles",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#bonnes-pratiques",
    "href": "fr/part-02-satellite/02-satellite-processing.html#bonnes-pratiques",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.7 Bonnes pratiques",
    "text": "32.7 Bonnes pratiques\n\n\nDocumenter toutes les étapes\n\nParamètres utilisés\n\nDécisions de contrôle qualité\n\nVersions des logiciels\n\n\n\nValider les résultats\n\nInspection visuelle\n\nVérifications statistiques\n\nComparaison avec des données de terrain\n\n\n\nOptimiser les ressources\n\nTraitement par lots\n\nCalcul parallèle\n\nGestion efficace de la mémoire\n\n\n\nAssurer la reproductibilité\n\nSuivi des modifications de code\n\nArchivage des jeux de données clés\n\nDocumentation des dépendances",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/02-satellite-processing.html#défis-courants",
    "href": "fr/part-02-satellite/02-satellite-processing.html#défis-courants",
    "title": "32  Traitement de l’imagerie satellitaire",
    "section": "\n32.8 Défis courants",
    "text": "32.8 Défis courants\n\n\nStockage : gestion des volumes massifs de données\n\n\nRessources de calcul : limites CPU/GPU, bande passante\n\n\nQualité des données : effets atmosphériques, artefacts du capteur\n\n\nDélais de traitement : temps de téléchargement et vérification\n\n\n\n\n\n\n\n\nÀ venir\n\n\n\nDans la prochaine section, nous allons charger, visualiser et explorer les images satellites NICFI dans un notebook Google Colab.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Traitement de l’imagerie satellitaire</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/03-satellite-demo.html",
    "href": "fr/part-02-satellite/03-satellite-demo.html",
    "title": "33  Démonstration d’imagerie",
    "section": "",
    "text": "33.1 Aperçu\nCette démonstration vous présentera quelques concepts clés sur les données satellitaires et la façon dont elles peuvent être préparées pour la création de feature (la création de feature est abordée au Chapitre 36) ## Données de démonstration\nPour cette démonstration, nous utiliserons des images satellitaires provenant des NICFI Basemaps. Les NICFI Basemaps sont une collection d’images satellites haute résolution, disponibles gratuitement à des fins de recherche. Ces données sont fournies avec une correction atmosphérique, une correction des nuages et des valeurs de pixels normalisées. De plus, les produits créés après avril 2022 appliquent également un filtre d’amélioration des images.\nPlus de détails sur le traitement des NICFI Basemaps sont disponibles ici.\nPour apprendre à accéder aux NICFI Basemaps, suivez les instructions d’inscription ici.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Démonstration d'imagerie</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/03-satellite-demo.html#code-de-démonstration",
    "href": "fr/part-02-satellite/03-satellite-demo.html#code-de-démonstration",
    "title": "33  Démonstration d’imagerie",
    "section": "\n33.2 Code de démonstration",
    "text": "33.2 Code de démonstration\nCi-dessous se trouve un lien vers un notebook Jupyter destiné à démontrer la préparation pratique des données satellitaires pour une utilisation dans MOSAIKS. Ce notebook vous guidera à travers le processus de préparation des images, y compris :\n\nChargement des images satellites\nInspection des propriétés des images\nNormalisation des images\nVisualisation des images\n\n\n\n\n\n\n\nCliquez sur l’icône pour exécuter la démonstration !\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ N’oubliez pas de cliquer sur Fichier -&gt; Enregistrer une copie dans Drive pour sauvegarder vos modifications.\n\nOu pour voir une version statique du code sur GitHub, cliquez sur l’icône ci-dessous.\n\n\nPour les instructions et conseils sur l’utilisation de Google Colab, veuillez vous référer à Chapitre 23.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Démonstration d'imagerie</span>"
    ]
  },
  {
    "objectID": "fr/part-02-satellite/03-satellite-demo.html#et-ensuite",
    "href": "fr/part-02-satellite/03-satellite-demo.html#et-ensuite",
    "title": "33  Démonstration d’imagerie",
    "section": "\n33.3 Et ensuite ?",
    "text": "33.3 Et ensuite ?\nMaintenant que nous avons couvert les bases du travail avec les données satellitaires, nous allons passer à la section suivante, où nous discuterons de la vectorisation des images.\n\n\n\n\n\n\nÀ suivre\n\n\n\nC’est la fin de la section sur les données satellitaires. Ensuite, nous passerons à la vectorisation des données satellitaires.",
    "crumbs": [
      "Imagerie satellitaire",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Démonstration d'imagerie</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/00-features.html",
    "href": "fr/part-03-features/00-features.html",
    "title": "Features provenant des satellites",
    "section": "",
    "text": "Aperçu\nCette section explore les features MOSAIKS – des représentations compressées de l’imagerie satellitaire qui permettent des prédictions efficaces sur diverses tâches. Bien que de nombreux utilisateurs puissent s’appuyer sur les features pré-calculées via l’API MOSAIKS, comprendre leur fonctionnement et savoir comment les générer offre un contexte précieux et permet une personnalisation si nécessaire.",
    "crumbs": [
      "Features provenant des satellites"
    ]
  },
  {
    "objectID": "fr/part-03-features/00-features.html#aperçu",
    "href": "fr/part-03-features/00-features.html#aperçu",
    "title": "Features provenant des satellites",
    "section": "",
    "text": "Les détails techniques abordés dans ces chapitres sont principalement destinés aux utilisateurs souhaitant comprendre ou générer leurs propres features MOSAIKS. Si vous utilisez les features pré-calculées de l’API MOSAIKS, vous pouvez vous concentrer sur 35  features API.",
    "crumbs": [
      "Features provenant des satellites"
    ]
  },
  {
    "objectID": "fr/part-03-features/00-features.html#pourquoi-aller-au-delà-des-features-de-lapi",
    "href": "fr/part-03-features/00-features.html#pourquoi-aller-au-delà-des-features-de-lapi",
    "title": "Features provenant des satellites",
    "section": "Pourquoi aller au-delà des features de l’API ?",
    "text": "Pourquoi aller au-delà des features de l’API ?\nL’API MOSAIKS fournit des features pré-calculées à partir des images satellites Planet Labs de 2019. Bien que ces features suffisent pour de nombreuses applications, vous pourriez avoir besoin de générer vos propres features si :\n\nVotre analyse nécessite des données d’une autre période temporelle\n\nVous avez besoin de features à une résolution spatiale différente\n\nVous souhaitez expérimenter avec différents paramètres de caractérisation\n\nVous développez de nouvelles méthodologies d’extraction\n\nVous devez valider ou comparer différents types de features",
    "crumbs": [
      "Features provenant des satellites"
    ]
  },
  {
    "objectID": "fr/part-03-features/00-features.html#types-de-features-et-calcul",
    "href": "fr/part-03-features/00-features.html#types-de-features-et-calcul",
    "title": "Features provenant des satellites",
    "section": "Types de features et calcul",
    "text": "Types de features et calcul\nLes features MOSAIKS transforment l’imagerie satellite brute en un format tabulaire compact, capturant les motifs essentiels tout en réduisant considérablement le volume de données. Le système prend actuellement en charge :\n\n\nfeatures convolutionnelles aléatoires (RCFs)\n\n\nfeatures gaussiennes aléatoires\n\n\nfeatures empiriques basées sur des patchs\n\nApproches hybrides\n\nCes différentes méthodes présentent des compromis en termes de temps de calcul, exigences de stockage et performance prédictive selon les tâches.",
    "crumbs": [
      "Features provenant des satellites"
    ]
  },
  {
    "objectID": "fr/part-03-features/00-features.html#plan-de-la-section",
    "href": "fr/part-03-features/00-features.html#plan-de-la-section",
    "title": "Features provenant des satellites",
    "section": "Plan de la section",
    "text": "Plan de la section\nLes chapitres suivants vous guideront à travers les concepts clés des features MOSAIKS :\n\n\n\n\n\n\n\n\nChapitre\nSujets clés\n\n\n\n34  Comprendre les features\nfeatures convolutionnelles aléatoires (RCFs), détails d’implémentation\n\n\n35  features API\nfeatures pré-calculées, spécifications, utilisation\n\n\n36  Calcul des features\nExigences de calcul, flux de travail, stockage\n\n\n\n\n\nTable 1: Plan de la section sur les features\n\n\nCes chapitres fournissent à la fois des conseils pratiques pour travailler avec les features MOSAIKS et une compréhension technique plus approfondie du processus d’extraction des features.\n\n\n\n\n\n\n\nÀ venir\n\n\n\nLe prochain chapitre introduira les features convolutionnelles aléatoires (RCFs), un élément central du système MOSAIKS, en apportant un contexte et une intuition sur leur fonctionnement.",
    "crumbs": [
      "Features provenant des satellites"
    ]
  },
  {
    "objectID": "fr/part-03-features/01-features-rcf.html",
    "href": "fr/part-03-features/01-features-rcf.html",
    "title": "34  Comprendre les features",
    "section": "",
    "text": "34.1 MOSAIKS et “kitchen sinks” ?\nMOSAIKS signifie Multi-task Observation using SAtellite Imagery & Kitchen Sinks. On nous demande souvent d’où vient l’expression kitchen sinks (évier de cuisine). Elle provient de l’expression anglaise everything but the kitchen sink, qui signifie “presque tout ce que l’on peut imaginer”.\nDans le contexte de MOSAIKS, cette métaphore illustre notre approche : nous extrayons une quantité massive d’informations à partir des images satellites, sans pour autant capturer chaque pixel ou chaque relation possible. Nous sélectionnons les ingrédients les plus utiles (les features) et laissons le reste de côté.\nL’idée d’abandonner les images brutes est essentielle à la puissance de MOSAIKS. Cela signifie que la plupart des utilisateurs n’ont jamais à manipuler directement ces volumes massifs d’imagerie satellitaire. L’équipe MOSAIKS prend en charge ce traitement et extrait un grand ensemble de features convolutionnelles aléatoires (RCFs), puis élimine les images sources.\nL’utilisateur final n’a pas besoin de voir les images brutes ni d’interpréter chaque caractéristique individuellement. Il peut directement exploiter ces représentations numériques compactes pour ses propres modèles prédictifs.\nDans cette section, nous allons lever le capot et voir comment ces features sont extraites à partir des images satellites.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Comprendre les features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/01-features-rcf.html#mosaiks-et-kitchen-sinks",
    "href": "fr/part-03-features/01-features-rcf.html#mosaiks-et-kitchen-sinks",
    "title": "34  Comprendre les features",
    "section": "",
    "text": "Figure 34.1: Maddy (Madagascar, au centre) prend des images satellites brutes (à gauche) et utilise la méthode du kitchen sink pour produire des features de convolution aléatoires (à droite). Art par Grace Lewin.\n\n\n\n\n\n\n\n\n\n\n\nDans ce manuel, les termes random convolutional features, RCFs, features, satellite features, et MOSAIKS features sont utilisés de manière interchangeable.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Comprendre les features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/01-features-rcf.html#transformer-des-images-en-features",
    "href": "fr/part-03-features/01-features-rcf.html#transformer-des-images-en-features",
    "title": "34  Comprendre les features",
    "section": "\n34.2 Transformer des images en features",
    "text": "34.2 Transformer des images en features\n\n\n\n\n\nFigure 34.2: Une collection d’images satellites. Source : Microsoft Planetary Computer\n\n\n\n\n34.2.1 Vue d’ensemble\nLe processus de featurization de MOSAIKS produit une représentation de longueur fixe pour chaque patch d’image satellite. Concrètement, cela signifie que nous obtenons un vecteur numérique pour chaque image. Comme MOSAIKS utilise des images satellites, chaque image représente une localisation spécifique, et donc chaque localisation est associée à un vecteur de features.\n\n\n\n\n\nFigure 34.3: Illustration du processus de génération des RCFs. Source : Rolf et al. 2021 Figure 1 C\n\n\nLe processus de featurization comporte trois étapes principales :\n\n\nConvolution\n\n\nActivation\n\nPooling (moyennage spatial)\n\nNous allons illustrer ces étapes en prenant l’exemple d’une image d’entrée de dimensions \\(3 \\times 256 \\times 256\\) (trois canaux couleur : rouge, vert et bleu, avec une taille de 256x256 pixels).\n\n34.2.2 Comprendre les convolutions\nEn termes simples, une convolution permet de détecter certains motifs dans une image : contours, textures ou couleurs. Un filtre de convolution “glisse” sur l’image et applique des opérations mathématiques sur de petites zones.\n\n\n\n\n\nFigure 34.4: Illustration d’une convolution sans padding ni strides. Source : A guide to convolution arithmetic for deep learning.\n\n\nContrairement aux réseaux de neurones profonds (CNNs) qui empilent plusieurs couches convolutives, MOSAIKS utilise une seule couche de convolution. Ces poids convolutifs sont initialisés de manière aléatoire et restent fixes, ce qui signifie que les features extraites ne sont pas ajustées pour une tâche spécifique.\n\n34.2.3 Activation\nAprès la convolution, on applique une fonction d’activation non linéaire, ReLU (Rectified Linear Unit). Cette fonction définit toute valeur négative à zéro :\n\\[\n\\text{ReLU}(x) = \\max(0, x)\n\\]\nCela permet de capturer les non-linéarités présentes dans l’image.\nUn avantage clé :\nMOSAIKS génère deux features par filtre :\n\n\nUne caractéristique avec la sortie ReLU\n\n\nUne caractéristique avec la sortie ReLU inversée (multipliée par -1)\n\nCette approche optimise l’efficacité du modèle et double la richesse de l’information extraite.\n\n34.2.4 Pooling : Réduction de la dimension spatiale\nLa dernière étape consiste à appliquer une couche de pooling adaptatif pour réduire la carte d’activation à une seule valeur par filtre.\nConcrètement, cela moyenne les activations sur toute l’image, produisant un résumé compact de l’information capturée.\n\n34.2.5 Synthèse du processus\nNous répétons ces trois étapes pour tous les filtres définis dans le modèle. Ainsi, si nous avons K filtres, nous obtenons un vecteur de features de dimension K.\n\n\n\n\n\nFigure 34.5: Image source, échantillons de patchs, cartes convolutées et activations.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Comprendre les features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/01-features-rcf.html#pourquoi-utiliser-les-rcfs",
    "href": "fr/part-03-features/01-features-rcf.html#pourquoi-utiliser-les-rcfs",
    "title": "34  Comprendre les features",
    "section": "\n34.3 Pourquoi utiliser les RCFs ?",
    "text": "34.3 Pourquoi utiliser les RCFs ?\nL’approche de MOSAIKS remplace l’apprentissage par minimisation par une approche basée sur la randomisation.\nContrairement aux CNNs traditionnels qui optimisent leurs filtres par rétropropagation (backpropagation), MOSAIKS applique une convolution aléatoire et ne met jamais à jour ses filtres. Cela semble contre-intuitif, mais cette approche présente plusieurs avantages clés :\n\n\nLégèreté et généralisation\n\nPas besoin d’adapter les features à une tâche spécifique\n\nRéutilisation des mêmes features pour une multitude d’applications\n\n\n\nScalabilité et rapidité\n\nPas d’apprentissage à grande échelle\n\nGénération rapide des features pour toute la planète\n\n\n\nRichesse des motifs capturés\n\nÉchantillonne une grande variété de textures, couleurs et structures spatiales\n\n\n\nDistribution simplifiée\n\nContrairement aux images brutes, les vecteurs de features sont faciles à stocker, télécharger et manipuler",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Comprendre les features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/01-features-rcf.html#résumé",
    "href": "fr/part-03-features/01-features-rcf.html#résumé",
    "title": "34  Comprendre les features",
    "section": "\n34.4 Résumé",
    "text": "34.4 Résumé\nLes features convolutionnelles aléatoires (RCFs) constituent l’épine dorsale de MOSAIKS :\n\n\nElles remplacent les CNNs complexes par une approche randomisée et sans entraînement\n\n\nElles sont généralisables et peuvent être appliquées à n’importe quelle tâche prédictive\n\n\nElles permettent un traitement à grande échelle, sans nécessiter d’accéder aux images brutes\n\nEn convertissant les images en vecteurs numériques compacts, les RCFs offrent un pont puissant entre l’imagerie satellitaire et l’apprentissage automatique.\n\n\n\n\n\n\n\nÀ venir\n\n\n\nDans la prochaine section, nous verrons comment accéder aux features pré-calculées disponibles via l’API MOSAIKS, sans avoir à effectuer la featurization vous-même.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Comprendre les features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html",
    "href": "fr/part-03-features/02-features-api.html",
    "title": "35  features API",
    "section": "",
    "text": "35.1 Vue d’ensemble\nDans ce chapitre, nous nous concentrons sur les features MOSAIKS disponibles via l’API (MOSAIKS API). Ces features permettent d’intégrer rapidement et facilement des prédicteurs basés sur l’imagerie satellite dans vos analyses sans avoir à traiter manuellement les images satellites.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#vue-densemble",
    "href": "fr/part-03-features/02-features-api.html#vue-densemble",
    "title": "35  features API",
    "section": "",
    "text": "L’accès aux features via l’API est expliqué en détail dans Chapitre 25. Ce chapitre fournit des informations complémentaires sur la génération des features et leurs spécifications. Si vous souhaitez générer vos propres features, consultez Chapitre 36.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#imagerie-source",
    "href": "fr/part-03-features/02-features-api.html#imagerie-source",
    "title": "35  features API",
    "section": "\n35.2 Imagerie source",
    "text": "35.2 Imagerie source\n\n\nSourcePlanet Labs Visual Basemap (Global Quarterly 2019, Q3).\n\nPériode temporelle\nPrincipalement entre juillet et septembre 2019 (Q3), bien que certaines régions puissent présenter des variations.\n\nCouverture spatiale\nToutes les zones terrestres du globe, à l’exclusion de la plupart des grandes étendues d’eau.\n\nArtefacts possibles\nCertaines régions peuvent être affectées par des nuages, de la brume ou des ombres, surtout dans les zones à forte couverture nuageuse pendant cette période.\n\n\n\n\n\n\nFigure 35.1: Exemple d’imagerie du basemap Planet Labs.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#détails-sur-la-génération-des-features-api",
    "href": "fr/part-03-features/02-features-api.html#détails-sur-la-génération-des-features-api",
    "title": "35  features API",
    "section": "\n35.3 Détails sur la génération des features API",
    "text": "35.3 Détails sur la génération des features API\nL’équipe MOSAIKS a effectué une unique passe de featurization sur l’imagerie Planet Labs 2019 Q3. Ce processus repose sur la méthode des features de Convolution Aléatoires (RCFs) décrite en Chapitre 34, avec les paramètres spécifiques suivants :\n\n\nÉchantillonnage de patches\n\nSélection aléatoire de patches (filtres) directement dans l’imagerie Planet Labs 2019 Q3.\n\n\nBlanchiment (whitening) des patches : centrage et déco-corrélation des valeurs de pixels pour mettre en évidence des motifs distincts.\n\n\n\nTailles de filtres (kernels)\n\n\n2 000 features dérivées de filtres 4×4.\n\n\n2 000 features dérivées de filtres 6×6.\n\nTous les filtres conservent 3 canaux couleur (Rouge, Vert, Bleu).\n\n\n\nBiais et activation\n\nAjout d’un biais de -1 avant activation, permettant d’affiner les seuils d’activation.\n\nApplication de la fonction ReLU (max(0, x)) pour garantir la non-linéarité.\n\n\n\nPooling et agrégation spatiale\n\nAprès convolution et activation, la réponse est moyennée sur chaque cellule 0.01° (~1 km²).\n\nChaque filtre produit une seule valeur numérique moyenne par cellule.\n\n\n\nVecteur final de features\n\nAprès application de tous les filtres, chaque cellule 0.01° reçoit un vecteur de 4 000 dimensions.\n\nCe processus a été exécuté une seule fois, générant une couche de features globale fixe.\n\n\n\n\n\n\n\n\nFigure 35.2: Trois cartes d’activation de features aléatoires extraites de l’imagerie Planet Labs.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#agrégations-dérivées",
    "href": "fr/part-03-features/02-features-api.html#agrégations-dérivées",
    "title": "35  features API",
    "section": "\n35.4 Agrégations dérivées",
    "text": "35.4 Agrégations dérivées\nBien que les features soient initialement calculées à 0.01° de résolution (~1 km²), l’API propose également des versions agrégées :\n\n\n\n\nRésolution\nDescription\nPondération\nAccès\n\n\n\n0.01°\nRésolution native (~1 km²)\nNon pondéré\nAPI Portal\n\n\n0.1°\nGrille agrégée (~10 km²)\nSurface ou population\nGrilles Globales\n\n\n1°\nGrille agrégée (~100 km²)\nSurface ou population\nGrilles Globales\n\n\nADM2\nNiveau départemental/district\nSurface ou population\nFichiers Pré-calculés\n\n\nADM1\nNiveau régional/provincial\nSurface ou population\nFichiers Pré-calculés\n\n\nADM0\nNiveau national\nSurface ou population\nFichiers Pré-calculés\n\n\n\n\n\nTable 35.1: Options de téléchargement des features via l’API MOSAIKS.\n\n\nIllustration des agrégations :\n\n\n\n\n\nFigure 35.3: Exemple de features convolutionnelles aléatoires téléchargées à différentes échelles : (A) grille 0.1°, (B) départements, (C) régions.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#pondération-par-surface-vs-population",
    "href": "fr/part-03-features/02-features-api.html#pondération-par-surface-vs-population",
    "title": "35  features API",
    "section": "\n35.5 Pondération par surface vs population",
    "text": "35.5 Pondération par surface vs population\nChaque agrégation offre deux options de pondération :\n\n\nPondération par surface : Les cellules ou régions avec plus de superficie terrestre ont plus de poids.\n\n\nPondération par population : Utilise la densité de population du GPWv4 pour pondérer davantage les zones plus peuplées.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#quand-utiliser-ces-features",
    "href": "fr/part-03-features/02-features-api.html#quand-utiliser-ces-features",
    "title": "35  features API",
    "section": "\n35.6 Quand utiliser ces features ?",
    "text": "35.6 Quand utiliser ces features ?\n\n\nDisponibilité immédiate :\n\nSi vos labels datent de ~2019 (ou d’une période proche sans changements majeurs), ces features sont la solution la plus rapide et facile.\n\n\n\nDonnées agrégées :\n\nSi vos données sont agrégées (ex. niveau pays), téléchargez directement les features agrégées.\n\n\n\nContraintes de ressources :\n\nSi vous avez des contraintes de stockage ou de calcul, utilisez les fichiers pré-agrégés.\n\n\n\nDonnées à haute résolution :\n\nPour des analyses fines (ex. enquêtes ménages), utilisez la résolution 0.01° ou agrégée selon vos besoins.\n\n\n\n\n\n\n\n\nFigure 35.4: Exemple de données d’Indice de Développement Humain (HDI) au niveau régional (ADM1). Source : Smits & Permanyer 2019.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#points-clés",
    "href": "fr/part-03-features/02-features-api.html#points-clés",
    "title": "35  features API",
    "section": "\n35.7 Points clés",
    "text": "35.7 Points clés\n\n\nImagerie source unique\n\n\nBasemap Planet Labs (2019 Q3)\n\nCouverture terrestre globale (~1 km de résolution)\n\n3 bandes spectrales (RVB)\n\n\n\nProcessus de featurization unique\n\n\nfeatures générées une seule fois (pas d’actualisation périodique)\n\nL’agrégation (0.1°, 1°, ADM) repose sur les mêmes features 0.01°\n\n\n\n\nfeatures RCF (Random Convolutional Features)\n\n\n4 000 dimensions\n\n\nFiltres de 4×4 et 6×6\n\n\nBlanchiment empirique des patches (décorrélation)\n\n\nBiais : -1, Activation ReLU\n\n3 canaux couleur (RVB)\n\n\n\nRésolutions flexibles\n\n\nHaute résolution (0.01°) : requêtes par fichier ou carte\n\n\nAgrégations : 0.1°, 1°, ADM0/ADM1/ADM2 disponibles en téléchargement\n\n\n\nCas d’usage\n\nIdéal pour les labels des années 2019-2020\n\nFacile à intégrer dans les modèles de Machine Learning\n\nCompatible avec analyses globales ou locales",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/02-features-api.html#prochaines-étapes",
    "href": "fr/part-03-features/02-features-api.html#prochaines-étapes",
    "title": "35  features API",
    "section": "\n35.8 Prochaines étapes",
    "text": "35.8 Prochaines étapes\n\n\n\n\n\n\nÀ venir\n\n\n\nDans la prochaine section, nous explorerons les techniques avancées pour calculer et personnaliser vos propres features MOSAIKS.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>features API</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html",
    "href": "fr/part-03-features/03-features-computing.html",
    "title": "36  Calcul des features",
    "section": "",
    "text": "36.1 Vue d’ensemble\nBien que l’API MOSAIKS fournisse des features pré-calculées pour de nombreuses applications, certains cas d’usage nécessitent le calcul de features personnalisées. Ce chapitre couvre les aspects techniques de la génération de features MOSAIKS à partir d’images satellites.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#prérequis",
    "href": "fr/part-03-features/03-features-computing.html#prérequis",
    "title": "36  Calcul des features",
    "section": "\n36.2 Prérequis",
    "text": "36.2 Prérequis\nPour calculer les features MOSAIKS, vous aurez besoin de :\n\n\nImagerie satellite (voir Chapitre 32)\n\nUn environnement de calcul avec GPU (fortement recommandé)\n\nPython avec bibliothèques de deep learning (PyTorch recommandé)\n\nStockage suffisant pour les matrices de features",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#implémentation",
    "href": "fr/part-03-features/03-features-computing.html#implémentation",
    "title": "36  Calcul des features",
    "section": "\n36.3 Implémentation",
    "text": "36.3 Implémentation\nIl existe plusieurs manières d’implémenter l’extraction des features MOSAIKS :\n\n36.3.1 Implémentation avec torchgeo\n\nLa bibliothèque torchgeo fournit une implémentation PyTorch des features de convolution aléatoires (RCF) :\nimport torch\nfrom torchgeo.models import RCF\n\n# Définition des paramètres du modèle\npatch_size = 3  # Taille des patches aléatoires\nin_channels = 4  # Nombre de bandes spectrales d’entrée\nnum_filters = 4000  # Nombre de features à générer\n\n# Pour le mode 'empirical', fournir une classe PyTorch Dataset personnalisée\n# Si 'gaussian', ne pas fournir de dataset.\n\n# Initialisation du modèle RCF\nmodel = RCF(\n    in_channels=in_channels, \n    features=num_filters, \n    kernel_size=3, \n    bias=-1.0, \n    seed=42, \n    mode='empirical',\n    dataset=CustomDataset,\n)\n\n# Déplacement du modèle sur GPU si disponible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#paramètres-des-features",
    "href": "fr/part-03-features/03-features-computing.html#paramètres-des-features",
    "title": "36  Calcul des features",
    "section": "\n36.4 Paramètres des features",
    "text": "36.4 Paramètres des features\nPlusieurs paramètres clés influencent l’extraction des features :\n\n36.4.1 Nombre de features (K)\n\nDétermine la dimensionnalité du vecteur de features\n\nUn plus grand nombre de features capture plus d’informations\n\nAugmente la charge de calcul et les besoins en stockage\n\nPlage typique : 1 000 - 8 192 features\n\n\nDiminution des gains au-delà de 4 000 features\n\n\n36.4.2 Taille des patches\n\nDétermine l’étendue spatiale prise en compte\nDes patches plus grands capturent plus de contexte\n\nMais augmentent la charge de calcul\n\nTaille typique : 3×3 ou 5×5 pixels\n\nÀ adapter à la résolution de l’imagerie\n\n36.4.3 Nombre de canaux en entrée\n\nDépend du nombre de bandes spectrales disponibles\nRVB = 3 canaux\nPossibilité d’utiliser des bandes supplémentaires (ex. NIR, SWIR)\nPlus de bandes = information spectrale plus riche\n\nMais augmente la charge de calcul",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#considérations-pratiques",
    "href": "fr/part-03-features/03-features-computing.html#considérations-pratiques",
    "title": "36  Calcul des features",
    "section": "\n36.5 Considérations pratiques",
    "text": "36.5 Considérations pratiques\n\n36.5.1 Gestion de la mémoire\nLors du traitement de grands ensembles de données satellitaires :\n\n\nUtilisation de mini-batches pour limiter la consommation mémoire\n\nStockage temporaire sur disque si la RAM est insuffisante\n\nUtilisation de torch.no_grad() pour désactiver la rétropropagation\n\n36.5.2 Formats de stockage\nFormats efficaces pour stocker de grandes matrices de features :\n\n\nParquet (rapide, compressé, optimisé pour le stockage et l’accès)\n\nZarr (bon pour l’accès distribué et le cloud computing)\n\nFeather (optimisé pour Pandas et Apache Arrow)\n\n36.5.3 Traitement parallèle\nPour extraire les features sur de grands ensembles de données :\n\nUtilisation de torch.multiprocessing\nDécoupage des images en lots\n\nExécution sur plusieurs GPU (si disponible)\nTraitement en parallèle sur un cluster",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#contrôle-qualité",
    "href": "fr/part-03-features/03-features-computing.html#contrôle-qualité",
    "title": "36  Calcul des features",
    "section": "\n36.6 Contrôle qualité",
    "text": "36.6 Contrôle qualité\nVérifications essentielles lors de l’extraction des features :\n\n\nValidation des entrées\n\nDimensions des images\nGamme des valeurs de pixels\nDonnées manquantes\nOrdre des bandes spectrales\n\n\n\nAnalyse statistique des features\n\nVérification des distributions\nDétection de valeurs nulles/anormales\nCorrélation entre features\nAnalyse de l’importance des features\n\n\n\nSuivi des performances\n\nUtilisation de la mémoire\nVitesse de traitement\nUtilisation du GPU\nEfficacité du stockage",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/03-features-computing.html#bonnes-pratiques",
    "href": "fr/part-03-features/03-features-computing.html#bonnes-pratiques",
    "title": "36  Calcul des features",
    "section": "\n36.7 Bonnes pratiques",
    "text": "36.7 Bonnes pratiques\n\n\nDocumentation\n\nEnregistrer tous les paramètres utilisés\n\nTracer les sources de données\n\nDocumenter les étapes de traitement\n\nNoter les éventuels problèmes rencontrés\n\n\n\n\nTests\n\nTests unitaires sur les fonctions critiques\n\nTests d’intégration\nTests de performance\nVérifications de validité des résultats\n\n\n\nGestion des versions\n\nVersionner le code\n\nVersionner les features\n\nSuivre les paramètres d’extraction\n\nEnregistrer les résultats intermédiaires\n\n\n\n\n\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le prochain chapitre, nous travaillerons sur un exemple complet de calcul de features MOSAIKS personnalisées.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Calcul des features</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/04-features-demo.html",
    "href": "fr/part-03-features/04-features-demo.html",
    "title": "37  Démonstration de la featurisation",
    "section": "",
    "text": "37.1 Vue d’ensemble\nCette démonstration vous montrera quelques concepts clés liés à la featurisation des données satellitaires pour une utilisation avec MOSAIKS.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Démonstration de la featurisation</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/04-features-demo.html#code-de-démonstration",
    "href": "fr/part-03-features/04-features-demo.html#code-de-démonstration",
    "title": "37  Démonstration de la featurisation",
    "section": "\n37.2 Code de démonstration",
    "text": "37.2 Code de démonstration\nVous trouverez ci-dessous un lien vers un notebook Jupyter conçu pour illustrer la featurisation des images satellitaires. Ce notebook vous guidera à travers les étapes suivantes :\n\nConstruction d’un modèle pytorch à partir de zéro\nUtilisation d’une solution préexistante avec torchgeo\nCréation d’un dataset et d’un dataloader en torch\nFeaturisation d’images satellitaires\nEnregistrement des features sur disque\nVisualisation des features extraites\n\n\n\n\n\n\n\n\nCliquez sur l’icône pour exécuter la démonstration !\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Pensez à cliquer sur File -&gt; Save a copy in Drive pour enregistrer vos modifications.\n\nOu pour voir une version statique du code sur GitHub, cliquez sur l’icône ci-dessous. \n\n\n\nPour obtenir des instructions et des conseils sur l’utilisation de Google Colab, veuillez vous référer à Chapitre 23.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Démonstration de la featurisation</span>"
    ]
  },
  {
    "objectID": "fr/part-03-features/04-features-demo.html#quelle-est-la-suite",
    "href": "fr/part-03-features/04-features-demo.html#quelle-est-la-suite",
    "title": "37  Démonstration de la featurisation",
    "section": "\n37.3 Quelle est la suite ?",
    "text": "37.3 Quelle est la suite ?\nMaintenant que nous avons couvert les bases de la featurisation des données satellitaires, nous allons passer à la section suivante, qui traitera du modélisation des étiquettes avec les features satellitaires.\n\n\n\n\n\n\n\nÀ venir\n\n\n\nCeci marque la fin de la section sur la featurisation. Nous allons maintenant passer à la modélisation des étiquettes à l’aide des features extraites des satellites.",
    "crumbs": [
      "Features provenant des satellites",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Démonstration de la featurisation</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/00-model.html",
    "href": "fr/part-04-models/00-model.html",
    "title": "Modélisation des tâches",
    "section": "",
    "text": "Plan de section\nLes chapitres suivants vous guideront à travers des aspects clés des tâches de modélisation dans le cadre MOSAIKS:",
    "crumbs": [
      "Modélisation des tâches"
    ]
  },
  {
    "objectID": "fr/part-04-models/00-model.html#plan-de-section",
    "href": "fr/part-04-models/00-model.html#plan-de-section",
    "title": "Modélisation des tâches",
    "section": "",
    "text": "Aperçu de la section de modélisation\n\n\n\n\n\nChapitre\nSujets clés\n\n\n\n38  Construire, évaluer, déployer\nSélection de l’algorithme, choix des hyperparamètres\n\n\n39  Parcourir l’espace\nValidation croisée spatiale, généralisation géographique\n\n\n40  Aller au fil du temps\nAnalyse des séries chronologiques, alignement temporel",
    "crumbs": [
      "Modélisation des tâches"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html",
    "href": "fr/part-04-models/01-model-choice.html",
    "title": "38  Construire, évaluer, déployer",
    "section": "",
    "text": "38.1 Aperçu\nLorsque vous utilisez MOSAIKS (observation multi-tâches à l’aide d’images satellites et d’évier de cuisine), la sélection du modèle dépend largement du type de données de vos étiquettes. Bien que des méthodes plus complexes soient certainement possibles, l’expérience montre que les modèles linéaires fonctionnent souvent remarquablement bien. En effet, les features convolutionnelles aléatoires dans MOSAIKS capturent et encodent déjà des informations non linéaires de l’imagerie satellite sous-jacente. Ce chapitre décrira les approches de modélisation pour différents types de données d’étiquette et offrira des conseils sur les meilleures pratiques pour l’évaluation du modèle.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#séparation-des-données-dentraînementvalidation-et-de-test",
    "href": "fr/part-04-models/01-model-choice.html#séparation-des-données-dentraînementvalidation-et-de-test",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.2 Séparation des données d’entraînement/validation et de test",
    "text": "38.2 Séparation des données d’entraînement/validation et de test\nAvant d’entrer dans les détails, il est important de souligner que pour toutes les modélisation suivent une approche basée sur une phase d’entraînement, une phase de validation (peut être omise dans certains cas) et une phase de test.\n\n\nEnsemble d’entraînement/validation (80% des données)\n\n\nEnsemble de test (20% des données)\n\nCela garantit que vous avez des ensembles de données distincts et impartiaux pour l’ajustement du modèle et l’évaluation des performances finales.\n\n\n\n\n\nFigure 38.1: Ensemble d’apprentissage/validation et de test pour une procédure de validation croisée standard de 5 blocs.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#étiquettes-continues",
    "href": "fr/part-04-models/01-model-choice.html#étiquettes-continues",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.3 Étiquettes continues",
    "text": "38.3 Étiquettes continues\nDe nombreuses applications MOSAIKS impliquent de prédire des résultats continus tels que le pourcentage de couverture forestière, la densité de population, le revenu moyen, les rendements des cultures ou la hauteur du bâtiment. Dans ces cas, les approches de régression linéaire pénalisée (en particulier régression ridge) fonctionnent bien. Ces méthodes offrent une simplicité, une efficacité de calcul et une interprétabilité, tout en atténuant le surapprentissage grâce à l’utilisation de la régularisation.\n\n38.3.1 Régression Ridge\nLa régression ridge (régularisation L2) est souvent le choix par défaut dans les applications MOSAIKS car il gère efficacement le grand nombre de fonctionnalités potentiellement corrélées produites par le processus de convolution aléatoire. Il y parvient via une pénalité L2 sur les coefficients de régression, ce qui réduit les coefficients vers zéro et réduit la variance, améliorant ainsi la généralisation.\nLa fonction d’objectif de la régression Ridge: \\[\n\\min_{\\beta} \\|y - X\\beta\\|^2_2 + \\lambda\\|\\beta\\|^2_2\n\\]\nOù:\n\n\n\\(\\lambda\\) contrôle l’intensité du terme de régularisation,\n\n\\(\\beta\\) sont les coefficients de la régression,\n\n\\(y\\) est le vecteur des étiquettes,\n\n\\(X\\) est la matrice de features issus de MOSAIKS\n\n38.3.2 Régression Lasso\nLa régression Lasso (régularisation L1) peut mettre la valeurs des coefficients à zéro, effectuant efficacement la sélection des features .La pénalité L1 aide à éliminer des variables dans le modèle, ce qui peut être utile lorsque l’interprétabilité ou l’identification des features clés est une priorité. propriété rend Lasso particulièrement précieux lorsque vous souhaitez identifier les features de MOSAIKS qui contribuent le plus fortement aux prédictions.\nLa fonction objectif de la régression Lasso:\n\\[\n\\min_{\\beta} \\|y - X\\beta\\|^2_2 + \\lambda\\|\\beta\\|_1\n\\]\nOù:\n\n\n\\(\\lambda\\) contrôle à nouveau la force de la pénalité,\nLe \\(\\|\\beta\\|_1\\) terme encourage certains coefficients à être exactement nul.\n\nLes deux peuvent être facilement mis en œuvre à l’aide de Scikit-Learn:\nfrom sklearn.linear_model import Ridge, Lasso\n\n# Ridge regression\nridge = Ridge(alpha=1.0)  # alpha is the regularization strength (λ)\nridge.fit(X_train, y_train)\n\n# Lasso regression\nlasso = Lasso(alpha=1.0)\nlasso.fit(X_train, y_train)\n\n38.3.3 Pourquoi les modèles linéaires fonctionnent bien\nBien que les modèles eux-mêmes soient linéaires, les features ne le sont pas. MOSAIKS utilise des convolutions aléatoires, des fonctions d’activation non linéaires (RELU) et un average pooling pour transformer l’imagerie satellite brute en features pertinentes. Étant donné que ces transformations capturent une large gamme de modèles spatiaux non linéaires, les méthodes linéaires traditionnelles peuvent alors bien fonctionner avec une complexité supplémentaire minimale.\n\n38.3.4 Métriques d’évaluation\nPour les résultats continus, les mesures d’évaluation clés comprennent:\n\n\nR²(Coefficient de détermination): Mesure la proportion de variance dans les données d’étiquette expliquée par le modèle.\n\n\nRMSE (Racine carrée de l’erreur quadratique moyenne): Quantifie l’ampleur moyenne des erreurs de prédiction.\n\n\nMAE (Erreur absolue moyenne): Différence absolue moyenne entre les prédictions et les valeurs réelles, moins sensible aux grandes valeurs aberrantes que RMSE.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#classification-binaire",
    "href": "fr/part-04-models/01-model-choice.html#classification-binaire",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.4 Classification binaire",
    "text": "38.4 Classification binaire\nDans certaines applications de MOSAIKS, vos étiquettes peuvent être binaires (par exemple, la présence de bâtiments ou à l’absence, le changement d’utilisation des terres vs pas de changement). Ici, la régression logistique sert souvent de choix simple.\n\n38.4.1 La Régression logistique\nLa régression logistique modélise la probabilité qu’un exemple donné appartient à la classe “positive”: \\[\n\\text{logit}(p) = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_n x_n\n\\]\noù \\(p\\) est la probabilité d’appartenir à la classe positive. Malgré sa simplicité, la régression logistique fournit des performances robustes et interprétables pour de nombreuses tâches de classification binaire avec des features de MOSAIKS.\n\n38.4.2 Métriques d’évaluation\nPour la classification binaire, les mesures communes comprennent:\n\n\nAUC-ROC: La zone sous la courbe ROC, évaluant le compromis entre le taux de vrais positifs et le taux de faux positifs selon différents valeurs de seuil.\n\n\nPrécision: la proportion de prédictions correctes.\n\n\nPrécision: Parmi les prédictions positives faites, combien étaient correctes?\n\n\nRappel: Parmi les positifs réels de l’ensemble de données, combien en avons-nous identifié correctement?\n\n\nScore F1: La moyenne harmonique de la précision et du rappel, souvent utilisée dans les cas de classification déséquilibrée.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#classification-multi-classes",
    "href": "fr/part-04-models/01-model-choice.html#classification-multi-classes",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.5 Classification multi-classes",
    "text": "38.5 Classification multi-classes\nCertaines applications nécessitent de prédire plusieurs catégories (par exemple, les types de couverture terrestre, la variété des cultures, les catégories de construction). Ce sont des problèmes de classification multi-classes. Plusieurs approches sont possibles:\n\n\nOne-Vs-Rest: Entraîner un classificateur binaire pour chaque classe ; chaque classificateur distingue une classe de “tous les autres”.\n\n\nRégression multinomiale (softmax): un seul modèle pour prédire les probabilités dans toutes les classes simultanément.\n\n\nRégression ordinale: pour prédire les catégories ordonnées (par exemple, léger, modéré et grave).\n\n\n\n\n\n\nFigure 38.2: Exemple de classification multiclasse\n\n\n\n38.5.1 Métriques d’évaluation\nPour les problèmes multi-classes, considérez:\n\n\nPrécision globale: pourcentage d’exemples correctement classé.\n\n\nPrécision par classe: Précision dans chaque classe, utile si les tailles de classe sont déséquilibrées.\n\n\nMatrice de confusion: fournit une ventilation détaillée des prédictions par rapport aux classes réelles.\n\n\nScore F1 pondéré: moyenne F1 dans les classes, pondération par fréquence des classes.\n\n\nKappa de Cohen: mesure l’accord entre les étiquettes prévues et les étiquettes réelles, l’accord de l’ajustement pour le hasard.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#en-appliquant-le-modèle-pour-faire-des-prédictions",
    "href": "fr/part-04-models/01-model-choice.html#en-appliquant-le-modèle-pour-faire-des-prédictions",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.6 En appliquant le modèle pour faire des prédictions",
    "text": "38.6 En appliquant le modèle pour faire des prédictions\nUne fois que vous avez sélectionné un modèle et l’avoir réglé (par exemple, via la validation croisée), vous pouvez appliquer le modèle à de nouvelles données. Cette étape est souvent appelée “inférence”:\n\nPréparer les features: Les features des nouvelles zones ou périodes doivent être extraites en utilisant le même modèle RCF qui a été utilisé pour extraire les features d’origine. Ainsi, si les features de l’ensemble d’entraînement ont été calculés d’une manière différente de celle de l’API (choix de différents filtres de convolution par exemple), il est important que les features des nouvelles données soient calculés de la même manière (utilisation des mêmes filtres par exemple).\nChargez le modèle entraîné: Assurez-vous que le modèle (ainsi que les hyperparamètres et les étapes de prétraitement) est chargé exactement comme il a été ajusté. Cette cohérence est essentielle pour maintenir la précision prédictive.\n\nPrédire: Mettre la nouvelle matrice de fonctionnalités (X_new) dans la méthode predict du modèle entraîné pour obtenir des prédictions. Par exemple, en utilisant Scikit-Learn:\ny_pred = ridge.predict (x_new)\n\n\nSi votre tâche est une classification, utilisez predict_proba pour obtenir des probabilités prédites: python    p_pred = logistic_regression.predict_proba(X_new)\n\n\nInterpréter et stocker les résultats: Enregistrer les prédictions dans un format structuré (par exemple, CSV, Geotiff) pour une analyse ultérieure. Envisagez d’inclure des métadonnées sur la date et la version de votre modèle, le processus d’extraction des features MOSAIKS et toutes les notes pertinentes sur la qualité des données.\n\nEn suivant ces étapes, vous vous assurez que vos modèles MOSAIKS sont déployés de manière efficace et cohérente. De là, vous pouvez visualiser les prédictions, les intégrer dans des analyses en aval ou éclairer la politique et la prise de décision en fonction de la sortie du modèle.\n\n38.6.1 Changement de distribution\nLorsque vous appliquez votre modèle à de nouvelles régions géographiques ou dans différentes conditions, sachez que la distribution des données sous-jacente (modèles d’imagerie satellite, facteurs socio-économiques, types d’utilisation des terres/couverture terrestre) peut différer de votre ensemble de formation. Ce “changement de distribution” peut entraîner une réduction des performances prédictives si le modèle n’a pas été exposé à des exemples similaires pendant l’entraînement. Pour atténuer cela, envisagez de collecter des données d’apprentissage représentatives supplémentaires à partir de ces nouvelles régions, d’adopter des techniques d’apprentissage ou d’adaptation de domaine et de quantification de l’incertitude prédictive afin que vous puissiez signaler les domaines où le modèle peut mal performer. Audits de performances périodiques et réentraînement - en particulier lorsque de nouvelles données deviennent disponibles - assurent une généralisation robuste à travers diverses géographies.\nIl est possible de prédire à une résolution plus élevée que les étiquettes. En effet dans certains, cas un modèle entraîné sur une résolution donnée, par exemple 1km x 1km, peut être utilisé pour faire des prédictions à une résolution de 250m x 250m. Il est important de rester vigilant lorsque l’onn utilise le modèle dans de tels cas et s’assurer que les performances à plus grande résolution reste comparable à la résolution initiale.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#quantification-de-lincertitude",
    "href": "fr/part-04-models/01-model-choice.html#quantification-de-lincertitude",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.7 Quantification de l’incertitude",
    "text": "38.7 Quantification de l’incertitude",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#processus-de-sélection-dun-modèle",
    "href": "fr/part-04-models/01-model-choice.html#processus-de-sélection-dun-modèle",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.8 Processus de sélection d’un modèle",
    "text": "38.8 Processus de sélection d’un modèle\n\n\nIdentifier le type d’étiquette\n\nContinue → Régression Ridge ou Lasso\n\nBinaire → Régression logistique\n\nMulti-Classe → One-VS-Rest ou multinomial\n\n\n\nValidation croisée\n\nDiviser les données en ensemble d’apprentissage, validation et ensemble de test, en respectant la structure spatiale si possible (par exemple, un contre tous (leave-one-out)).\n\nSélectionnez les mesures d’évaluation appropriées (par exemple, R² pour continu, ROC-AUC pour le binaire).\n\nChoisir les hyperparamètres (\\(\\lambda\\) dans Ridge / Lasso, régularisation en logistique) en utilisant l’ensemble de validation.\n\n\n\nDéploiement du modèle\n\nRéentraîner le modèle sur l’ensemble des données en utilisant les hyperparamètres choisis.\n\nGénérer des prédictions sur l’ensemble de tests (ou de nouvelles données).\n\nQuantifier l’incertitude (par exemple, intervalles de confiance, estimations d’erreur hors échantillon).",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/01-model-choice.html#résumé",
    "href": "fr/part-04-models/01-model-choice.html#résumé",
    "title": "38  Construire, évaluer, déployer",
    "section": "\n38.9 Résumé",
    "text": "38.9 Résumé\n\n\nCommencez par des modèles linéaires simples: Utiliser les features MOSAIKSpour obtenir des données non linéaires.\n\n\nFaites correspondre la métrique à la tâche: R² ou RMSE pour les étiquettes continues, le score AUC-ROC ou F1 pour la classification, etc.\n\n\nUtilisez la validation croisée: Toujours séparer les ensembles d’entraînement et de test pour obtenir des estimations non biaisées des performances du modèle.\n\nConsidérons la structure spatiale: Lorsque vous traitez des données spatiales, des divisions aléatoires standard peuvent conduire à des estimations trop optimistes des performances.\n\nLes éléments clés pour la construction de modèles réussis comprennent:\n\n\nSélection d’algorithme\n\nChoisissez en fonction du type d’étiquette\nConsidérez les besoins de calcul\nTrouver un équilibre entre complexité et performance\n\n\n\nValidation croisée\n\nUtilisez le facteur spatial lors de la création des différents ensembles\nSélectionnez des métriques appropriées\nAjuster les hyperparamètres du modèle\n\n\n\nÉvaluation du modèle\n\nTester les performances sur un ensemble de test\nValider dans l’espace (si possible)\nQuantifier les incertitudes\n\n\n\nDéploiement\n\nEntraîner le modèle final\nGénérer des prédictions\nDocumenter la procédure\nSurveiller les performances\n\n\n\n\n\n\n\n\n\nÀ venir\n\n\n\nDans le chapitre suivant, nous discuterons des stratégies de comptabilité des dépendances spatiales dans votre flux de travail de modélisation, y compris des méthodes de validation croisée spatiale, d’interpolation spatiale et d’extrapolation spatiale.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Construire, évaluer, déployer</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/02-model-spatial.html",
    "href": "fr/part-04-models/02-model-spatial.html",
    "title": "39  Parcourir l’espace",
    "section": "",
    "text": "39.1 Étiqueter la super-résolution",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Parcourir l'espace</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/02-model-spatial.html#étiqueter-la-super-résolution",
    "href": "fr/part-04-models/02-model-spatial.html#étiqueter-la-super-résolution",
    "title": "39  Parcourir l’espace",
    "section": "",
    "text": "Exemple HDI",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Parcourir l'espace</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/02-model-spatial.html#extrapolation-spatiale",
    "href": "fr/part-04-models/02-model-spatial.html#extrapolation-spatiale",
    "title": "39  Parcourir l’espace",
    "section": "\n39.2 Extrapolation spatiale",
    "text": "39.2 Extrapolation spatiale\n\nExemple ASM (prédire les mines dans de nouveaux pays)\nPasser en revue l’espace des features et montrer une dimension réduite\n\nConvergence des pays vs divergence dans les étiquettes\n\n\n\n\n\n\n\n\n\nClick the badge to run the demo in Google Colab!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓\nN’oubliez pas de cliquer File -&gt; Save a copy in Drive pour enregistrer toutes les modifications que vous apportez.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Parcourir l'espace</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/02-model-spatial.html#interpolation-spatiale",
    "href": "fr/part-04-models/02-model-spatial.html#interpolation-spatiale",
    "title": "39  Parcourir l’espace",
    "section": "\n39.3 Interpolation spatiale",
    "text": "39.3 Interpolation spatiale\n\nCombler les lacunes à partir des données d’enquête. Par exemple vous avez des données de population pour certaines zones mais pas toutes.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Parcourir l'espace</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html",
    "href": "fr/part-04-models/03-model-temporal.html",
    "title": "40  Aller au fil du temps",
    "section": "",
    "text": "40.1 Comprendre la résolution temporelle\nL’analyse des séries chronologiques dans les applications ML basées sur satellite nécessite une attention particulière à la résolution temporelle de vos étiquettes et de vos images. Dans le contexte des MOSAIKS, vous pouvez opter pour différentes stratégies en fonction de la fréquence des acquisitions de satellites et de la rapidité avec laquelle votre résultat d’intérêt change.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#comprendre-la-résolution-temporelle",
    "href": "fr/part-04-models/03-model-temporal.html#comprendre-la-résolution-temporelle",
    "title": "40  Aller au fil du temps",
    "section": "",
    "text": "Figure 40.1: ESRI visualisation des valeurs de pixels pour un emplacement donné changeant dans le temps.\n\n\n\n40.1.1 Alignement temporel\nLorsque vous alignez les données dans le temps, considérez:\n\nFréquence de l’étiquette: À quelle fréquence les mesures du sol sont-elles collectées? Par exemple, les rendements des cultures annuelles, les indicateurs économiques mensuels ou même les observations météorologiques quotidiennes. La granularité de ces points de données guidera comment les faire correspondre à vos features dérivées de satellites.\nDisponibilité des images: À quelle fréquence pouvez-vous obtenir des images satellites claires de votre domaine d’intérêt? Des fréquences de revisite élevées permettent des observations plus fréquentes, mais des facteurs tels que les anomalies de couverture nuageuse ou de capteur peuvent réduire le nombre réel d’images utilisables.\nChangement Detection: À quelle vitesse votre variable d’intérêt change-t-elle? Le développement urbain peut se dérouler sur des mois ou des années, tandis que les événements d’inondation peuvent se produire en quelques jours. Il est crucial de faire correspondre la granularité temporelle de vos features à la dynamique de votre phénomène.\n\n40.1.2 Modèles saisonniers\nLes processus naturels et axés sur l’homme présentent souvent de solides signaux saisonniers:\n\nCycles naturels: La croissance de la végétation, la couverture de neige et l’étendue de l’eau sont toutes influencées par les saisons. Par exemple, les métriques NDVI pourraient être plus informatives pendant les saisons de croissance de pointe (Figure 18.2).\nActivités humaines: Les cycles de culture, les voyages de vacances et la demande de chauffage ou de refroidissement ne sont que quelques exemples de la façon dont le comportement humain peut varier tout au long de l’année. Ces rythmes temporels peuvent introduire des modèles systématiques dans vos données.\nExtraction des caractéristiques: Parce que les observations par satellite reflètent les conditions de surface, différentes périodes de l’année peuvent nécessiter des ensembles de features distinctes.Par exemple, les valeurs de réflectance changent lorsque la végétation est sénescente vs lorsqu’elle est pleinement cultivée. De même, les conditions atmosphériques (comme la brume) peuvent être plus répandues à certaines saisons. \n\n40.1.3 Défis dans les applications de séries chronologiques\nBien que les avantages potentiels de l’analyse des séries chronologiques soient significatifs, il y a quelques pièges communs:\n\n40.1.3.1 Données manquantes\n\nCouverture nuageuse: Dans les régions avec une couverture nuageuse élevée, l’imagerie utilisable peut être clairsemée, conduisant à des intervalles de temps irréguliers entre les observations valides.\nMaintenance des satellites ou défaillance des capteurs: Même les interruptions courtes dans les opérations par satellite peuvent réduire la disponibilité des données.\nModèles orbitaux: Certains satellites ont des horaires de revisite spécifiques, ce qui signifie que certaines zones peuvent ne pas être imagées aussi souvent que d’autres, ce qui conduit à des données temporelles inégales.\n\n\n\n\n\n\nFigure 40.2: Visualisation de la couverture nuageuse au dessus de la forêt amazonienne.\n\n\n\n\n\n\n\n\nLecture recommandée\n\n\n\nPour plus d’informations sur la couverture cloud et son impact sur les données par satellite, voir Flores-Anderson et al. 2023.\n\n\n\n40.1.4 Données satellites prétraitées\nPlusieurs fournisseurs de satellites proposent des outils de pré-traitement des données spécialement conçus pour l’analyse des séries chronologiques. Ces outils gèrent des défis communs comme la couverture nuageuse et la normalisation:\n\n40.1.4.1 Indices de végétation MODIS\n\nComposites de 16 jours ou mensuels des indices de végétation (par exemple NDBI, EVI)\nMasquage des nuages ​​automatisé et contrôle de la qualité\nValeurs de réflectance de surface normalisées pour les effets atmosphériques\nCouverture globale à une résolution de 250m-1 km depuis 2000\nIdéal pour surveiller les dynamiques saisonnières de la végétation\n\n40.1.4.2 Planet Basemap\n\nComposites visuels trimestriels de plusieurs satellites PlanetScope\nMosaïques sans nuage utilisant les meilleurs pixels disponibles\nÉquilibrage des couleurs et calibrage radiométrique\nCouverture globale à une résolution d’environ 4,7m\nConvient pour suivre les changements progressifs d’utilisation des terres\n\n40.1.4.3 Harmonized Landsat-Sentinel (HLS)\n\nProduit combiné utilisant les images de Landsat 8-9 et Sentinel-2\nFréquence de révision de 2-3 jours à une résolution de 30m\nCorrection atmosphérique et co-enregistrée\nValeurs de réflectance de surface cohérentes entre les capteurs\nFournit des séries chronologiques denses depuis 2013\n\nCes produits réduisent la charge de prétraitement pour les utilisateurs, mais peuvent ne pas saisir des changements rapides qui se produisent entre les périodes de composition. Le choix entre l’utilisation d’images brutes ou les produits prétraités dépend de la résolution temporelle nécessaire pour votre application spécifique. Ces produits de données et comment les utiliser seront couverts plus en détail dans Chapitre 31 et Chapitre 32.\n\n40.1.4.4 Cohérence temporelle\n\nDéviation du capteur: Au fil du temps, les capteurs satellites peuvent se dégrader ou dériver, influençant la cohérence de vos données. Un étalonnage approprié peut atténuer ces problèmes.\nCalibration multi-capteurs: Si vous combinez des données de plusieurs satellites dans une constellation, assurez-vous que les différences de sensibilité des capteurs ou de bandes n’introduisent pas de signaux parasites dans vos séries temporelles.\n\n\nVideo\nImages de [North Platte, Nebraska] durant différents laps de temps(https://www.planet.com/industries/agriculture/). Imagerie et visualisation de Planet Labs Inc.\n\n\n40.1.4.5 Stockage et calcul\n\nVolume de données Chaque pas de temps supplémentaire dans votre analyse augmente les exigences de stockage et de traitement.\nCorrélation temporelle De nombreux phénomènes de séries chronologiques présentent une autocorrélation, qui peut influencer la façon dont vous concevez et entraînez des modèles. Les algorithmes ML standard supposent que l’indépendance entre les échantillons, de sorte que des méthodes ou des caractéristiques spécialisées (telles que des caractéristiques décalées) peuvent être nécessaires pour gérer les dépendances temporelles.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#approches-de-la-modélisation-des-séries-chronologiques",
    "href": "fr/part-04-models/03-model-temporal.html#approches-de-la-modélisation-des-séries-chronologiques",
    "title": "40  Aller au fil du temps",
    "section": "\n40.2 Approches de la modélisation des séries chronologiques",
    "text": "40.2 Approches de la modélisation des séries chronologiques\nVous trouverez ci-dessous trois stratégies courantes pour incorporer des données de séries chronologiques dans un cadre de type MOSAIKS. Chaque approche a des compromis en termes de complexité, de coût de calcul et d’interprétabilité.\n\n40.2.1 Empilement des features\nDans une approche d’empilement de features, vous générez des features MOSAIKS pendant plusieurs pas de temps, puis les concaténez en un seul vecteur de fonctionnalité. Ceci est simple, mais peut conduire à de très grands espaces de features si vous avez de nombreux moments.\n\nCalculez les features pour chaque période de temps Exécutez l’extraction de vos features MOSAIKS pour chaque trimestre, mois ou année - quelle que soit le temps de granularité.\nConcaténer les features Combinez-les en un seul vecteur, en veillant à les nommer de sorte à pouvoir distinguer les pas de temps.\nEntraînement du modèle Entrez les features empilées dans votre algorithme d’apprentissage automatique préféré (par exemple, régression linéaire, forêt aléatoire ou réseaux de neurones).\n\nExemple (empilement trimestriel):\n# Create feature names for each quarter\nfeatures_Q1 = [f'X_{i}_Q1' for i in range(1000)]  # X_0_Q1, X_1_Q1, ..., X_999_Q1\nfeatures_Q2 = [f'X_{i}_Q2' for i in range(1000)]  # X_0_Q2, X_1_Q2, ..., X_999_Q2\nfeatures_Q3 = [f'X_{i}_Q3' for i in range(1000)]  # X_0_Q3, X_1_Q3, ..., X_999_Q3\nfeatures_Q4 = [f'X_{i}_Q4' for i in range(1000)]  # X_0_Q4, X_1_Q4, ..., X_999_Q4\n\n# Combine features names for all quarters\nfeatures_annual = features_Q1 + features_Q2 + features_Q3 + features_Q4\n\n# Total length = 4,000 features for four quarters\nfeatures_df = pd.DataFrame(data=features, columns=features_annual)\nCette approche convient généralement aux données annuelles ou saisonnières où le nombre de pas de temps reste gérable.Cependant, il peut être moins pratique si vous avez des observations quotidiennes ou hebdomadaires sur plusieurs années.\n\n40.2.2 Aggrégation temporelle\nDans l’agrégation temporelle, vous calculez les features à une fréquence plus élevée, mais les résumez ensuite sur une fenêtre temporelle:\n\nExtraire les features à haute fréquence Cela fournit une vue temporelle riche.\nAggréger les features Calculer des résumés statistiques tels que la moyenne, le maximum ou la variance de chaque fonctionnalité à travers la fenêtre de temps choisie. Les fenêtres communes comprennent des agrégations quotidiennes, hebdomadaires, mensuelles et trimestrielles.\nAjuster un modèle avec les features agrégées Les features agrégées peuvent représenter des processus dynamiques tout en contrôlant la dimensionnalité de votre ensemble de données.\n\nCette méthode capture les tendances générales et réduit le bruit de la couverture nuageuse ou d’autres facteurs transitoires. Cependant, d’importantes nuances temporelles (comme des événements spécifiques de courte durée) pourraient être perdus dans l’agrégation.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#dégradation-des-performances-dans-le-temps",
    "href": "fr/part-04-models/03-model-temporal.html#dégradation-des-performances-dans-le-temps",
    "title": "40  Aller au fil du temps",
    "section": "\n40.3 Dégradation des performances dans le temps",
    "text": "40.3 Dégradation des performances dans le temps\nÉvaluation dans le temps\n\n40.3.1 Modélisation séquentielle\nPour les phénomènes où l’ordre temporel est crucial et des observations fréquentes existent, la modélisation séquentielle peut être plus puissante:\n\nExtraction des features Maintenez la dimension temporelle dans votre matrice de fonctionnalité (par exemple, une matrice par emplacement, avec le temps comme lignes et features comme colonnes).\nAppliquer la modélisation des séries chronologiques des techniques comme les réseaux LSTM (mémoire à court terme), les réseaux de convolution temporelle ou les modèles classiques d’espace d’état (par exemple ARIMA) peuvent gérer explicitement les dépendances temporelles.\nCorrelations avec des variables passées Incorporez les caractéristiques des pas de temps précédents pour capturer les effets retardés (par exemple, les précipitations du mois dernier affectant la végétation aujourd’hui).\n\nBien que ces méthodes fournissent une vision plus nuancée des processus temporels, ils nécessitent une expertise de modélisation et des ressources de calcul supplémentaires.\n\n\n\n\n\n\nCommencez par une approche plus simple comme l’empilement des features ou l’agrégation temporelle.Si vous constatez que votre phénomène a une dynamique temporelle rapide ou complexe qui n’est pas bien accumulée par ces méthodes, explorez les modèles séquentiels plus avancés.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#pratique-sur-les-séries-chronologiques",
    "href": "fr/part-04-models/03-model-temporal.html#pratique-sur-les-séries-chronologiques",
    "title": "40  Aller au fil du temps",
    "section": "\n40.4 Pratique sur les séries chronologiques",
    "text": "40.4 Pratique sur les séries chronologiques\nAu lieu des features de MOSAIKS de séries chronologiques, nous allons plutôt démontrer des exemples similaires en utilisant des données MODIS NDVI. Cela nous permettra d’explorer les défis et les opportunités de l’analyse des séries chronologiques sans avoir besoin d’une extraction des features personnalisées.\n\n\n\n\n\n\nClick the badge to run the demo in Google Colab!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓\nN’oubliez pas de cliquer File -&gt; Save a copy in Drive pour enregistrer toutes les modifications que vous apportez.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#combler-les-données-manquantes",
    "href": "fr/part-04-models/03-model-temporal.html#combler-les-données-manquantes",
    "title": "40  Aller au fil du temps",
    "section": "\n40.5 Combler les données manquantes",
    "text": "40.5 Combler les données manquantes\nLorsque vous travaillez avec des données de séries chronologiques, vous pouvez rencontrer des valeurs manquantes en raison de la couverture cloud, des problèmes de capteurs ou d’autres facteurs. Voici quelques stratégies courantes pour combler ces lacunes:",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/03-model-temporal.html#en-résumé",
    "href": "fr/part-04-models/03-model-temporal.html#en-résumé",
    "title": "40  Aller au fil du temps",
    "section": "\n40.6 En résumé",
    "text": "40.6 En résumé\nLa gestion des séries chronologiques dans les workflows ML basés sur les satellites nécessite d’équilibrer le volume de données, l’alignement temporel et la complexité de modélisation. Bien que l’empilement des features puisse être efficace pour les processus à basse fréquence ou saisonniers, des techniques plus sophistiquées peuvent être nécessaires pour capturer des changements à haute fréquence ou des dépendances temporelles à longue portée.En fin de compte, la “meilleure” approche dépend de la nature de votre variable cible, de la disponibilité des données et des ressources à votre disposition.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Aller au fil du temps</span>"
    ]
  },
  {
    "objectID": "fr/part-04-models/04-model-demo.html",
    "href": "fr/part-04-models/04-model-demo.html",
    "title": "41  Construire un modèle",
    "section": "",
    "text": "Ce chapitre est en cours de construction et peut être incomplet.\n\n\n\n\n\n\n\n\n\n\nCliquez sur l’insigne pour exécuter la démonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ N’oubliez pas de cliquer File -&gt; Save a copy in Drive pour enregistrer toutes les modifications que vous apportez.\n\nOu pour afficher une version statique du code sur GitHub, cliquez sur l’insigne ci-dessous.",
    "crumbs": [
      "Modélisation des tâches",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Construire un modèle</span>"
    ]
  },
  {
    "objectID": "fr/part-05-responsible/00-responsible.html",
    "href": "fr/part-05-responsible/00-responsible.html",
    "title": "SIML responsable",
    "section": "",
    "text": "Plan de section\nLes chapitres suivants discuteront des aspects importants de l’incertitude et des préjugés du modèle, ainsi que les considérations éthiques dans le contexte des Mosaiks:",
    "crumbs": [
      "SIML responsable"
    ]
  },
  {
    "objectID": "fr/part-05-responsible/00-responsible.html#plan-de-section",
    "href": "fr/part-05-responsible/00-responsible.html#plan-de-section",
    "title": "SIML responsable",
    "section": "",
    "text": "Chapitre\nSujets clés\n\n\n\n42  Biais, capitaux propres et éthique\nUtilisation responsable, communication, limitations\n\n\n43  Quantification de l’incertitude\nSources d’erreur, intervalles de confiance, validation\n\n\n44  Transparence (démo)\nDémontrant comment les mosaiks peuvent être utilisés pour caractériser l’incertitude\n\n\n\n\n\nTable 1: Aperçu de la section d’incertitude",
    "crumbs": [
      "SIML responsable"
    ]
  },
  {
    "objectID": "fr/part-05-responsible/01-responsible-ethics.html",
    "href": "fr/part-05-responsible/01-responsible-ethics.html",
    "title": "42  Biais, capitaux propres et éthique",
    "section": "",
    "text": "NAis in early draft form and may be incomplete.\n\n\n\n\n\nhttps://www.earthcube.org/fair-training-materials\nhttps://www.fatml.org/\n\n\n\n\n\n\n\nÀ venir\n\n\n\nLe prochain chapitre\n\n\nPourrait inclure des concepts de ce document: The politics of pixels: A review and agenda for critical remote sensing\nLes facteurs sociopolitiques ont un impact qui collecte des données détectées à distance, comment elle est traitée et qui bénéficie des résultats.Cet article décline la politique de la télédétection et comment elle peut être utilisée pour promouvoir la justice sociale et l’équité.",
    "crumbs": [
      "SIML responsable",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Biais, capitaux propres et éthique</span>"
    ]
  },
  {
    "objectID": "fr/part-05-responsible/02-responsible-uncertainty.html",
    "href": "fr/part-05-responsible/02-responsible-uncertainty.html",
    "title": "43  Quantification de l’incertitude",
    "section": "",
    "text": "Ce chapitre est en cours de construction et peut être incomplet.",
    "crumbs": [
      "SIML responsable",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Quantification de l'incertitude</span>"
    ]
  },
  {
    "objectID": "fr/part-05-responsible/03-responsible-demo.html",
    "href": "fr/part-05-responsible/03-responsible-demo.html",
    "title": "44  Transparence (démo)",
    "section": "",
    "text": "Ce chapitre est en cours de construction et peut être incomplet.\n\n\n\n\n\n\n\n\n\n\nCliquez sur l’insigne pour exécuter la démonstration!\n\n\n\n↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Remember to click File -&gt; Save a copy in Drive to save any changes you make.\n\nOu pour afficher une version statique du code sur GitHub, cliquez sur l’insigne ci-dessous.",
    "crumbs": [
      "SIML responsable",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Transparence (démo)</span>"
    ]
  }
]