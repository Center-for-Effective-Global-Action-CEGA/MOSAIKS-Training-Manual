---
lang: fr
---
# Construire, évaluer, déployer {#sec-model-choice}

```{r}
#| echo: false
#| results: "asis"

source("../../_common.R")
status("draft_fr")
```

## Aperçu

Lorsque vous utilisez MOSAIKS (observation multi-tâches à l'aide d'images satellites et d'évier de cuisine), la sélection du modèle dépend largement du type de données de vos étiquettes. Bien que des méthodes plus complexes soient certainement possibles, l'expérience montre que **les modèles linéaires** fonctionnent souvent remarquablement bien. En effet, les features convolutionnelles aléatoires dans MOSAIKS capturent et encodent déjà des informations non linéaires de l'imagerie satellite sous-jacente. Ce chapitre décrira les approches de modélisation pour différents types de données d'étiquette et offrira des conseils sur les meilleures pratiques pour l'évaluation du modèle.

## Séparation des données d'entraînement/validation et de test

Avant d'entrer dans les détails, il est important de souligner que pour **toutes les modélisation** suivent une approche basée sur une phase d'entraînement, une phase de validation (peut être omise dans certains cas) et une phase de test.

- **Ensemble d'entraînement/validation** (80% des données)  
- **Ensemble de test** (20% des données)

Cela garantit que vous avez des ensembles de données distincts et impartiaux pour l'ajustement du modèle et l'évaluation des performances finales.  

![Ensemble d'apprentissage/validation et de test pour une procédure de validation croisée standard de 5 blocs.](../../images/kfold_cv_split.png){#fig-train-val-test-splits}

## Étiquettes continues

De nombreuses applications MOSAIKS impliquent de prédire des résultats continus tels que le pourcentage de couverture forestière, la densité de population, le revenu moyen, les rendements des cultures ou la hauteur du bâtiment. Dans ces cas, les approches de **régression linéaire pénalisée** (en particulier **régression ridge**) fonctionnent bien. Ces méthodes offrent une simplicité, une efficacité de calcul et une interprétabilité, tout en atténuant le surapprentissage grâce à l'utilisation de la régularisation.

### Régression Ridge

**La régression ridge** (régularisation L2) est souvent le choix par défaut dans les applications MOSAIKS car il gère efficacement le grand nombre de fonctionnalités potentiellement corrélées produites par le processus de convolution aléatoire. Il y parvient via une pénalité L2 sur les coefficients de régression, ce qui réduit les coefficients vers zéro et réduit la variance, améliorant ainsi la généralisation.

La fonction d'objectif de la régression Ridge:
$$
\min_{\beta} \|y - X\beta\|^2_2 + \lambda\|\beta\|^2_2
$$

Où:

- $\lambda$ contrôle l'intensité du terme de régularisation,
- $\beta$ sont les coefficients de la régression,
- $y$ est le vecteur des étiquettes,
- $X$ est la matrice de features issus de MOSAIKS

### Régression Lasso

**La régression Lasso** (régularisation L1) peut mettre la valeurs des coefficients à zéro, effectuant efficacement la sélection des features .La pénalité L1 aide à éliminer des variables dans le modèle, ce qui peut être utile lorsque l'interprétabilité ou l'identification des features clés est une priorité.  propriété rend Lasso particulièrement précieux lorsque vous souhaitez identifier les features de MOSAIKS qui contribuent le plus fortement aux prédictions.

La fonction objectif de la régression Lasso:

$$
\min_{\beta} \|y - X\beta\|^2_2 + \lambda\|\beta\|_1
$$

Où:

- $\lambda$ contrôle à nouveau la force de la pénalité, 
- Le $\|\beta\|_1$ terme encourage certains coefficients à être exactement nul.

Les deux peuvent être facilement mis en œuvre à l'aide de Scikit-Learn:

```python
from sklearn.linear_model import Ridge, Lasso

# Ridge regression
ridge = Ridge(alpha=1.0)  # alpha is the regularization strength (λ)
ridge.fit(X_train, y_train)

# Lasso regression
lasso = Lasso(alpha=1.0)
lasso.fit(X_train, y_train)
```

### Pourquoi les modèles linéaires fonctionnent bien

Bien que les modèles eux-mêmes soient linéaires, **les features ne le sont pas**. MOSAIKS utilise des convolutions aléatoires, des fonctions d'activation non linéaires (RELU) et un *average pooling* pour transformer l'imagerie satellite brute en features pertinentes. Étant donné que ces transformations capturent une large gamme de modèles spatiaux non linéaires, les méthodes linéaires traditionnelles peuvent alors bien fonctionner avec une complexité supplémentaire minimale.

### Métriques d'évaluation

Pour les résultats continus, les mesures d'évaluation clés comprennent:

- **R²(Coefficient de détermination)**: Mesure la proportion de variance dans les données d'étiquette expliquée par le modèle.  
- **RMSE (Racine carrée de l'erreur quadratique moyenne)**: Quantifie l'ampleur moyenne des erreurs de prédiction.  
- **MAE (Erreur absolue moyenne)**: Différence absolue moyenne entre les prédictions et les valeurs réelles, moins sensible aux grandes valeurs aberrantes que RMSE.

## Classification binaire

Dans certaines applications de MOSAIKS, vos étiquettes peuvent être binaires (par exemple, la présence de bâtiments ou à l'absence, le changement d'utilisation des terres vs pas de changement). Ici, **la régression logistique** sert souvent de choix simple.

### La Régression logistique

La régression logistique modélise la probabilité qu'un exemple donné appartient à la classe "positive":
$$
\text{logit}(p) = \beta_0 + \beta_1 x_1 + \cdots + \beta_n x_n
$$

où $p$ est la probabilité d'appartenir à la classe positive. Malgré sa simplicité, la régression logistique fournit des performances robustes et interprétables pour de nombreuses tâches de classification binaire avec des features de MOSAIKS.

### Métriques d'évaluation

Pour la classification binaire, les mesures communes comprennent:

- **AUC-ROC**: La zone sous la courbe ROC, évaluant le compromis entre le taux de vrais positifs et le taux de faux positifs selon différents valeurs de seuil.  
- **Précision**: la proportion de prédictions correctes.  
- **Précision**: Parmi les prédictions positives faites, combien étaient correctes?  
- **Rappel**: Parmi les positifs réels de l'ensemble de données, combien en avons-nous identifié correctement?  
- **Score F1**: La moyenne harmonique de la précision et du rappel, souvent utilisée dans les cas de classification déséquilibrée.

## Classification multi-classes

Certaines applications nécessitent de prédire plusieurs catégories (par exemple, les types de couverture terrestre, la variété des cultures, les catégories de construction). Ce sont des problèmes de classification **multi-classes**. Plusieurs approches sont possibles:

1. **One-Vs-Rest**: Entraîner un classificateur binaire pour chaque classe ; chaque classificateur distingue une classe de "tous les autres".  
2. **Régression multinomiale (softmax)**: un seul modèle pour prédire les probabilités dans toutes les classes simultanément.  
3. **Régression ordinale**: pour prédire les catégories ordonnées (par exemple, léger, modéré et grave).

![Exemple de classification multiclasse](../../images/proctor_et_al_100_ecoregions_comparison.jpg){#fig-multiclass-classification}

### Métriques d'évaluation

Pour les problèmes multi-classes, considérez:

- **Précision globale**: pourcentage d'exemples correctement classé.  
- **Précision par classe**: Précision dans chaque classe, utile si les tailles de classe sont déséquilibrées.  
- **Matrice de confusion**: fournit une ventilation détaillée des prédictions par rapport aux classes réelles.  
- **Score F1 pondéré**: moyenne F1 dans les classes, pondération par fréquence des classes.  
- **Kappa de Cohen**: mesure l'accord entre les étiquettes prévues et les étiquettes réelles, l'accord de l'ajustement pour le hasard.

## En appliquant le modèle pour faire des prédictions

Une fois que vous avez sélectionné un modèle et l'avoir réglé (par exemple, via la validation croisée), vous pouvez **appliquer le modèle à de nouvelles données**. Cette étape est souvent appelée "inférence":

1. **Préparer les features**: Les features des nouvelles zones ou périodes doivent être extraites en utilisant le même modèle RCF qui a été utilisé pour extraire les features d'origine. Ainsi, si les features de l'ensemble d'entraînement ont été calculés d'une manière différente de celle de l'API (choix de différents filtres de convolution par exemple), il est important que les features des nouvelles données soient calculés de la même manière (utilisation des mêmes filtres par exemple).

1. **Chargez le modèle entraîné**: Assurez-vous que le modèle (ainsi que les hyperparamètres et les étapes de prétraitement) est chargé exactement comme il a été ajusté. Cette cohérence est essentielle pour maintenir la précision prédictive.

1. **Prédire**: Mettre la nouvelle matrice de fonctionnalités (`X_new`) dans la méthode `predict` du modèle entraîné pour obtenir des prédictions. Par exemple, en utilisant Scikit-Learn:
   ```python
   y_pred = ridge.predict (x_new)
    ```

Si votre tâche est une classification, utilisez `predict_proba` pour obtenir des probabilités prédites:
   ```python
   p_pred = logistic_regression.predict_proba(X_new)
   ```

1. **Interpréter et stocker les résultats**: Enregistrer les prédictions dans un format structuré (par exemple, CSV, Geotiff) pour une analyse ultérieure. Envisagez d'inclure des métadonnées sur la date et la version de votre modèle, le processus d'extraction des features MOSAIKS et toutes les notes pertinentes sur la qualité des données.

En suivant ces étapes, vous vous assurez que vos modèles MOSAIKS sont déployés de manière efficace et cohérente. De là, vous pouvez visualiser les prédictions, les intégrer dans des analyses en aval ou éclairer la politique et la prise de décision en fonction de la sortie du modèle.

### Changement de distribution
Lorsque vous appliquez votre modèle à de nouvelles régions géographiques ou dans différentes conditions, sachez que la distribution des données sous-jacente (modèles d'imagerie satellite, facteurs socio-économiques, types d'utilisation des terres/couverture terrestre) peut différer de votre ensemble de formation. Ce "changement de distribution" peut entraîner une réduction des performances prédictives si le modèle n'a pas été exposé à des exemples similaires pendant l'entraînement. Pour atténuer cela, envisagez de collecter des données d'apprentissage représentatives supplémentaires à partir de ces nouvelles régions, d'adopter des techniques d'apprentissage ou d'adaptation de domaine et de quantification de l'incertitude prédictive afin que vous puissiez signaler les domaines où le modèle peut mal performer. Audits de performances périodiques et réentraînement - en particulier lorsque de nouvelles données deviennent disponibles - assurent une généralisation robuste à travers diverses géographies.

Il est possible de prédire à une résolution plus élevée que les étiquettes. En effet dans certains, cas un modèle entraîné sur une résolution donnée, par exemple 1km x 1km, peut être utilisé pour faire des prédictions à une résolution de 250m x 250m. Il est important de rester vigilant lorsque l'onn utilise le modèle dans de tels cas et s'assurer que les performances à plus grande résolution reste comparable à la résolution initiale.


## Quantification de l'incertitude


## Processus de sélection d'un modèle

1. **Identifier le type d'étiquette** 
   - Continue → Régression Ridge ou Lasso  
   - Binaire → Régression logistique  
   - Multi-Classe → One-VS-Rest ou multinomial

2. **Validation croisée** 
   - Diviser les données en ensemble d'apprentissage, validation et ensemble de test, en respectant la structure spatiale si possible (par exemple, un contre tous (leave-one-out)).  
   - Sélectionnez les mesures d'évaluation appropriées (par exemple, R² pour continu, ROC-AUC pour le binaire).  
   - Choisir les hyperparamètres ($\lambda$ dans Ridge / Lasso, régularisation en logistique) en utilisant l'ensemble de validation.

3. **Déploiement du modèle** 
   - Réentraîner le modèle sur l'ensemble des données en utilisant les hyperparamètres choisis.  
   - Générer des prédictions sur l'ensemble de tests (ou de nouvelles données).  
   - Quantifier l'incertitude (par exemple, intervalles de confiance, estimations d'erreur hors échantillon).

## Résumé

- **Commencez par des modèles linéaires simples**: Utiliser les features MOSAIKSpour obtenir des données non linéaires.  
- **Faites correspondre la métrique à la tâche**: R² ou RMSE pour les étiquettes continues, le score AUC-ROC ou F1 pour la classification, etc.  
- **Utilisez la validation croisée**: Toujours séparer les ensembles d'entraînement et de test pour obtenir des estimations non biaisées des performances du modèle.
- **Considérons la structure spatiale**: Lorsque vous traitez des données spatiales, des divisions aléatoires standard peuvent conduire à des estimations trop optimistes des performances.

Les éléments clés pour la construction de modèles réussis comprennent:

1. **Sélection d'algorithme**
   - Choisissez en fonction du type d'étiquette
   - Considérez les besoins de calcul
   - Trouver un équilibre entre complexité et performance

2. **Validation croisée**
   - Utilisez le facteur spatial lors de la création des différents ensembles
   - Sélectionnez des métriques appropriées
   - Ajuster les hyperparamètres du modèle

3. **Évaluation du modèle**
   - Tester les performances sur un ensemble de test
   - Valider dans l'espace (si possible)
   - Quantifier les incertitudes

4. **Déploiement**
   - Entraîner le modèle final
   - Générer des prédictions
   - Documenter la procédure
   - Surveiller les performances

::: {.callout-note}
Dans le chapitre suivant, nous discuterons des stratégies de comptabilité des dépendances spatiales dans votre flux de travail de modélisation, y compris des méthodes de validation croisée spatiale, d'interpolation spatiale et d'extrapolation spatiale.
:::